[{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Getting Started with countSTAR","text":"countSTAR package implements variety methods analyze diverse count-valued data, based idea Simultaneous Transformation Rounding (STAR) models. package functionality broadly split three categories: Bayesian estimation STAR models (Kowal Canale (2020), Kowal Wu (2022)), frequentist/classical estimation (Kowal Wu (2021)), time series analysis using warped Dynamic Linear Models (King Kowal (2023)). give brief description STAR framework, diving specific examples show countSTAR functionality.","code":""},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"star-model-overview","dir":"Articles","previous_headings":"","what":"STAR Model Overview","title":"Getting Started with countSTAR","text":"STAR models build upon continuous data models provide valid count-valued data-generating process. example STAR model linear regression follows: \\[\\begin{align*} y_i &= \\mbox{floor}(y_i^*) \\\\ z_i^* &= \\log(y_i^*) \\\\ z_i^* &= x_i'\\beta + \\epsilon_i, \\quad \\epsilon_i \\stackrel{iid}{\\sim}N(0, \\sigma^2) \\end{align*}\\] latent data \\(y_i^*\\) act continuous proxy count data \\(y_i\\), easier model yet simple mapping via floor function observed data. latent data \\(y_i^*\\) transformed \\(z_i^*\\), common practice, modeled using Gaussian linear regression. model inherits structure , data-generating process now count-valued. generally, STAR models defined via rounding operator \\(h\\), (known unknown) transformation \\(g\\), continuous data model \\(\\Pi_\\theta\\) unknown parameters \\(\\theta\\): \\[\\begin{align*} y &= h(y^*) \\quad \\mbox{(rounding)}\\\\ z^* &= g(y^*) \\quad \\mbox{(transformation)}\\\\ z^* & \\sim \\Pi_\\theta \\quad \\mbox{(model)}\\\\ \\end{align*}\\] Importantly, STAR models highly flexible count-valued processes, provide capability model () discrete data, (ii) zero-inflation, (iii) - -dispersion, (iv) bounded censored data. focus conditionally Gaussian models form \\[ z^*(x) = \\mu_\\theta(x) + \\epsilon(x), \\quad \\epsilon(x) \\stackrel{iid}{\\sim}N(0, \\sigma^2) \\] \\(\\mu_\\theta(x)\\) conditional expectation transformed latent data unknown parameters \\(\\theta\\). Examples include linear, additive, tree-based regression models.","code":""},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"the-rounding-operator","dir":"Articles","previous_headings":"STAR Model Overview","what":"The Rounding Operator","title":"Getting Started with countSTAR","text":"rounding operator \\(h\\) many--one function sets \\(y = j\\) whenever \\(y^*\\\\mathcal{}_j\\) equivalently \\(z^*=g(y^*) \\g(\\mathcal{}_j)\\) . take many different forms, generally floor function, .e \\(\\mathcal{}_j := [j, j+1)\\) works well default, modification \\(g(\\mathcal{}_0) := (-\\infty, 0)\\) \\(y = 0\\) whenever \\(z^* < 0\\). latter modification ensures much latent space mapped zero, therefore STAR models can easily account zero-inflation. Furthermore, known upper bound y_max\\(=K\\) data, additional change incorporate structure, namely let \\(g(\\mathcal{}_K) := [g(a_K), \\infty)\\). rounding operator inverse implemented countSTAR functions a_j() round_fun(), although rarely need employed end user. Instead, thing might need specified user whether upper bound data exists, case simple option setting y_max modeling functions passed rounding function.","code":""},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"the-transformation-function","dir":"Articles","previous_headings":"STAR Model Overview","what":"The Transformation Function","title":"Getting Started with countSTAR","text":"variety options transformation function \\(g\\), ranging fixed functions -priori data-driven transformations transformations learned along rest model. models countSTAR support three common fixed transformations: log, square root (‘sqrt’), identity transformation (essentially rounding-model). Furthermore, functions support set transformations learned matching marginal moments data \\(y\\) latent \\(z\\): transformation='pois' uses moment-matched marginal Poisson CDF transformation='neg-bin' uses moment-matched marginal Negative Binomial CDF transformation='np' nonparametric transformation estimated empirical CDF \\(y\\). Details estimation transformations can found Kowal Wu (2021). particular “np” transformation proven effective, especially heaped data, default across functions. STAR methods also support ways learning transformation alongside model: transformation='box-cox': transformation assumed belong Box-Cox family; sampler samples \\(\\lambda\\) parameter transformation='ispline': transformation modeled unknown, monotone function using -splines. Robust Adaptive Metropolis (RAM) sampler used drawing parameter transformation function. transformation='bnp': transformation modeled using Bayesian bootstrap, Bayesian nonparametric model incorporates uncertainty transformation posterior predictive inference. learned transformations always available every function; check appropriate help page see options supported.","code":""},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"count-valued-data-the-roaches-dataset","dir":"Articles","previous_headings":"","what":"Count-Valued Data: The Roaches Dataset","title":"Getting Started with countSTAR","text":"example complex count-valued data, consider roaches data Gelman Hill (2006). response variable, \\(y_i\\), number roaches caught traps apartment \\(\\), \\(=1,\\ldots, n = 262\\).  several notable features data: Zero-inflation: 36% observations zeros. (Right-) Skewness, clear histogram common (zero-inflated) count data. Overdispersion: sample mean 26 sample variance 2585. pest management treatment applied subset 158 apartments, remaining 104 apartments receiving control. Additional data available pre-treatment number roaches, whether apartment building restricted elderly residents, number days traps exposed. interested modeling roach incidence varies predictors.","code":"data(roaches, package=\"countSTAR\")   # Roaches: y = roaches$y  # Function to plot the point mass function: stickplot = function(y, ...){   js = 0:max(y);    plot(js,         sapply(js, function(js) mean(js == y)),         type='h', lwd=2, ...) } stickplot(y, main = 'PMF: Roaches Data',           xlab = 'Roaches', ylab = 'Probability mass')"},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"frequentist-inference-for-star-models","dir":"Articles","previous_headings":"","what":"Frequentist inference for STAR models","title":"Getting Started with countSTAR","text":"Frequentist (classical) estimation inference STAR models provided EM algorithm. Sufficient estimation estimator function solves least squares (Gaussian maximum likelihood) problem associated \\(\\mu_\\theta\\)—words, estimator used Gaussian continuous data. Specifically, estimator inputs data outputs list two elements: estimated coefficients \\(\\hat \\theta\\) fitted.values \\(\\hat \\mu_\\theta(x_i) = \\mu_{\\hat \\theta}(x_i)\\).","code":""},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"the-star-linear-model","dir":"Articles","previous_headings":"Frequentist inference for STAR models","what":"The STAR Linear Model","title":"Getting Started with countSTAR","text":"many applications, STAR linear model often first method try. countSTAR, linear model implemented lm_star function, aims mimic functionality lm allowing users input formula. Standard functions like coef fitted can used output extract coefficients fitted values, respectively. np transformation used, options available; see ?lm_star details. Based fitted STAR linear model, may obtain confidence intervals estimated coefficients using confint: Similarly, p-values available using likelihood ratio tests, can applied individual coefficients, \\[ H_0: \\beta_j= 0 \\quad \\mbox{vs} \\quad H_1: \\beta_j \\ne 0 \\] joint sets variables, analogous (partial) F-test: \\[ H_0: \\beta_1=\\ldots=\\beta_p = 0, \\quad \\mbox{vs.} \\quad H_1: \\beta_j \\ne 0 \\mbox{ } j=1,\\ldots,p \\] P-values individual coefficients well p-value effects computed pvals function. Finally, can get predictions new data points (training data) using predict. Optionally, prediction intervals can estimated using (plug-) predictive distribution MLEs (see ?predict.lmstar details). Note “plug-” predictive distribution crude approximation, better approaches uncertainty quantification available using Bayesian models.","code":"library(countSTAR)  # Select a transformation: transformation = 'np' # Estimated transformation using empirical CDF  # EM algorithm for STAR fit = lm_star(y ~ roach1 + treatment + senior + log(exposure2),               data = roaches,                transformation = transformation)   # Dimensions: n = nrow(fit$X); p = ncol(fit$X)  # Fitted coefficients: round(coef(fit), 3) #>    (Intercept)         roach1      treatment         senior log(exposure2)  #>          0.035          0.006         -0.285         -0.321          0.216 # Confidence interval for all coefficients confint(fit) #>                       2.5 %       97.5 % #> (Intercept)    -0.141422049  0.202055725 #> roach1          0.004898197  0.007466265 #> treatment      -0.486526183 -0.084393965 #> senior         -0.548147166 -0.102149034 #> log(exposure2) -0.197811283  0.637275996 # P-values: print(pvals(fit)) #>        (Intercept)             roach1          treatment             senior  #>       6.973311e-01       1.887411e-18       5.600904e-03       4.862496e-03  #>     log(exposure2) Any linear effects  #>       3.072376e-01       9.271134e-20 #Compute the predictive draws (just using observed points here) y_pred = predict(fit)"},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"star-machine-learning-models","dir":"Articles","previous_headings":"Frequentist inference for STAR models","what":"STAR Machine Learning Models","title":"Getting Started with countSTAR","text":"addition linear model, countSTAR also implementations STAR models paired flexible regression methods, particular random forests (randomForest_star()) generalized boosted machines (gbm_star()). functions, user directly inputs set predictors \\(X\\) alongside test points \\(X_{test}\\), can seen example : frequentist models, functions output log-likelihood values MLEs, allows quick comparison model fit. general, preferable compare fits using --sample predictive performance.","code":"# Select a transformation: transformation = 'np' # Estimated transformation using empirical CDF  # Construct data matrix y = roaches$y X = roaches[, c(\"roach1\", \"treatment\", \"senior\", \"exposure2\")]  #Fit STAR with random forests fit_rf = randomForest_star(y = y, X = X,                             transformation = transformation)  #Fit STAR with GBM fit_gbm = gbm_star(y = y, X = X,                     transformation = transformation) #Look at -2*log-likelihood print(-2*c(fit_rf$logLik, fit_gbm$logLik)) #> [1] 1665.662 1594.125"},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"bayesian-inference-for-star-models","dir":"Articles","previous_headings":"","what":"Bayesian inference for STAR models","title":"Getting Started with countSTAR","text":"Bayesian model, STAR requires algorithm initializing sampling posterior distribution continuous data model. specifically, posterior inference STAR based Gibbs sampler, augments aforementioned continuous sampler draw \\([z^* | y, \\theta]\\). \\(\\Pi_\\theta\\) conditionally Gaussian, \\([z^* | y, \\theta]\\) truncated Gaussian distribution.","code":""},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"linear-model","dir":"Articles","previous_headings":"Bayesian inference for STAR models","what":"Linear Model","title":"Getting Started with countSTAR","text":"illustration, consider Bayesian linear regression model \\[\\begin{align*} z_i^* &= x_i'\\beta + \\epsilon_i, \\quad \\epsilon_i \\stackrel{iid}{\\sim}N(0, \\sigma^2) \\\\ 1/\\sigma^2 &\\sim \\mbox{Gamma}(\\alpha=0.001, \\beta=0.001) \\;. \\end{align*}\\] model completed assigning prior structure \\(\\beta\\). default countSTAR Zellner’s g-prior, functionality, options available (namely, horseshoe ridge priors). model estimated using blm_star(). Note Bayesian models countSTAR, user must supply design matrix \\(X\\) (predictions desired, matrix predictors test points). apply roaches data, now using default nonparametric transformation. default, function uses Gibbs sampler draw posterior, settings exact inference can performed (see Kowal Wu (2022) details). enable , one can simply set use_MCMC=FALSE. either case, output function much , exception \\(\\sigma\\) estimated priori thus posterior draws. Posterior expectations posterior credible intervals model available follows: may evaluate model based posterior diagnostics posterior predictive checks simulated versus observed proportion zeros. Posterior predictive checks easily visualized using bayesplot package.","code":"X = model.matrix(y ~ roach1 + treatment + senior + log(exposure2),                  data = roaches)  # Dimensions: n = nrow(X); p = ncol(X)  fit_blm = blm_star(y = y, X = X,                     transformation = 'np') # Posterior mean of each coefficient: round(coef(fit_blm),3) #>    (Intercept)         roach1      treatment         senior log(exposure2)  #>          0.031          0.006         -0.291         -0.333          0.220  # Credible intervals for regression coefficients ci_all_bayes = apply(fit_blm$post.beta,       2, function(x) quantile(x, c(.025, .975)))  # Rename and print: rownames(ci_all_bayes) = c('Lower', 'Upper') print(t(round(ci_all_bayes, 3))) #>                 Lower  Upper #> (Intercept)    -0.148  0.204 #> roach1          0.005  0.007 #> treatment      -0.503 -0.087 #> senior         -0.552 -0.113 #> log(exposure2) -0.171  0.660 # MCMC diagnostics for posterior draws of the regression coefficients plot(as.ts(fit_blm$post.beta), main = 'Trace plots', cex.lab = .75) # (Summary of) effective sample sizes across coefficients: getEffSize(fit_blm$post.beta) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   629.9   677.4   781.2   750.4   791.9   871.7  # Posterior predictive check using bayesplot suppressMessages(library(bayesplot)) prop_zero = function(y) mean(y == 0) ppc_stat(y = roaches$y,            yrep = fit_blm$post.pred,            stat = \"prop_zero\")"},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"bart-star","dir":"Articles","previous_headings":"Bayesian inference for STAR models","what":"BART STAR","title":"Getting Started with countSTAR","text":"One flexible model options use Bayesian Additive Regression Trees (BART; Chipman, George, McCulloch (2012)) latent regression model: , can perform posterior predictive checks. time plot densities.  Bayesian models, pointwise log-likelihoods WAIC values outputted model comparison. Using information, can see BART STAR model seems better fit linear model.","code":"#Get the model matrix of predictors (no intercept necessary) X = model.matrix(y ~ -1 + roach1 + treatment + senior + exposure2,                  data = roaches)  fit_bart = bart_star(y = y, X = X,                       transformation = 'np') #> [1] \"Burn-In Period\" #> [1] \"Starting sampling\" #> [1] \"0 seconds remaining\" #> [1] \"Total time:  3 seconds\" ppc_dens_overlay(y = roaches$y,                   yrep = fit_bart$post.pred[1:50,]) waic <- c(fit_blm$WAIC, fit_bart$WAIC) names(waic) <- c(\"STAR Linear Model\", \"BART-STAR\") print(waic) #> STAR Linear Model         BART-STAR  #>          1687.548          1639.219"},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"other-models","dir":"Articles","previous_headings":"Bayesian inference for STAR models","what":"Other Models","title":"Getting Started with countSTAR","text":"countSTAR also implements Bayesian additive models. function bam_star(), can specify covariates modeled linearly others modeled non-linearly using spline bases. word warning, additive models can take much longer fit. exploring relationship one predictor count outcome \\(y\\), one can also use spline regression implemented spline_star(). See appropriate help pages examples run models.","code":""},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"count-time-series-modeling-warpdlm","dir":"Articles","previous_headings":"","what":"Count Time Series Modeling: warpDLM","title":"Getting Started with countSTAR","text":"point, attention focused static regression data depend time. However, ideas simultaneous transformation rounding extended time series domain King Kowal (2023). work, proposed linking time-dependent count data \\(y_t\\) powerful time series framework known Dynamic Linear Models (DLMs). DLM defined two equations: () observation equation, specifies observations related latent state vector (ii) state evolution equation, describes states updated Markovian fashion. concretely, represent following form: \\[\\begin{align*}     z_t &= F_t \\theta_t + v_t, \\quad v_t \\sim N_n(0, V_t) \\\\     \\theta_t &= G_t \\theta_{t-1} +  w_t, \\quad w_t \\sim N_p( 0, W_t) \\end{align*}\\] \\(t=1,\\ldots, T\\), \\(\\{ v_t, w_t\\}_{t=1}^T\\) mutually independent \\(\\theta_0 \\sim N_p(a_0, R_0)\\). course, given Gaussian assumptions model, DLM alone appropriate count data. Thus, warping operation (simultaneous transformation rounding) applied DLM, resulting count time series framework known warped DLM (warpDLM). explicitly, can written : \\[\\begin{align*}          y_t &= h \\circ g^{-1}(z_t) \\\\         \\{z_t\\}_{t=1}^T &\\sim \\text{DLM} \\end{align*}\\] DLM form shown earlier general. Among DLMs, countSTAR currently implements local level model local linear trend model. local level model (also known random walk noise model) univariate state \\(\\theta_t:=\\mu_t\\), DLM equations simply \\[\\begin{align*}     z_t &= \\mu_t + v_t, \\quad v_t \\sim N(0, V) \\\\     \\mu_t &= \\mu_{t-1} +  w_t, \\quad w_t \\sim N(0, W) \\end{align*}\\] local linear trend model extends local level model incorporating time varying drift \\(\\nu_t\\) dynamics: \\[\\begin{align*}     z_t &= \\mu_t + v_t, \\quad v_t \\sim N(0, V) \\\\     \\mu_t &= \\mu_{t-1} + \\nu_{t-1} +  w_{\\mu,t}, \\quad w_{\\mu,t} \\sim N( 0, W_     \\mu) \\\\     \\nu_t &= \\nu_{t-1} +  w_{\\nu,t}, \\quad w_{\\nu,t} \\sim N( 0, W_\\nu) \\end{align*}\\] can turn recast general two-equation DLM form. Namely, let \\(\\theta_t:=(\\mu_t, \\nu_t)\\), local linear trend written \\[\\begin{align*} z_t & = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} \\mu_t \\\\ \\nu_t \\end{pmatrix} + v_t, \\quad v_t \\sim N(0, V) \\\\ \\begin{pmatrix} \\mu_t \\\\ \\nu_t \\end{pmatrix} & = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\begin{pmatrix} \\mu_{t-1} \\\\ \\nu_{t-1} \\end{pmatrix}  + \\boldsymbol{w_t}, \\quad \\boldsymbol{w_t} \\sim N\\begin{pmatrix} \\boldsymbol{0}, \\begin{bmatrix} W_     \\mu & 0 \\\\ 0 & W_\\nu \\end{bmatrix} \\end{pmatrix} \\end{align*}\\] two common forms long history also referred structural time series models (implemented base R via StructTS()). countSTAR, warpDLM time series modeling accomplished via warpDLM() function. , apply model time series dataset included base R concerning yearly numbers important discoveries 1860 1959 (?discoveries information).  , can check fit using posterior predictive checks. median posterior predictive draws can act sort count-valued smoother time series.","code":"#Visualize the data plot(discoveries) #Fit the model warpfit <- warpDLM(y=discoveries, type=\"trend\") #> [1] \"Time taken:  67.026  seconds\" ppc_ribbon(y = as.vector(discoveries),             yrep = warpfit$post_pred)"},{"path":[]},{"path":"https://bking124.github.io/countSTAR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Brian King. Author, maintainer. Dan Kowal. Author.","code":""},{"path":"https://bking124.github.io/countSTAR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"King B, Kowal D (2023). countSTAR: Flexible Modeling Count Data. R package version 1.0.2.9000, https://bking124.github.io/countSTAR/https://github.com/bking124/countSTAR.","code":"@Manual{,   title = {countSTAR: Flexible Modeling of Count Data},   author = {Brian King and Dan Kowal},   year = {2023},   note = {R package version 1.0.2.9000},   url = {https://bking124.github.io/countSTAR/ https://github.com/bking124/countSTAR}, }"},{"path":[]},{"path":"https://bking124.github.io/countSTAR/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Flexible Modeling of Count Data ","text":"Count-valued data common many fields. Frequently, count data observed jointly predictors, time intervals, across spatial locations. Furthermore, often exhibit variety complex distributional features, including zero-inflation, skewness, - underdispersion, cases may bounded censored. Flexible interpretable models count-valued processes therefore highly useful practice. countSTAR implements variety methods modeling processes, based idea Simultaneous Transformation Rounding (STAR). Estimation, inference, prediction STAR available Bayesian frequentist models. bulk methods serve static regression problems, package also supports time series analysis via warped Dynamic Linear Model (DLM) framework. Broadly, STAR defines count-valued probability model (1) specifying (conditionally) Gaussian model continuous latent data (2) connecting latent data observed data via transformation rounding operation. Importantly, STAR models highly flexible count-valued processes, provide capability model () discrete data, (ii) zero-inflation, (iii) - -dispersion, (iv) heaping, (v) bounded censored data. modularity STAR framework allows ability utilize wide variety different latent data models, can range simple forms like linear regression advanced machine learning methods random forests gradient boosting machines. countSTAR can installed loaded follows: Detailed information different options STAR models implemented countSTAR can found vignette, accessible website running command vignette(\"countSTAR\"). basic breakdown available modeling functions shown : addition ready use functions, users can also implement STAR methods custom latent regression models using genEM_star() genMCMC_star() functions. Please submit issues feature requests https://github.com/bking124/countSTAR/issues.","code":"#CRAN version install.packages(\"countSTAR\")  #Development version remotes::install_github(\"bking124/countSTAR\")  library(\"countSTAR\")"},{"path":"https://bking124.github.io/countSTAR/reference/BrentMethod.html","id":null,"dir":"Reference","previous_headings":"","what":"Brent's method for optimization — BrentMethod","title":"Brent's method for optimization — BrentMethod","text":"Implementation Brent's algorithm minimizing univariate function interval. code based function stsm package.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/BrentMethod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Brent's method for optimization — BrentMethod","text":"","code":"BrentMethod(a = 0, b, fcn, tol = .Machine$double.eps^0.25)"},{"path":"https://bking124.github.io/countSTAR/reference/BrentMethod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Brent's method for optimization — BrentMethod","text":"lower limit search b upper limit search fcn function minimize tol tolerance level convergence optimization procedure","code":""},{"path":"https://bking124.github.io/countSTAR/reference/BrentMethod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Brent's method for optimization — BrentMethod","text":"list containing following elements: fx: minimum value input function x: argument minimizes function iter: number iterations converge vx: vector stores arguments convergence","code":""},{"path":"https://bking124.github.io/countSTAR/reference/a_j.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse rounding function — a_j","title":"Inverse rounding function — a_j","text":"Define intervals associated y = j based flooring function. function returns -Inf j = 0 (smaller) Inf j >= y_max + 1, y_max known upper bound data y (specified).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/a_j.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse rounding function — a_j","text":"","code":"a_j(j, y_max = Inf)"},{"path":"https://bking124.github.io/countSTAR/reference/a_j.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse rounding function — a_j","text":"j integer-valued input(s) y_max fixed known upper bound observations; default Inf","code":""},{"path":"https://bking124.github.io/countSTAR/reference/a_j.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse rounding function — a_j","text":"(lower) interval endpoint(s) associated j.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/a_j.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse rounding function — a_j","text":"","code":"# Standard cases: a_j(1) #> [1] 1 a_j(20) #> [1] 20  # Boundary cases: a_j(0) #> [1] -Inf a_j(20, y_max = 15) #> [1] Inf"},{"path":"https://bking124.github.io/countSTAR/reference/bam_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Bayesian Additive STAR Model with MCMC — bam_star","title":"Fit Bayesian Additive STAR Model with MCMC — bam_star","text":"Run MCMC algorithm STAR Bayesian additive model transformation can known (e.g., log sqrt) unknown (Box-Cox estimated nonparametrically) greater flexibility.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bam_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Bayesian Additive STAR Model with MCMC — bam_star","text":"","code":"bam_star(   y,   X_lin,   X_nonlin,   splinetype = \"orthogonal\",   transformation = \"np\",   y_max = Inf,   nsave = 1000,   nburn = 1000,   nskip = 0,   save_y_hat = FALSE,   verbose = TRUE )"},{"path":"https://bking124.github.io/countSTAR/reference/bam_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Bayesian Additive STAR Model with MCMC — bam_star","text":"y n x 1 vector observed counts X_lin n x pL matrix predictors modelled linear X_nonlin n x pNL matrix predictors modelled nonlinear splinetype Type spline use modelling nonlinear predictors; must either \"orthogonal\" (orthogonalized splines--default) \"thinplate\" (low-rank thin plate splines) transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) \"ispline\" (transformation modeled unknown, monotone function using -splines) y_max fixed known upper bound observations; default Inf nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw save_y_hat logical; TRUE, compute save posterior draws expected counts, E(y), may slow compute verbose logical; TRUE, print time remaining","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bam_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Bayesian Additive STAR Model with MCMC — bam_star","text":"list least following elements: coefficients: posterior mean coefficients fitted.values: posterior mean conditional expectation counts y post.coefficients: posterior draws coefficients post.fitted.values: posterior draws conditional mean counts y post.pred: draws posterior predictive distribution y post.lambda: draws posterior distribution lambda post.sigma: draws posterior distribution sigma post.log.like.point: draws log-likelihood n observations WAIC: Widely-Applicable/Watanabe-Akaike Information Criterion p_waic: Effective number parameters based WAIC case transformation=\"ispline\", list also contains post.g: draws posterior distribution transformation g post.sigma.gamma: draws posterior distribution sigma.gamma, prior standard deviation transformation g() coefficients","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bam_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit Bayesian Additive STAR Model with MCMC — bam_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. Posterior predictive inference obtained via Gibbs sampler combines () latent data augmentation step (like probit regression) (ii) existing sampler continuous data model. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt', well version Box-Cox parameter inferred within MCMC sampler ('box-cox'). Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y. Third, transformation can modeled unknown, monotone function using -splines ('ispline'). Robust Adaptive Metropolis (RAM) sampler used drawing parameter transformation function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bam_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Bayesian Additive STAR Model with MCMC — bam_star","text":"","code":"# \\donttest{ # Simulate data with count-valued response y: sim_dat = simulate_nb_friedman(n = 100, p = 5, seed=32) y = sim_dat$y; X = sim_dat$X  # Linear and nonlinear components: X_lin = as.matrix(X[,-(1:3)]) X_nonlin = as.matrix(X[,(1:3)])  # STAR: nonparametric transformation fit = bam_star(y = y, X_lin = X_lin, X_nonlin = X_nonlin) #> [1] \"Burn-In Period\" #> [1] \"Starting sampling\" #> [1] \"-0.01 seconds remaining\" #> [1] \"Total time:  27 seconds\"  # What is included: names(fit) #>  [1] \"coefficients\"        \"post.coefficients\"   \"post.pred\"           #>  [4] \"post.predtest\"       \"post.sigma\"          \"post.log.like.point\" #>  [7] \"WAIC\"                \"p_waic\"              \"post.lambda\"         #> [10] \"fitted.values\"       \"post.fitted.values\"   # Posterior mean of each coefficient: coef(fit) #>      beta_lin1      beta_lin2      beta_lin3      beta_lin4      beta_lin5  #>   4.849553e-01  -9.844473e-02   2.112875e-01   3.457011e-01  -5.990038e-02  #>           f_j1           f_j2           f_j3           f_j4           f_j5  #>   1.015439e-02   6.186467e-02   1.887529e-01   1.393624e-01  -2.635504e-01  #>           f_j6           f_j7           f_j8           f_j9          f_j10  #>   3.096598e-01   1.539452e-01   2.198692e-01   1.073200e-01  -6.852183e-02  #>          f_j11          f_j12          f_j13          f_j14          f_j15  #>   9.840488e-02  -1.192382e-01   7.184468e-02   1.655447e-01  -1.636809e-01  #>          f_j16          f_j17          f_j18          f_j19          f_j20  #>   1.511202e-01   1.825797e-01  -4.523562e-02   7.770523e-02   2.655978e-01  #>          f_j21          f_j22          f_j23          f_j24          f_j25  #>   1.126634e-01   2.511618e-01  -1.802007e-02  -2.764885e-01   5.368532e-02  #>          f_j26          f_j27          f_j28          f_j29          f_j30  #>   3.338221e-01  -1.649638e-02   1.685891e-02   3.015832e-02   7.163969e-02  #>          f_j31          f_j32          f_j33          f_j34          f_j35  #>  -6.326433e-02   1.996706e-01   2.684669e-01   2.024368e-01  -3.002365e-02  #>          f_j36          f_j37          f_j38          f_j39          f_j40  #>   1.628551e-01   1.843565e-02  -2.670556e-01   1.814901e-01   3.378932e-01  #>          f_j41          f_j42          f_j43          f_j44          f_j45  #>  -6.967785e-02   1.574249e-01  -2.762269e-01   2.743747e-02   2.008084e-01  #>          f_j46          f_j47          f_j48          f_j49          f_j50  #>  -2.003650e-01   8.850640e-02   3.163510e-01   1.641973e-01  -3.574127e-01  #>          f_j51          f_j52          f_j53          f_j54          f_j55  #>   1.903302e-01   3.059019e-01   1.235127e-01  -9.751814e-02  -4.062758e-01  #>          f_j56          f_j57          f_j58          f_j59          f_j60  #>  -4.278529e-01   2.085722e-01   2.329737e-01   1.122958e-01   3.101053e-01  #>          f_j61          f_j62          f_j63          f_j64          f_j65  #>   1.790396e-01  -2.826231e-01   1.356264e-01  -2.251938e-01  -2.121353e-01  #>          f_j66          f_j67          f_j68          f_j69          f_j70  #>   3.483099e-01   2.153971e-01  -3.049449e-01   2.944546e-01  -5.170414e-02  #>          f_j71          f_j72          f_j73          f_j74          f_j75  #>   2.089114e-01  -1.736095e-01  -2.274735e-02  -3.965110e-01  -3.030856e-01  #>          f_j76          f_j77          f_j78          f_j79          f_j80  #>  -1.989557e-01   1.493029e-01  -2.999672e-01  -7.402775e-02  -7.310110e-02  #>          f_j81          f_j82          f_j83          f_j84          f_j85  #>   2.551681e-02   3.004657e-02   2.608051e-02  -4.203799e-01  -2.401758e-01  #>          f_j86          f_j87          f_j88          f_j89          f_j90  #>   2.576076e-02  -2.318883e-02   2.263757e-01  -2.277064e-01   2.264860e-01  #>          f_j91          f_j92          f_j93          f_j94          f_j95  #>  -3.666942e-01  -1.217160e-01  -2.901900e-01  -1.131730e-01  -1.611680e-01  #>          f_j96          f_j97          f_j98          f_j99         f_j100  #>  -3.592445e-01  -1.685916e-01  -6.016295e-02  -3.101295e-01  -3.266571e-01  #>         f_j101         f_j102         f_j103         f_j104         f_j105  #>   2.667322e-01   4.922053e-01  -1.069602e-02  -4.875935e-01  -1.338805e-01  #>         f_j106         f_j107         f_j108         f_j109         f_j110  #>   4.273025e-01   5.379545e-02   3.651966e-01  -4.471073e-01   3.581969e-01  #>         f_j111         f_j112         f_j113         f_j114         f_j115  #>  -2.363343e-01  -3.598158e-01   4.146551e-01  -3.228591e-01  -7.668570e-03  #>         f_j116         f_j117         f_j118         f_j119         f_j120  #>   5.821080e-01   4.478373e-01  -2.423650e-01  -1.841927e-01  -5.696989e-02  #>         f_j121         f_j122         f_j123         f_j124         f_j125  #>  -3.312868e-01   5.672789e-01  -5.016086e-01   1.963290e-01  -5.896813e-02  #>         f_j126         f_j127         f_j128         f_j129         f_j130  #>  -2.668449e-01   1.934559e-01  -7.069197e-02   1.487082e-01  -4.156384e-01  #>         f_j131         f_j132         f_j133         f_j134         f_j135  #>  -3.035879e-01   1.487018e-01  -2.537371e-01   8.600796e-02   2.808255e-01  #>         f_j136         f_j137         f_j138         f_j139         f_j140  #>   2.139386e-01   2.741226e-01   4.600725e-02   6.629853e-02  -3.848296e-01  #>         f_j141         f_j142         f_j143         f_j144         f_j145  #>  -3.609607e-01  -4.580388e-01   2.411985e-01   5.876189e-01   2.563360e-01  #>         f_j146         f_j147         f_j148         f_j149         f_j150  #>   5.999405e-01  -1.518753e-01   8.369444e-02  -2.857929e-01  -3.697154e-01  #>         f_j151         f_j152         f_j153         f_j154         f_j155  #>  -8.485407e-02  -3.519104e-01   5.557219e-01  -2.304672e-01  -5.201529e-01  #>         f_j156         f_j157         f_j158         f_j159         f_j160  #>   6.290472e-01   2.500025e-01  -1.748695e-01  -1.066620e-01  -4.878426e-01  #>         f_j161         f_j162         f_j163         f_j164         f_j165  #>   5.509638e-01   3.281961e-01  -3.827043e-01   6.073153e-01  -3.797893e-01  #>         f_j166         f_j167         f_j168         f_j169         f_j170  #>   3.425536e-01  -4.916739e-01   2.194192e-01   2.159419e-01   1.480891e-01  #>         f_j171         f_j172         f_j173         f_j174         f_j175  #>   5.015089e-01  -3.475583e-01   4.626021e-01  -4.284760e-01   1.694648e-01  #>         f_j176         f_j177         f_j178         f_j179         f_j180  #>  -1.744059e-03   4.313754e-01   2.137441e-01  -2.429365e-01  -3.590415e-01  #>         f_j181         f_j182         f_j183         f_j184         f_j185  #>  -1.562685e-01  -4.895912e-01   1.418749e-01  -4.692466e-01   5.427964e-01  #>         f_j186         f_j187         f_j188         f_j189         f_j190  #>  -3.431726e-01   5.477686e-01  -1.418614e-01   3.545608e-01   1.900015e-01  #>         f_j191         f_j192         f_j193         f_j194         f_j195  #>   2.039799e-01   5.290709e-02  -2.458091e-01  -3.100213e-01  -1.508979e-01  #>         f_j196         f_j197         f_j198         f_j199         f_j200  #>  -3.493571e-01  -2.197984e-01  -4.479175e-01   8.018299e-02  -5.208270e-01  #>         f_j201         f_j202         f_j203         f_j204         f_j205  #>   4.680027e-02   1.279592e-02  -4.118792e-02   5.303648e-02   2.177169e-02  #>         f_j206         f_j207         f_j208         f_j209         f_j210  #>   6.162988e-02   2.681978e-02   2.175273e-03  -5.715551e-03   6.292454e-02  #>         f_j211         f_j212         f_j213         f_j214         f_j215  #>   4.539798e-02   1.292490e-02  -2.438377e-03  -5.024292e-02  -3.605321e-02  #>         f_j216         f_j217         f_j218         f_j219         f_j220  #>   4.270034e-02  -3.506045e-03  -2.919392e-03  -1.754997e-02  -3.357347e-02  #>         f_j221         f_j222         f_j223         f_j224         f_j225  #>   4.923791e-02  -1.275079e-02   5.711102e-02  -5.983778e-02  -1.401392e-01  #>         f_j226         f_j227         f_j228         f_j229         f_j230  #>   4.430688e-02   5.738915e-02   7.177873e-02   3.630835e-03   6.908686e-02  #>         f_j231         f_j232         f_j233         f_j234         f_j235  #>   7.053329e-02   6.805429e-02  -1.352606e-01   6.713425e-02   3.843074e-02  #>         f_j236         f_j237         f_j238         f_j239         f_j240  #>  -1.709503e-02   5.611307e-02  -2.225475e-02   7.208212e-05   5.869824e-02  #>         f_j241         f_j242         f_j243         f_j244         f_j245  #>   3.159638e-02   6.050307e-02  -1.382525e-01   4.556591e-02   3.416840e-02  #>         f_j246         f_j247         f_j248         f_j249         f_j250  #>   4.144189e-02  -6.703148e-02   7.180215e-02  -6.086902e-02   4.682029e-02  #>         f_j251         f_j252         f_j253         f_j254         f_j255  #>  -1.306620e-01  -7.520667e-02  -1.373847e-01   7.914209e-03   4.839113e-02  #>         f_j256         f_j257         f_j258         f_j259         f_j260  #>   5.096559e-02  -1.057167e-01  -1.134617e-01  -7.845069e-02   5.787978e-02  #>         f_j261         f_j262         f_j263         f_j264         f_j265  #>  -3.464109e-02  -9.086745e-02  -1.240114e-01  -7.628591e-02   4.603567e-02  #>         f_j266         f_j267         f_j268         f_j269         f_j270  #>   4.519459e-02   6.061627e-02   5.651794e-02   5.409951e-02  -9.540204e-02  #>         f_j271         f_j272         f_j273         f_j274         f_j275  #>   5.435055e-02   1.594741e-02  -7.902410e-03  -9.093276e-02   1.877592e-02  #>         f_j276         f_j277         f_j278         f_j279         f_j280  #>   4.977865e-02   4.846383e-02  -7.307506e-02   5.692034e-02  -5.873316e-02  #>         f_j281         f_j282         f_j283         f_j284         f_j285  #>  -3.713113e-02   2.504136e-02  -7.155930e-03   5.803859e-02  -6.879177e-02  #>         f_j286         f_j287         f_j288         f_j289         f_j290  #>  -1.869993e-02   2.605053e-02  -6.645597e-02   6.667880e-03   1.736252e-02  #>         f_j291         f_j292         f_j293         f_j294         f_j295  #>   6.649086e-02   1.658626e-02   7.173672e-02  -2.642314e-02  -1.384949e-01  #>         f_j296         f_j297         f_j298         f_j299         f_j300  #>  -7.735410e-03   5.309431e-02   4.862763e-02   6.965745e-02  -5.335790e-02  #>       theta_j1       theta_j2       theta_j3       theta_j4       theta_j5  #>   5.511964e-03  -3.547121e-02   5.177035e-02   5.622327e-02   2.648950e-02  #>       theta_j6       theta_j7       theta_j8       theta_j9      theta_j10  #>   1.484805e-02  -2.561068e-02  -3.145342e-02   1.618344e-02   4.609276e-02  #>      theta_j11      theta_j12      theta_j13      theta_j14      theta_j15  #>   6.918443e-02  -3.046492e-02  -3.372859e-02   3.616988e-02  -3.616866e-03  #>      theta_j16      theta_j17      theta_j18      theta_j19      theta_j20  #>   1.662726e-02  -1.830267e-02   1.085889e-02   1.566433e-02   2.737865e-02  #>      theta_j21      theta_j22      theta_j23      theta_j24    sigma_beta1  #>   1.666489e-02  -2.826058e-03  -6.770128e-02   2.566466e-02   1.000000e+03  #>    sigma_beta2    sigma_beta3    sigma_beta4    sigma_beta5 sigma_theta_j1  #>   3.598467e-01   3.598467e-01   3.598467e-01   3.598467e-01   1.055570e+00  #> sigma_theta_j2 sigma_theta_j3  #>   9.433258e-01   1.031847e+00   # WAIC: fit$WAIC #> [1] 378.1769  # MCMC diagnostics: plot(as.ts(fit$post.coefficients[,1:3]))   # Posterior predictive check: hist(apply(fit$post.pred, 1,            function(x) mean(x==0)), main = 'Proportion of Zeros', xlab=''); abline(v = mean(y==0), lwd=4, col ='blue')   # }"},{"path":"https://bking124.github.io/countSTAR/reference/bart_star.html","id":null,"dir":"Reference","previous_headings":"","what":"MCMC Algorithm for BART-STAR — bart_star","title":"MCMC Algorithm for BART-STAR — bart_star","text":"Run MCMC algorithm BART model count-valued responses using STAR. transformation can known (e.g., log sqrt) unknown (Box-Cox estimated nonparametrically) greater flexibility.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bart_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MCMC Algorithm for BART-STAR — bart_star","text":"","code":"bart_star(   y,   X,   X_test = NULL,   y_test = NULL,   transformation = \"np\",   y_max = Inf,   n.trees = 200,   sigest = NULL,   sigdf = 3,   sigquant = 0.9,   k = 2,   power = 2,   base = 0.95,   nsave = 1000,   nburn = 1000,   nskip = 0,   save_y_hat = FALSE,   verbose = TRUE )"},{"path":"https://bking124.github.io/countSTAR/reference/bart_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MCMC Algorithm for BART-STAR — bart_star","text":"y n x 1 vector observed counts X n x p matrix predictors X_test n0 x p matrix predictors test data y_test n0 x 1 vector test data responses (used computing log-predictive scores) transformation transformation use latent process; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) \"ispline\" (transformation modeled unknown, monotone function using -splines) y_max fixed known upper bound observations; default Inf n.trees number trees use BART; default 200 sigest positive numeric estimate residual standard deviation (see ?bart) sigdf degrees freedom error variance prior (see ?bart) sigquant quantile error variance prior rough estimate (sigest) placed . closer quantile 1, aggressive fit (see ?bart) k number prior standard deviations E(Y|x) = f(x) away +/- 0.5. response internally scaled range -0.5 0.5. bigger k , conservative fitting (see ?bart) power power parameter tree prior (see ?bart) base base parameter tree prior (see ?bart) nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw save_y_hat logical; TRUE, compute save posterior draws expected counts, E(y), may slow compute verbose logical; TRUE, print time remaining","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bart_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MCMC Algorithm for BART-STAR — bart_star","text":"list following elements: post.pred: draws posterior predictive distribution y post.sigma: draws posterior distribution sigma post.log.like.point: draws log-likelihood n observations WAIC: Widely-Applicable/Watanabe-Akaike Information Criterion p_waic: Effective number parameters based WAIC post.pred.test: draws posterior predictive distribution test points X_test (NULL X_test given) post.fitted.values.test: posterior draws conditional mean test points X_test (NULL X_test given) post.mu.test: draws conditional mean z_star test points X_test (NULL X_test given) post.log.pred.test: draws log-predictive distribution n0 test cases (NULL X_test given) fitted.values: posterior mean conditional expectation counts y (NULL save_y_hat=FALSE) post.fitted.values: posterior draws conditional mean counts y (NULL save_y_hat=FALSE) case transformation=\"ispline\", list also contains post.g: draws posterior distribution transformation g post.sigma.gamma: draws posterior distribution sigma.gamma, prior standard deviation transformation g() coefficients transformation=\"box-cox\", list also contains post.lambda: draws posterior distribution lambda","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bart_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MCMC Algorithm for BART-STAR — bart_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. , model (1) Bayesian additive regression tree (BART) model. Posterior predictive inference obtained via Gibbs sampler combines () latent data augmentation step (like probit regression) (ii) existing sampler continuous data model. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt', well version Box-Cox parameter inferred within MCMC sampler ('box-cox'). Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y. Third, transformation can modeled unknown, monotone function using -splines ('ispline'). Robust Adaptive Metropolis (RAM) sampler used drawing parameter transformation function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bart_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MCMC Algorithm for BART-STAR — bart_star","text":"","code":"# \\donttest{ # Simulate data with count-valued response y: sim_dat = simulate_nb_friedman(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # BART-STAR with log-transformation: fit_log = bart_star(y = y, X = X, transformation = 'log',                     save_y_hat = TRUE, nburn=1000, nskip=0) #> [1] \"Burn-In Period\" #> [1] \"Starting sampling\" #> [1] \"0 seconds remaining\" #> [1] \"Total time:  2 seconds\"  # Fitted values plot_fitted(y = sim_dat$Ey,             post_y = fit_log$post.fitted.values,             main = 'Fitted Values: BART-STAR-log')   # WAIC for BART-STAR-log: fit_log$WAIC #> [1] 382.4023  # MCMC diagnostics: plot(as.ts(fit_log$post.fitted.values[,1:10]))   # Posterior predictive check: hist(apply(fit_log$post.pred, 1,            function(x) mean(x==0)), main = 'Proportion of Zeros', xlab=''); abline(v = mean(y==0), lwd=4, col ='blue')   # BART-STAR with nonparametric transformation: fit = bart_star(y = y, X = X,                      transformation = 'np', save_y_hat = TRUE) #> [1] \"Burn-In Period\" #> [1] \"Starting sampling\" #> [1] \"0 seconds remaining\" #> [1] \"Total time:  4 seconds\"  # Fitted values plot_fitted(y = sim_dat$Ey,             post_y = fit$post.fitted.values,             main = 'Fitted Values: BART-STAR-np')   # WAIC for BART-STAR-np: fit$WAIC #> [1] 379.1259  # MCMC diagnostics: plot(as.ts(fit$post.fitted.values[,1:10]))   # Posterior predictive check: hist(apply(fit$post.pred, 1,            function(x) mean(x==0)), main = 'Proportion of Zeros', xlab=''); abline(v = mean(y==0), lwd=4, col ='blue')  # }"},{"path":"https://bking124.github.io/countSTAR/reference/bart_star_ispline.html","id":null,"dir":"Reference","previous_headings":"","what":"MCMC sampler for BART-STAR with a monotone spline model\nfor the transformation — bart_star_ispline","title":"MCMC sampler for BART-STAR with a monotone spline model\nfor the transformation — bart_star_ispline","text":"Run MCMC algorithm BART model count-valued responses using STAR. transformation modeled unknown, monotone function using -splines. Robust Adaptive Metropolis (RAM) sampler used drawing parameter transformation function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bart_star_ispline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MCMC sampler for BART-STAR with a monotone spline model\nfor the transformation — bart_star_ispline","text":"","code":"bart_star_ispline(   y,   X,   X_test = NULL,   y_test = NULL,   lambda_prior = 1/2,   y_max = Inf,   n.trees = 200,   sigest = NULL,   sigdf = 3,   sigquant = 0.9,   k = 2,   power = 2,   base = 0.95,   nsave = 1000,   nburn = 1000,   nskip = 0,   save_y_hat = FALSE,   target_acc_rate = 0.3,   adapt_rate = 0.75,   stop_adapt_perc = 0.5,   verbose = TRUE )"},{"path":"https://bking124.github.io/countSTAR/reference/bart_star_ispline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MCMC sampler for BART-STAR with a monotone spline model\nfor the transformation — bart_star_ispline","text":"y n x 1 vector observed counts X n x p matrix predictors X_test n0 x p matrix predictors test data y_test n0 x 1 vector test data responses (used computing log-predictive scores) lambda_prior prior mean transformation g() Box-Cox function parameter lambda_prior y_max fixed known upper bound observations; default Inf n.trees number trees use BART; default 200 sigest positive numeric estimate residual standard deviation (see ?bart) sigdf degrees freedom error variance prior (see ?bart) sigquant quantile error variance prior rough estimate (sigest) placed . closer quantile 1, aggresive fit (see ?bart) k number prior standard deviations E(Y|x) = f(x) away +/- 0.5. response internally scaled range -0.5 0.5. bigger k , conservative fitting (see ?bart) power power parameter tree prior (see ?bart) base base parameter tree prior (see ?bart) nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw save_y_hat logical; TRUE, compute save posterior draws expected counts, E(y), may slow compute target_acc_rate target acceptance rate (zero one) adapt_rate rate adaptation RAM sampler (zero one) stop_adapt_perc stop adapting proposal covariance stop_adapt_perc*nburn verbose logical; TRUE, print time remaining","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bart_star_ispline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MCMC sampler for BART-STAR with a monotone spline model\nfor the transformation — bart_star_ispline","text":"list following elements: fitted.values: posterior mean conditional expectation counts y post.fitted.values: posterior draws conditional mean counts y post.pred.test: draws posterior predictive distribution test points X_test post.fitted.values.test: posterior draws conditional mean test points X_test post.pred: draws posterior predictive distribution y post.sigma: draws posterior distribution sigma post.mu.test: draws conditional mean z_star test points post.log.like.point: draws log-likelihood n observations post.log.pred.test: draws log-predictive distribution n0 test cases WAIC: Widely-Applicable/Watanabe-Akaike Information Criterion p_waic: Effective number parameters based WAIC post.g: draws posterior distribution transformation g post.sigma.gamma: draws posterior distribution sigma.gamma, prior standard deviation transformation g coefficients","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star.html","id":null,"dir":"Reference","previous_headings":"","what":"STAR Bayesian Linear Regression — blm_star","title":"STAR Bayesian Linear Regression — blm_star","text":"Posterior inference STAR linear model","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"STAR Bayesian Linear Regression — blm_star","text":"","code":"blm_star(   y,   X,   X_test = NULL,   transformation = \"np\",   y_max = Inf,   prior = \"gprior\",   use_MCMC = TRUE,   nsave = 1000,   nburn = 1000,   nskip = 0,   psi = NULL,   compute_marg = FALSE )"},{"path":"https://bking124.github.io/countSTAR/reference/blm_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"STAR Bayesian Linear Regression — blm_star","text":"y n x 1 vector observed counts X n x p matrix predictors X_test n0 x p matrix predictors test data transformation transformation use latent process; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) \"ispline\" (transformation modeled unknown, monotone function using -splines) \"bnp\" (Bayesian nonparametric transformation using Bayesian bootstrap) y_max fixed known upper bound observations; default Inf prior prior use latent linear regression; currently implemented options \"gprior\", \"horseshoe\", \"ridge\" use_MCMC logical; whether run Gibbs sampler Monte Carlo (default TRUE) nsave number MCMC iterations save (MC samples draw use_MCMC=FALSE) nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw psi prior variance (g-prior) compute_marg logical; TRUE, compute return marginal likelihood (available using exact sampler, .e. use_MCMC=FALSE)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"STAR Bayesian Linear Regression — blm_star","text":"list least following elements: coefficients: posterior mean regression coefficients post.beta: posterior draws regression coefficients post.pred: draws posterior predictive distribution y post.log.like.point: draws log-likelihood n observations WAIC: Widely-Applicable/Watanabe-Akaike Information Criterion p_waic: Effective number parameters based WAIC test points passed , list also post.predtest, contains draws posterior predictive distribution test points. elements may present depending choice prior, transformation, sampling approach.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"STAR Bayesian Linear Regression — blm_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. , continuous latent data model linear regression. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt', well version Box-Cox parameter inferred within MCMC sampler ('box-cox'). Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y. distribution-based transformations approximately preserve mean variance count data y latent data scale, lends interpretability model parameters. Lastly, transformation can modeled using Bayesian bootstrap ('bnp'), Bayesian nonparametric model incorporates uncertainty transformation posterior predictive inference. Monte Carlo sampler (use_MCMC=FALSE) produces direct, discrete, joint draws posterior distribution posterior predictive distribution linear regression model g-prior.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"STAR Bayesian Linear Regression — blm_star","text":"'bnp' transformation slower transformations way TruncatedNormal sampler must updated lower upper limits change (due sampling g). Thus, computational improvements likely available.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"STAR Bayesian Linear Regression — blm_star","text":"","code":"# \\donttest{ # Simulate data with count-valued response y: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Fit the Bayesian STAR linear model: fit = blm_star(y = y, X = X) #> [1] \"Burn-In Period\" #> [1] \"Starting sampling\" #> [1] \"0 seconds remaining\" #> [1] \"Total time:  1 seconds\"  # What is included: names(fit) #> [1] \"coefficients\"        \"post.beta\"           \"post.pred\"           #> [4] \"post.sigma\"          \"post.log.like.point\" \"WAIC\"                #> [7] \"p_waic\"               # Posterior mean of each coefficient: coef(fit) #>       beta1       beta2       beta3       beta4       beta5  #>  0.08370276  0.29644099  0.41728039 -0.09148244 -0.06807578   # WAIC: fit$WAIC #> [1] 325.1182  # MCMC diagnostics: plot(as.ts(fit$post.beta))   # Posterior predictive check: hist(apply(fit$post.pred, 1,            function(x) mean(x==0)), main = 'Proportion of Zeros', xlab=''); abline(v = mean(y==0), lwd=4, col ='blue')   # }"},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_bnpgibbs.html","id":null,"dir":"Reference","previous_headings":"","what":"Gibbs sampler for STAR linear regression with BNP transformation — blm_star_bnpgibbs","title":"Gibbs sampler for STAR linear regression with BNP transformation — blm_star_bnpgibbs","text":"Compute MCMC samples posterior predictive distributions STAR linear regression model g-prior BNP transformation.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_bnpgibbs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gibbs sampler for STAR linear regression with BNP transformation — blm_star_bnpgibbs","text":"","code":"blm_star_bnpgibbs(   y,   X,   X_test = X,   y_max = Inf,   psi = NULL,   nsave = 1000,   nburn = 1000,   nskip = 0,   verbose = TRUE )"},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_bnpgibbs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gibbs sampler for STAR linear regression with BNP transformation — blm_star_bnpgibbs","text":"y n x 1 vector observed counts X n x p matrix predictors X_test n0 x p matrix predictors test data; default observed covariates X y_max fixed known upper bound observations; default Inf psi prior variance (g-prior) nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_bnpgibbs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gibbs sampler for STAR linear regression with BNP transformation — blm_star_bnpgibbs","text":"list following elements: coefficients: posterior mean regression coefficients post.beta: nsave x p samples posterior distribution regression coefficients post.pred: nsave x n0 samples posterior predictive distribution test points X_test post.g: nsave posterior samples transformation evaluated unique y values (applies 'bnp' transformations)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_exact.html","id":null,"dir":"Reference","previous_headings":"","what":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"Compute direct Monte Carlo samples posterior predictive distributions STAR linear regression model g-prior.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_exact.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"","code":"blm_star_exact(   y,   X,   X_test = X,   transformation = \"np\",   y_max = Inf,   psi = NULL,   nsave = 1000,   compute_marg = FALSE )"},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_exact.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"y n x 1 vector observed counts X n x p matrix predictors X_test n0 x p matrix predictors test data transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"bnp\" (Bayesian nonparametric transformation using Bayesian bootstrap) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) y_max fixed known upper bound observations; default Inf psi prior variance (g-prior) nsave number Monte Carlo simulations compute_marg logical; TRUE, compute return marginal likelihood","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_exact.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"list following elements: coefficients: posterior mean regression coefficients post.beta: nsave x p samples posterior distribution regression coefficients post.pred: draws posterior predictive distribution y post.pred.test: nsave x n0 samples posterior predictive distribution test points X_test (given, otherwise NULL) sigma: estimated latent data standard deviation post.g: nsave posterior samples transformation evaluated unique y values (applies 'bnp' transformations) marg.like: marginal likelihood (requested; otherwise NULL)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_exact.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. , continuous latent data model linear regression. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt'. Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y. distribution-based transformations approximately preserve mean variance count data y latent data scale, lends interpretability model parameters. Lastly, transformation can modeled using Bayesian bootstrap ('bnp'), Bayesian nonparametric model incorporates uncertainty transformation posterior predictive inference. Monte Carlo sampler produces direct, discrete, joint draws posterior distribution posterior predictive distribution linear regression model g-prior.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_exact.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"'bnp' transformation slower transformations way TruncatedNormal sampler must updated lower upper limits change (due sampling g). Thus, computational improvements likely available.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/computeTimeRemaining.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the remaining time in the MCMC based on previous samples — computeTimeRemaining","title":"Estimate the remaining time in the MCMC based on previous samples — computeTimeRemaining","text":"Estimate remaining time MCMC based previous samples","code":""},{"path":"https://bking124.github.io/countSTAR/reference/computeTimeRemaining.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the remaining time in the MCMC based on previous samples — computeTimeRemaining","text":"","code":"computeTimeRemaining(nsi, timer0, nsims, nrep = 1000)"},{"path":"https://bking124.github.io/countSTAR/reference/computeTimeRemaining.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the remaining time in the MCMC based on previous samples — computeTimeRemaining","text":"nsi Current iteration timer0 Initial timer value, returned proc.time()[3] nsims Total number simulations nrep Print estimated time remaining every nrep iterations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/computeTimeRemaining.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the remaining time in the MCMC based on previous samples — computeTimeRemaining","text":"Table summary statistics using function summary","code":""},{"path":"https://bking124.github.io/countSTAR/reference/confint.lmstar.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute asymptotic confidence intervals for STAR linear regression — confint.lmstar","title":"Compute asymptotic confidence intervals for STAR linear regression — confint.lmstar","text":"linear regression model within STAR framework, compute (asymptotic) confidence intervals regression coefficient interest. Confidence intervals computed inverting likelihood ratio test profiling log-likelihood.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/confint.lmstar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute asymptotic confidence intervals for STAR linear regression — confint.lmstar","text":"","code":"# S3 method for lmstar confint(object, parm, level = 0.95, ...)"},{"path":"https://bking124.github.io/countSTAR/reference/confint.lmstar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute asymptotic confidence intervals for STAR linear regression — confint.lmstar","text":"object Object class \"lmstar\" output lm_star parm specification parameters given confidence intervals, either vector numbers vector names. missing, parameters considered. level confidence level; default 0.95 ... Ignored","code":""},{"path":"https://bking124.github.io/countSTAR/reference/confint.lmstar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute asymptotic confidence intervals for STAR linear regression — confint.lmstar","text":"matrix (vector) columns giving lower upper confidence limits parameter. labelled (1-level)/2 1 - (1-level)/2 ","code":""},{"path":"https://bking124.github.io/countSTAR/reference/confint.lmstar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute asymptotic confidence intervals for STAR linear regression — confint.lmstar","text":"","code":"#Simulate data with count-valued response y: sim_dat = simulate_nb_lm(n = 100, p = 2) y = sim_dat$y; X = sim_dat$X[,-1] # remove intercept  # Select a transformation: transformation = 'np'  #Estimate model fit = lm_star(y~X, transformation = transformation)  #Confidence interval for all parameters confint(fit) #>                  2.5 %    97.5 % #> (Intercept) -0.1651785 0.1805371 #> X            0.3098616 0.6679353"},{"path":"https://bking124.github.io/countSTAR/reference/credBands.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Simultaneous Credible Bands — credBands","title":"Compute Simultaneous Credible Bands — credBands","text":"Compute (1-alpha)% credible BANDS function based MCMC samples using Crainiceanu et al. (2007)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/credBands.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Simultaneous Credible Bands — credBands","text":"","code":"credBands(sampFuns, alpha = 0.05)"},{"path":"https://bking124.github.io/countSTAR/reference/credBands.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Simultaneous Credible Bands — credBands","text":"sampFuns Nsims x m matrix Nsims MCMC samples m points along curve alpha confidence level","code":""},{"path":"https://bking124.github.io/countSTAR/reference/credBands.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Simultaneous Credible Bands — credBands","text":"m x 2 matrix credible bands; first column lower band, second upper band","code":""},{"path":"https://bking124.github.io/countSTAR/reference/credBands.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute Simultaneous Credible Bands — credBands","text":"input needs curves: simultaneous credible \"bands\" may computed vectors. resulting credible intervals provide joint coverage (1-alpha) level across components vector.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/ergMean.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the ergodic (running) mean. — ergMean","title":"Compute the ergodic (running) mean. — ergMean","text":"Compute ergodic (running) mean.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/ergMean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the ergodic (running) mean. — ergMean","text":"","code":"ergMean(x)"},{"path":"https://bking124.github.io/countSTAR/reference/ergMean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the ergodic (running) mean. — ergMean","text":"x vector compute running mean","code":""},{"path":"https://bking124.github.io/countSTAR/reference/ergMean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the ergodic (running) mean. — ergMean","text":"vector y element defined y[] = mean(x[1:])","code":""},{"path":"https://bking124.github.io/countSTAR/reference/ergMean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the ergodic (running) mean. — ergMean","text":"","code":"# Compare: ergMean(1:10) #>  [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 mean(1:10) #> [1] 5.5  # Running mean for iid N(5, 1) samples: x = rnorm(n = 10^4, mean = 5, sd = 1) plot(ergMean(x)) abline(h=5)"},{"path":"https://bking124.github.io/countSTAR/reference/expectation2_gRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute E(Y^2) for a STAR process — expectation2_gRcpp","title":"Compute E(Y^2) for a STAR process — expectation2_gRcpp","text":"Compute conditional expectation Y^2 STAR process Y generic link function g.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation2_gRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute E(Y^2) for a STAR process — expectation2_gRcpp","text":"","code":"expectation2_gRcpp(g_a_j, g_a_jp1, mu, sigma, Jmax)"},{"path":"https://bking124.github.io/countSTAR/reference/expectation2_gRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute E(Y^2) for a STAR process — expectation2_gRcpp","text":"g_a_j Jmax x 1 vector g((j)) g_a_jp1 Jmax x 1 vector g((j + 1)) mu m x 1 vector conditional expectations sigma m x 1 vector conditional standard deviations Jmax m x 1 vector maximum integer values consider","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation2_gRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute E(Y^2) for a STAR process — expectation2_gRcpp","text":"y2_hat m x 1 vector conditional expectations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation2_gRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute E(Y^2) for a STAR process — expectation2_gRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_gRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the mean for a STAR process — expectation_gRcpp","title":"Estimate the mean for a STAR process — expectation_gRcpp","text":"Estimate conditional expectation STAR process generic link function g.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_gRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the mean for a STAR process — expectation_gRcpp","text":"","code":"expectation_gRcpp(g_a_j, g_a_jp1, mu, sigma, Jmax)"},{"path":"https://bking124.github.io/countSTAR/reference/expectation_gRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the mean for a STAR process — expectation_gRcpp","text":"g_a_j Jmax x 1 vector g((j)) g_a_jp1 Jmax x 1 vector g((j + 1)) mu m x 1 vector conditional expectations sigma m x 1 vector conditional standard deviations Jmax m x 1 vector maximum integer values consider","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_gRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the mean for a STAR process — expectation_gRcpp","text":"y_hat m x 1 vector conditional expectations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_gRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimate the mean for a STAR process — expectation_gRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_identity.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the mean for a STAR process — expectation_identity","title":"Estimate the mean for a STAR process — expectation_identity","text":"Estimate conditional expectation STAR process identity link function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_identity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the mean for a STAR process — expectation_identity","text":"","code":"expectation_identity(a, Jmax, Mu, sigma_t, Offset)"},{"path":"https://bking124.github.io/countSTAR/reference/expectation_identity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the mean for a STAR process — expectation_identity","text":"Jmaxmax-dimensional vector STAR integers a_j Jmax T x m matrix maximum integer values consider Mu T x m matrix latent means sigma_t T-dimensional vector time-dependent latent error sd's Offset T x m matrix offsets","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_identity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the mean for a STAR process — expectation_identity","text":"Zhat T x m matrix conditional expectations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_identity.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimate the mean for a STAR process — expectation_identity","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_log.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the mean for a STAR process — expectation_log","title":"Estimate the mean for a STAR process — expectation_log","text":"Estimate conditional expectation STAR process log link function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the mean for a STAR process — expectation_log","text":"","code":"expectation_log(a, Jmax, Mu, sigma_t, Offset)"},{"path":"https://bking124.github.io/countSTAR/reference/expectation_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the mean for a STAR process — expectation_log","text":"Jmaxmax-dimensional vector STAR integers a_j Jmax T x m matrix maximum integer values consider Mu T x m matrix latent means sigma_t T-dimensional vector time-dependent latent error sd's Offset T x m matrix offsets","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_log.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the mean for a STAR process — expectation_log","text":"Zhat T x m matrix conditional expectations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_log.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimate the mean for a STAR process — expectation_log","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_sqrt.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the mean for a STAR process — expectation_sqrt","title":"Estimate the mean for a STAR process — expectation_sqrt","text":"Estimate conditional expectation STAR process square root link function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_sqrt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the mean for a STAR process — expectation_sqrt","text":"","code":"expectation_sqrt(a, Jmax, Mu, sigma_t, Offset)"},{"path":"https://bking124.github.io/countSTAR/reference/expectation_sqrt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the mean for a STAR process — expectation_sqrt","text":"Jmaxmax-dimensional vector STAR integers a_j Jmax T x m matrix maximum integer values consider Mu T x m matrix latent means sigma_t T-dimensional vector time-dependent latent error sd's Offset T x m matrix offsets","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_sqrt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the mean for a STAR process — expectation_sqrt","text":"Zhat T x m matrix conditional expectations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_sqrt.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimate the mean for a STAR process — expectation_sqrt","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_bc.html","id":null,"dir":"Reference","previous_headings":"","what":"Box-Cox transformation — g_bc","title":"Box-Cox transformation — g_bc","text":"Evaluate Box-Cox transformation, scaled power transformation preserve continuity index lambda zero. Negative values permitted.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_bc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Box-Cox transformation — g_bc","text":"","code":"g_bc(t, lambda)"},{"path":"https://bking124.github.io/countSTAR/reference/g_bc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Box-Cox transformation — g_bc","text":"t argument(s) evaluate function lambda Box-Cox parameter","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_bc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Box-Cox transformation — g_bc","text":"evaluation(s) Box-Cox function given input(s) t.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_bc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Box-Cox transformation — g_bc","text":"Special cases include identity transformation (lambda = 1), square-root transformation (lambda = 1/2), log transformation (lambda = 0).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_bc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Box-Cox transformation — g_bc","text":"","code":"# Log-transformation: g_bc(1:5, lambda = 0); log(1:5) #> [1] 0.0000000 0.6931472 1.0986123 1.3862944 1.6094379 #> [1] 0.0000000 0.6931472 1.0986123 1.3862944 1.6094379  # Square-root transformation: note the shift and scaling g_bc(1:5, lambda = 1/2); sqrt(1:5) #> [1] 0.0000000 0.8284271 1.4641016 2.0000000 2.4721360 #> [1] 1.000000 1.414214 1.732051 2.000000 2.236068"},{"path":"https://bking124.github.io/countSTAR/reference/g_bnp.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian bootstrap-based transformation — g_bnp","title":"Bayesian bootstrap-based transformation — g_bnp","text":"Compute one posterior draw smoothed transformation implied (separate) Bayesian bootstrap models CDFs y X.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_bnp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian bootstrap-based transformation — g_bnp","text":"","code":"g_bnp(y, xt_Sigma_x = rep(0, length(y)), z_grid = NULL)"},{"path":"https://bking124.github.io/countSTAR/reference/g_bnp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian bootstrap-based transformation — g_bnp","text":"y n x 1 vector observed counts xt_Sigma_x n x 1 vector t(X_i) Sigma_theta X_i, Sigma_theta prior variance z_grid optional vector grid points evaluating CDF z (Fz)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_bnp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian bootstrap-based transformation — g_bnp","text":"smooth monotone function can used evaluations transformation posterior draw.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_bnp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian bootstrap-based transformation — g_bnp","text":"","code":"# \\donttest{ # Sample some data: y = rpois(n = 200, lambda = 5) # Compute 100 draws of g on a grid: t = seq(0, max(y), length.out = 50) # grid g_post = t(sapply(1:100, function(s) g_bnp(y)(t))) # Plot together: plot(t, t, ylim = range(g_post), type='n', ylab = 'g(t)',  main = 'Bayesian bootstrap posterior: g') temp = apply(g_post, 1, function(g) lines(t, g, col='gray')) # And the posterior mean of g: lines(t, colMeans(g_post), lwd=3)  # }"},{"path":"https://bking124.github.io/countSTAR/reference/g_cdf.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative distribution function (CDF)-based transformation — g_cdf","title":"Cumulative distribution function (CDF)-based transformation — g_cdf","text":"Compute CDF-based transformation using observed count data. CDF can estimated nonparametrically parametrically based Poisson Negative Binomial distributions. parametric case, parameters determined based moments y. Note fixed quantity come uncertainty quantification.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_cdf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative distribution function (CDF)-based transformation — g_cdf","text":"","code":"g_cdf(y, distribution = \"np\")"},{"path":"https://bking124.github.io/countSTAR/reference/g_cdf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative distribution function (CDF)-based transformation — g_cdf","text":"y n x 1 vector observed counts distribution distribution used CDF; must one \"np\" (empirical CDF) \"pois\" (moment-matched marginal Poisson CDF) \"neg-bin\" (moment-matched marginal Negative Binomial CDF)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_cdf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative distribution function (CDF)-based transformation — g_cdf","text":"smooth monotone function can used evaluations transformation.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_cdf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative distribution function (CDF)-based transformation — g_cdf","text":"","code":"# Sample some data: y = rpois(n = 500, lambda = 5)  # Empirical CDF version: g_np = g_cdf(y, distribution = 'np')  # Poisson version: g_pois = g_cdf(y, distribution = 'pois')  # Negative binomial version: g_negbin = g_cdf(y, distribution = 'neg-bin') #> Warning: 'neg-bin' not recommended for underdispersed data  # Plot together: t = 1:max(y) # grid plot(t, g_np(t), type='l') lines(t, g_pois(t), lty = 2) lines(t, g_negbin(t), lty = 3)"},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_approx.html","id":null,"dir":"Reference","previous_headings":"","what":"Approximate inverse transformation — g_inv_approx","title":"Approximate inverse transformation — g_inv_approx","text":"Compute inverse function transformation g based grid search.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_approx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Approximate inverse transformation — g_inv_approx","text":"","code":"g_inv_approx(g, t_grid)"},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_approx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Approximate inverse transformation — g_inv_approx","text":"g transformation function t_grid grid arguments evaluate transformation function","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_approx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Approximate inverse transformation — g_inv_approx","text":"function can used evaluations (approximate) inverse transformation function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_approx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Approximate inverse transformation — g_inv_approx","text":"","code":"# Sample some data: y = rpois(n = 500, lambda = 5)  # Empirical CDF transformation: g_np = g_cdf(y, distribution = 'np')  # Grid for approximation: t_grid = seq(1, max(y), length.out = 100)  # Approximate inverse: g_inv = g_inv_approx(g = g_np, t_grid = t_grid)  # Check the approximation: plot(t_grid, g_inv(g_np(t_grid)), type='p') lines(t_grid, t_grid)"},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_bc.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse Box-Cox transformation — g_inv_bc","title":"Inverse Box-Cox transformation — g_inv_bc","text":"Evaluate inverse Box-Cox transformation. Negative values permitted.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_bc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse Box-Cox transformation — g_inv_bc","text":"","code":"g_inv_bc(s, lambda)"},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_bc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse Box-Cox transformation — g_inv_bc","text":"s argument(s) evaluate function lambda Box-Cox parameter","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_bc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse Box-Cox transformation — g_inv_bc","text":"evaluation(s) inverse Box-Cox function given input(s) s.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_bc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Inverse Box-Cox transformation — g_inv_bc","text":"Special cases include identity transformation (lambda = 1), square-root transformation (lambda = 1/2), log transformation (lambda = 0). #' @examples # (Inverse) log-transformation: g_inv_bc(1:5, lambda = 0); exp(1:5) # (Inverse) square-root transformation: note shift scaling g_inv_bc(1:5, lambda = 1/2); (1:5)^2","code":""},{"path":"https://bking124.github.io/countSTAR/reference/gbm_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"Compute MLEs log-likelihood Gradient Boosting Machines (GBM) STAR model. STAR model requires *transformation* *estimation function* conditional mean given observed data. transformation can known (e.g., log sqrt) unknown (Box-Cox estimated nonparametrically) greater flexibility. estimator case GBM. Standard function calls including fitted residuals apply.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/gbm_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"","code":"gbm_star(   y,   X,   X.test = NULL,   transformation = \"np\",   y_max = Inf,   sd_init = 10,   tol = 10^-10,   max_iters = 1000,   n.trees = 100,   interaction.depth = 1,   shrinkage = 0.1,   bag.fraction = 1 )"},{"path":"https://bking124.github.io/countSTAR/reference/gbm_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"y n x 1 vector observed counts X n x p matrix predictors X.test m x p matrix --sample predictors transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) y_max fixed known upper bound observations; default Inf sd_init add random noise EM algorithm initialization scaled sd_init times Gaussian MLE standard deviation; default 10 tol tolerance stopping EM algorithm; default 10^-10; max_iters maximum number EM iterations stopping; default 1000 n.trees Integer specifying total number trees fit. equivalent number iterations number basis functions additive expansion. Default 100. interaction.depth Integer specifying maximum depth tree (.e., highest level variable interactions allowed). value 1 implies additive model, value 2 implies model 2-way interactions, etc. Default 1. shrinkage shrinkage parameter applied tree expansion. Also known learning rate step-size reduction; 0.001 0.1 usually work, smaller learning rate typically requires trees. Default 0.1. bag.fraction fraction training set observations randomly selected propose next tree expansion. introduces randomnesses model fit. bag.fraction < 1 running model twice result similar different fits. Default 1 (deterministic prediction).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/gbm_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"list following elements: fitted.values: fitted values MLEs (training) fitted.values.test: fitted values MLEs (testing) g.hat function containing (known estimated) transformation sigma.hat MLE standard deviation mu.hat MLE conditional mean (transformed scale) z.hat estimated latent data (transformed scale) MLEs residuals Dunn-Smyth residuals (randomized) residuals_rep Dunn-Smyth residuals (randomized) 10 replicates logLik log-likelihood MLEs logLik0 log-likelihood MLEs *unrounded* initialization lambda Box-Cox nonlinear parameter gbmObj: object returned gbm() MLEs parameters (1) track parameters across EM iterations (2) record model specifications","code":""},{"path":"https://bking124.github.io/countSTAR/reference/gbm_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. Gaussian model case GBM.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/gbm_star.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"Infinite latent data values may occur transformed Gaussian model highly inadequate. case, function returns *indices* data points infinite latent values, significant outliers model. Deletion indices re-running model one option, care must taken ensure () appropriate treat observations outliers (ii) model adequate remaining data points.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/gbm_star.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"Kowal, D. R., & Wu, B. (2021). Semiparametric count data regression self‐reported mental health. Biometrics. doi:10.1111/biom.13617","code":""},{"path":"https://bking124.github.io/countSTAR/reference/gbm_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"","code":"# Simulate data with count-valued response y: sim_dat = simulate_nb_friedman(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # EM algorithm for STAR (using the log-link) fit_em = gbm_star(y = y, X = X,                  transformation = 'log')  # Evaluate convergence: plot(fit_em$logLik_all, type='l', main = 'GBM-STAR-log', xlab = 'Iteration', ylab = 'log-lik')   # Fitted values: y_hat = fitted(fit_em) plot(y_hat, y);   # Residuals: plot(residuals(fit_em))  qqnorm(residuals(fit_em)); qqline(residuals(fit_em))   # Log-likelihood at MLEs: fit_em$logLik #> [1] -181.3181"},{"path":"https://bking124.github.io/countSTAR/reference/genEM_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized EM estimation for STAR — genEM_star","title":"Generalized EM estimation for STAR — genEM_star","text":"Compute MLEs log-likelihood generalized STAR model. STAR model requires *transformation* *estimation function* conditional mean given observed data. transformation can known (e.g., log sqrt) unknown (Box-Cox estimated nonparametrically) greater flexibility. estimator can least squares estimator, including nonlinear models. Standard function calls including coefficients(), fitted(), residuals() apply.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genEM_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized EM estimation for STAR — genEM_star","text":"","code":"genEM_star(   y,   estimator,   transformation = \"np\",   y_max = Inf,   sd_init = 10,   tol = 10^-10,   max_iters = 1000 )"},{"path":"https://bking124.github.io/countSTAR/reference/genEM_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized EM estimation for STAR — genEM_star","text":"y n x 1 vector observed counts estimator function inputs data y outputs list two elements: fitted values fitted.values parameter estimates coefficients transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) y_max fixed known upper bound observations; default Inf sd_init add random noise EM algorithm initialization scaled sd_init times Gaussian MLE standard deviation; default 10 tol tolerance stopping EM algorithm; default 10^-10; max_iters maximum number EM iterations stopping; default 1000","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genEM_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized EM estimation for STAR — genEM_star","text":"list following elements: coefficients MLEs coefficients fitted.values fitted values MLEs g.hat function containing (known estimated) transformation sigma.hat MLE standard deviation mu.hat MLE conditional mean (transformed scale) z.hat estimated latent data (transformed scale) MLEs residuals Dunn-Smyth residuals (randomized) residuals_rep Dunn-Smyth residuals (randomized) 10 replicates logLik log-likelihood MLEs logLik0 log-likelihood MLEs *unrounded* initialization lambda Box-Cox nonlinear parameter parameters (1) track parameters across EM iterations (2) record model specifications","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genEM_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized EM estimation for STAR — genEM_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. expectation-maximization (EM) algorithm used produce maximum likelihood estimators (MLEs) parameters defined estimator function, linear regression coefficients, define Gaussian model continuous latent data. Fitted values (point predictions), residuals, log-likelihood values also available. Inference estimators proceeds via classical maximum likelihood. Initialization EM algorithm can randomized monitor convergence. However, log-likelihood concave transformations (except 'box-cox'), global convergence guaranteed. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt', well version Box-Cox parameter estimated within EM algorithm ('box-cox'). Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genEM_star.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Generalized EM estimation for STAR — genEM_star","text":"Infinite latent data values may occur transformed Gaussian model highly inadequate. case, function returns *indices* data points infinite latent values, significant outliers model. Deletion indices re-running model one option, care must taken ensure () appropriate treat observations outliers (ii) model adequate remaining data points.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genEM_star.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized EM estimation for STAR — genEM_star","text":"Kowal, D. R., & Wu, B. (2021). Semiparametric count data regression self‐reported mental health. Biometrics. doi:10.1111/biom.13617","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genEM_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized EM estimation for STAR — genEM_star","text":"","code":"# Simulate data with count-valued response y: sim_dat = simulate_nb_friedman(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Select a transformation: transformation = 'np'  # Example using GAM as underlying estimator (for illustration purposes only) if(require(\"mgcv\")){   fit_em = genEM_star(y = y,                       estimator = function(y) gam(y ~ s(X1)+s(X2),                       data=data.frame(y,X)),                       transformation = transformation) } #> Loading required package: mgcv #> Loading required package: nlme #> This is mgcv 1.8-42. For overview type 'help(\"mgcv-package\")'.  # Fitted coefficients: coef(fit_em) #>   (Intercept)       s(X1).1       s(X1).2       s(X1).3       s(X1).4  #> -2.214839e-03  4.072969e-02 -4.502402e-02  5.620972e-02  8.691034e-02  #>       s(X1).5       s(X1).6       s(X1).7       s(X1).8       s(X1).9  #>  1.817052e-02  9.741752e-02  3.576770e-02  5.285201e-01  2.367366e-01  #>       s(X2).1       s(X2).2       s(X2).3       s(X2).4       s(X2).5  #>  2.944182e-11 -2.155302e-11 -5.705282e-12  2.942153e-11  2.815270e-13  #>       s(X2).6       s(X2).7       s(X2).8       s(X2).9  #>  2.585049e-11  9.712464e-12  1.335680e-10  1.167171e-01   # Fitted values: y_hat = fitted(fit_em) plot(y_hat, y);   # Log-likelihood at MLEs: fit_em$logLik #> [1] -215.6038"},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized MCMC Algorithm for STAR — genMCMC_star","title":"Generalized MCMC Algorithm for STAR — genMCMC_star","text":"Run MCMC algorithm STAR given function initialize model parameters; function sample (.e., update) model parameters. transformation can known (e.g., log sqrt) unknown (Box-Cox estimated nonparametrically) greater flexibility.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized MCMC Algorithm for STAR — genMCMC_star","text":"","code":"genMCMC_star(   y,   sample_params,   init_params,   transformation = \"np\",   y_max = Inf,   nsave = 1000,   nburn = 1000,   nskip = 0,   save_y_hat = FALSE,   verbose = TRUE )"},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized MCMC Algorithm for STAR — genMCMC_star","text":"y n x 1 vector observed counts sample_params function inputs data y named list params containing mu: n x 1 vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu outputs updated list params samples full conditional posterior distribution coefficients sigma (updates mu) init_params initializing function inputs data y initializes named list params mu, sigma, coefficients transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) y_max fixed known upper bound observations; default Inf nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw save_y_hat logical; TRUE, compute save posterior draws expected counts, E(y), may slow compute verbose logical; TRUE, print time remaining","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized MCMC Algorithm for STAR — genMCMC_star","text":"list least following elements: post.pred: draws posterior predictive distribution y post.sigma: draws posterior distribution sigma post.log.like.point: draws log-likelihood n observations WAIC: Widely-Applicable/Watanabe-Akaike Information Criterion p_waic: Effective number parameters based WAIC post.lambda: draws posterior distribution lambda (NULL unless transformation='box-cox') fitted.values: posterior mean conditional expectation counts y (NULL save_y_hat=FALSE) post.fitted.values: posterior draws conditional mean counts y (NULL save_y_hat=FALSE) coefficients list init_params sample_params contains named element beta, e.g. linear regression, function output contains coefficients: posterior mean beta coefficients post.beta: draws posterior distribution beta post.othercoefs: draws posterior distribution sampled coefficients, e.g. variance terms beta exists parameter coefficients, output list just contains coefficients: posterior mean coefficients post.beta: draws posterior distribution coefficients Additionally, init_params sample_params output mu_test, sampler output post.predtest, contains draws posterior predictive distribution test points.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized MCMC Algorithm for STAR — genMCMC_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. Posterior predictive inference obtained via Gibbs sampler combines () latent data augmentation step (like probit regression) (ii) existing sampler continuous data model. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt', well version Box-Cox parameter inferred within MCMC sampler ('box-cox'). Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized MCMC Algorithm for STAR — genMCMC_star","text":"","code":"# Simulate data with count-valued response y: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # STAR: log-transformation: fit_log = genMCMC_star(y = y,                          sample_params = function(y, params) sample_lm_gprior(y, X, params),                          init_params = function(y) init_lm_gprior(y, X),                          transformation = 'log') #> [1] \"Burn-In Period\" #> [1] \"Starting sampling\" #> [1] \"0 seconds remaining\" #> [1] \"Total time:  0 seconds\"  # What is included: names(fit_log) #>  [1] \"coefficients\"        \"post.beta\"           \"post.othercoefs\"     #>  [4] \"post.pred\"           \"post.predtest\"       \"post.sigma\"          #>  [7] \"post.log.like.point\" \"WAIC\"                \"p_waic\"              #> [10] \"post.lambda\"         \"fitted.values\"       \"post.fitted.values\"   # Posterior mean of each coefficient: coef(fit_log) #>        beta1        beta2        beta3        beta4        beta5  #>  0.240239425  0.623564718  0.588955162 -0.029877031 -0.002942044   # WAIC for STAR-log: fit_log$WAIC #> [1] 377.8431  # MCMC diagnostics: plot(as.ts(fit_log$post.beta[,1:3]))   # Posterior predictive check: hist(apply(fit_log$post.pred, 1,            function(x) mean(x==0)), main = 'Proportion of Zeros', xlab=''); abline(v = mean(y==0), lwd=4, col ='blue')"},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star_ispline.html","id":null,"dir":"Reference","previous_headings":"","what":"MCMC sampler for STAR with a monotone spline model\nfor the transformation — genMCMC_star_ispline","title":"MCMC sampler for STAR with a monotone spline model\nfor the transformation — genMCMC_star_ispline","text":"Run MCMC algorithm STAR given function initialize model parameters; function sample (.e., update) model parameters. transformation modeled unknown, monotone function using -splines. Robust Adaptive Metropolis (RAM) sampler used drawing parameter transformation function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star_ispline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MCMC sampler for STAR with a monotone spline model\nfor the transformation — genMCMC_star_ispline","text":"","code":"genMCMC_star_ispline(   y,   sample_params,   init_params,   lambda_prior = 1/2,   y_max = Inf,   nsave = 1000,   nburn = 1000,   nskip = 0,   save_y_hat = FALSE,   target_acc_rate = 0.3,   adapt_rate = 0.75,   stop_adapt_perc = 0.5,   verbose = TRUE )"},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star_ispline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MCMC sampler for STAR with a monotone spline model\nfor the transformation — genMCMC_star_ispline","text":"y n x 1 vector observed counts sample_params function inputs data y named list params containing least mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu optionally fourth element mu_test contains vector conditional means test points. output updated list params samples full conditional posterior distribution coefficients sigma (along updates mu mu_test applicable) init_params initializing function inputs data y initializes named list params mu, sigma, coefficients mu_test (desired) lambda_prior prior mean transformation g() Box-Cox function parameter lambda_prior y_max fixed known upper bound observations; default Inf nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw save_y_hat logical; TRUE, compute save posterior draws expected counts, E(y), may slow compute target_acc_rate target acceptance rate (zero one) adapt_rate rate adaptation RAM sampler (zero one) stop_adapt_perc stop adapting proposal covariance stop_adapt_perc*nburn verbose logical; TRUE, print time remaining","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star_ispline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MCMC sampler for STAR with a monotone spline model\nfor the transformation — genMCMC_star_ispline","text":"list least following elements: post.pred: draws posterior predictive distribution y post.sigma: draws posterior distribution sigma post.log.like.point: draws log-likelihood n observations WAIC: Widely-Applicable/Watanabe-Akaike Information Criterion p_waic: Effective number parameters based WAIC post.g: draws posterior distribution transformation g post.sigma.gamma: draws posterior distribution sigma.gamma, prior standard deviation transformation g() coefficients fitted.values: posterior mean conditional expectation counts y (NULL save_y_hat=FALSE) post.fitted.values: posterior draws conditional mean counts y (NULL save_y_hat=FALSE) along elements depending nature initialization sampling functions. See details info.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star_ispline.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MCMC sampler for STAR with a monotone spline model\nfor the transformation — genMCMC_star_ispline","text":"coefficients list init_params sample_params contains named element beta, e.g. linear regression, function output contains coefficients: posterior mean beta coefficients post.beta: draws posterior distribution beta post.othercoefs: draws posterior distribution sampled coefficients, e.g. variance terms beta exists parameter coefficients, output list just contains coefficients: posterior mean coefficients post.beta: draws posterior distribution coefficients Additionally, init_params sample_params output mu_test, sampler output post.predtest, contains draws posterior predictive distribution test points.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/getEffSize.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize of effective sample size — getEffSize","title":"Summarize of effective sample size — getEffSize","text":"Compute summary statistics effective sample size (ESS) across posterior samples possibly many variables","code":""},{"path":"https://bking124.github.io/countSTAR/reference/getEffSize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize of effective sample size — getEffSize","text":"","code":"getEffSize(postX)"},{"path":"https://bking124.github.io/countSTAR/reference/getEffSize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize of effective sample size — getEffSize","text":"postX array arbitrary dimension (nsims x ... x ...), nsims number posterior samples","code":""},{"path":"https://bking124.github.io/countSTAR/reference/getEffSize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize of effective sample size — getEffSize","text":"Table summary statistics using function summary().","code":""},{"path":"https://bking124.github.io/countSTAR/reference/getEffSize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize of effective sample size — getEffSize","text":"","code":"# ESS for iid simulations: rand_iid = rnorm(n = 10^4) getEffSize(rand_iid) #>  var1  #> 10000   # ESS for several AR(1) simulations with coefficients 0.1, 0.2,...,0.9: rand_ar1 = sapply(seq(0.1, 0.9, by = 0.1), function(x) arima.sim(n = 10^4, list(ar = x))) getEffSize(rand_ar1) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   521.8  1754.2  3259.4  3764.2  5785.7  8142.5"},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_orthog.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize the parameters for an additive model — init_bam_orthog","title":"Initialize the parameters for an additive model — init_bam_orthog","text":"Initialize parameters additive model, may contain linear nonlinear predictors. nonlinear terms modeled using orthogonalized splines.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_orthog.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize the parameters for an additive model — init_bam_orthog","text":"","code":"init_bam_orthog(y, X_lin, X_nonlin, B_all = NULL)"},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_orthog.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize the parameters for an additive model — init_bam_orthog","text":"y n x 1 vector data X_lin n x pL matrix predictors modelled linear X_nonlin n x pNL matrix predictors modelled nonlinear B_all optional pNL-dimensional list n x L[j] dimensional basis matrices nonlinear term j=1,...,pNL; NULL, compute internally","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_orthog.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize the parameters for an additive model — init_bam_orthog","text":"named list params containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_orthog.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize the parameters for an additive model — init_bam_orthog","text":"parameters coefficients : beta_lin: p x 1 linear coefficients, including linear terms X_nonlin f_j: n x pNL matrix fitted values nonlinear function theta_j: pNL-dimensional nonlinear basis coefficients sigma_beta: p x 1 vector linear regression coefficient standard deviations sigma_theta_j: pNL x 1 vector nonlinear coefficient standard deviations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_thin.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize the parameters for an additive model — init_bam_thin","title":"Initialize the parameters for an additive model — init_bam_thin","text":"Initialize parameters additive model, may contain linear nonlinear predictors. nonlinear terms modeled using low-rank thin plate splines.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_thin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize the parameters for an additive model — init_bam_thin","text":"","code":"init_bam_thin(y, X_lin, X_nonlin, B_all = NULL)"},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_thin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize the parameters for an additive model — init_bam_thin","text":"y n x 1 vector data X_lin n x pL matrix predictors modelled linear X_nonlin n x pNL matrix predictors modelled nonlinear B_all optional pNL-dimensional list n x L[j] dimensional basis matrices nonlinear term j=1,...,pNL; NULL, compute internally","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_thin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize the parameters for an additive model — init_bam_thin","text":"named list params containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_thin.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize the parameters for an additive model — init_bam_thin","text":"parameters coefficients : beta_lin: p x 1 linear coefficients, including linear terms X_nonlin f_j: n x pNL matrix fitted values nonlinear function theta_j: pNL-dimensional nonlinear basis coefficients sigma_beta: p x 1 vector linear regression coefficient standard deviations sigma_theta_j: pNL x 1 vector nonlinear coefficient standard deviations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_gprior.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","title":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","text":"Initialize parameters linear regression model assuming g-prior coefficients.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_gprior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","text":"","code":"init_lm_gprior(y, X, X_test = NULL)"},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_gprior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","text":"y n x 1 vector data X n x p matrix predictors X_test n0 x p matrix predictors test points (default NULL)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_gprior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","text":"named list params containing least mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu Additionally, X_test NULL, list includes element mu_test, vector conditional means test points","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_gprior.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","text":"parameters coefficients : beta: p x 1 vector regression coefficients components beta","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_gprior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","text":"","code":"# Simulate data for illustration: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Initialize: params = init_lm_gprior(y = y, X = X) names(params) #> [1] \"mu\"           \"sigma\"        \"coefficients\" names(params$coefficients) #> [1] \"beta\""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_hs.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","title":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","text":"Initialize parameters linear regression model assuming horseshoe prior (non-intercept) coefficients. number predictors p may exceed number observations n.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_hs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","text":"","code":"init_lm_hs(y, X, X_test = NULL)"},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_hs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","text":"y n x 1 vector data X n x p matrix predictors X_test n0 x p matrix predictors test points (default NULL)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_hs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","text":"named list params containing least mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu Additionally, X_test NULL, list includes element mu_test, vector conditional means test points","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_hs.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","text":"parameters coefficients : beta: p x 1 vector regression coefficients sigma_beta: p x 1 vector regression coefficient standard deviations (local scale parameters) xi_sigma_beta: p x 1 vector parameter-expansion variables sigma_beta lambda_beta: global scale parameter xi_lambda_beta: parameter-expansion variable lambda_beta components beta","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_ridge.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","title":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","text":"Initialize parameters linear regression model assuming ridge prior (non-intercept) coefficients. number predictors p may exceed number observations n.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_ridge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","text":"","code":"init_lm_ridge(y, X, X_test = NULL)"},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_ridge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","text":"y n x 1 vector data X n x p matrix predictors X_test n0 x p matrix predictors test points (default NULL)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_ridge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","text":"named list params containing least mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu Additionally, X_test NULL, list includes element mu_test, vector conditional means test points","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_ridge.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","text":"parameters coefficients : beta: p x 1 vector regression coefficients sigma_beta: prior standard deviation (non-intercept) components beta","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_params_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize the parameters for a simple mean-only model — init_params_mean","title":"Initialize the parameters for a simple mean-only model — init_params_mean","text":"Initialize parameters model y ~ N(mu0, sigma^2) flat prior mu0.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_params_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize the parameters for a simple mean-only model — init_params_mean","text":"","code":"init_params_mean(y)"},{"path":"https://bking124.github.io/countSTAR/reference/init_params_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize the parameters for a simple mean-only model — init_params_mean","text":"y n x 1 vector data","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_params_mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize the parameters for a simple mean-only model — init_params_mean","text":"named list params containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_params_mean.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize the parameters for a simple mean-only model — init_params_mean","text":"parameter coefficients mu0. Although redundant , parametrization useful functions.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/interval_gRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate confidence intervals/bands for a STAR process — interval_gRcpp","title":"Estimate confidence intervals/bands for a STAR process — interval_gRcpp","text":"Compute confidence intervals/bands expected value count-valued STAR process y based intervals/bands Gaussian process mu.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/interval_gRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate confidence intervals/bands for a STAR process — interval_gRcpp","text":"","code":"interval_gRcpp(g_a_j, g_a_jp1, L_mu, U_mu, sigma, Jmax)"},{"path":"https://bking124.github.io/countSTAR/reference/interval_gRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate confidence intervals/bands for a STAR process — interval_gRcpp","text":"g_a_j Jmax x 1 vector g((j)) g_a_jp1 Jmax x 1 vector g((j + 1)) L_mu m x 1 vector lower intervals mu U_mu m x 1 vector upper intervals mu sigma m x 1 vector conditional standard deviations Jmax m x 1 vector maximum integer values consider","code":""},{"path":"https://bking124.github.io/countSTAR/reference/interval_gRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate confidence intervals/bands for a STAR process — interval_gRcpp","text":"LU_y m x 2 vector intervals y.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/interval_gRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimate confidence intervals/bands for a STAR process — interval_gRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/invlogit.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the inverse log-odds — invlogit","title":"Compute the inverse log-odds — invlogit","text":"Compute inverse log-odds","code":""},{"path":"https://bking124.github.io/countSTAR/reference/invlogit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the inverse log-odds — invlogit","text":"","code":"invlogit(x)"},{"path":"https://bking124.github.io/countSTAR/reference/invlogit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the inverse log-odds — invlogit","text":"x scalar vector compute (componentwise) inverse log-odds","code":""},{"path":"https://bking124.github.io/countSTAR/reference/invlogit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the inverse log-odds — invlogit","text":"scalar vector values (0,1)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/lm_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting frequentist STAR linear model via EM algorithm — lm_star","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"Compute MLEs log-likelihood STAR linear model. regression coefficients estimated using least squares within EM algorithm.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/lm_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"","code":"lm_star(   formula,   data = NULL,   transformation = \"np\",   y_max = Inf,   sd_init = 10,   tol = 10^-10,   max_iters = 1000 )"},{"path":"https://bking124.github.io/countSTAR/reference/lm_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"formula object class \"formula\" (see lm details model specification) data optional data frame, list environment (object coercible .data.frame data frame) containing variables model; like lm, found data, variables taken environment(formula) transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) y_max fixed known upper bound observations; default Inf sd_init add random noise EM algorithm initialization scaled sd_init times Gaussian MLE standard deviation; default 10 tol tolerance stopping EM algorithm; default 10^-10; max_iters maximum number EM iterations stopping; default 1000","code":""},{"path":"https://bking124.github.io/countSTAR/reference/lm_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"object class \"lmstar\", list following elements: coefficients MLEs coefficients fitted.values fitted values MLEs g.hat function containing (known estimated) transformation ginv.hat function containing inverse transformation sigma.hat MLE standard deviation mu.hat MLE conditional mean (transformed scale) z.hat estimated latent data (transformed scale) MLEs residuals Dunn-Smyth residuals (randomized) residuals_rep Dunn-Smyth residuals (randomized) 10 replicates logLik log-likelihood MLEs logLik0 log-likelihood MLEs *unrounded* initialization lambda Box-Cox nonlinear parameter parameters (1) track parameters across EM iterations (2) record model specifications","code":""},{"path":"https://bking124.github.io/countSTAR/reference/lm_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"Standard function calls including coefficients, fitted, residuals apply. Fitted values expectation MLEs, necessarily count-valued.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/lm_star.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"Infinite latent data values may occur transformed Gaussian model highly inadequate. case, function returns *indices* data points infinite latent values, significant outliers model. Deletion indices re-running model one option, care must taken ensure () appropriate treat observations outliers (ii) model adequate remaining data points.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/lm_star.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"Kowal, D. R., & Wu, B. (2021). Semiparametric count data regression self‐reported mental health. Biometrics. doi:10.1111/biom.13617","code":""},{"path":"https://bking124.github.io/countSTAR/reference/lm_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"","code":"# Simulate data with count-valued response y: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X[,-1] # remove intercept  # Fit model fit_em = lm_star(y ~ X)  # Fitted coefficients: coef(fit_em) #> (Intercept)          X1          X2          X3          X4  #> -0.11050236  0.41340093  0.51350840  0.02321521  0.12092063   # Fitted values: y_hat = fitted(fit_em) plot(y_hat, y);   # Residuals: plot(residuals(fit_em))  qqnorm(residuals(fit_em)); qqline(residuals(fit_em))"},{"path":"https://bking124.github.io/countSTAR/reference/logLikePointRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the pointwise log-likelihood for STAR — logLikePointRcpp","title":"Compute the pointwise log-likelihood for STAR — logLikePointRcpp","text":"Compute pointwise log-likelihood STAR model. code assumes transformed real-valued process (z_star) conditionally independent components means mu standard deviations sigma.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logLikePointRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the pointwise log-likelihood for STAR — logLikePointRcpp","text":"","code":"logLikePointRcpp(g_a_j, g_a_jp1, mu, sigma)"},{"path":"https://bking124.github.io/countSTAR/reference/logLikePointRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the pointwise log-likelihood for STAR — logLikePointRcpp","text":"g_a_j m x 1 vector g((j)) g_a_jp1 m x 1 vector g((j + 1)) mu m x 1 vector conditional expectations sigma m x 1 vector conditional standard deviations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logLikePointRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the pointwise log-likelihood for STAR — logLikePointRcpp","text":"loglike m x 1 log-likelihood value","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logLikePointRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute the pointwise log-likelihood for STAR — logLikePointRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logLikeRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the log-likelihood for STAR — logLikeRcpp","title":"Compute the log-likelihood for STAR — logLikeRcpp","text":"Compute log-likelihood STAR model. code assumes transformed real-valued process (z_star) conditionally independent components means mu standard deviations sigma.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logLikeRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the log-likelihood for STAR — logLikeRcpp","text":"","code":"logLikeRcpp(g_a_j, g_a_jp1, mu, sigma)"},{"path":"https://bking124.github.io/countSTAR/reference/logLikeRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the log-likelihood for STAR — logLikeRcpp","text":"g_a_j m x 1 vector g((j)) g_a_jp1 m x 1 vector g((j + 1)) mu m x 1 vector conditional expectations sigma m x 1 vector conditional standard deviations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logLikeRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the log-likelihood for STAR — logLikeRcpp","text":"loglike scalar log-likelihood value","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logLikeRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute the log-likelihood for STAR — logLikeRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logit.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the log-odds — logit","title":"Compute the log-odds — logit","text":"Compute log-odds","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the log-odds — logit","text":"","code":"logit(x)"},{"path":"https://bking124.github.io/countSTAR/reference/logit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the log-odds — logit","text":"x scalar vector (0,1) compute (componentwise) log-odds","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the log-odds — logit","text":"scalar vector log-odds","code":""},{"path":"https://bking124.github.io/countSTAR/reference/plot_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the estimated regression coefficients and credible intervals — plot_coef","title":"Plot the estimated regression coefficients and credible intervals — plot_coef","text":"Plot estimated regression coefficients credible intervals linear effects two models.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/plot_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the estimated regression coefficients and credible intervals — plot_coef","text":"","code":"plot_coef(   post_coefficients_1,   post_coefficients_2 = NULL,   alpha = 0.05,   labels = NULL )"},{"path":"https://bking124.github.io/countSTAR/reference/plot_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the estimated regression coefficients and credible intervals — plot_coef","text":"post_coefficients_1 Nsims x p matrix simulations posterior distribution p coefficients, Nsims number simulations post_coefficients_2 Nsims x p matrix simulations posterior distribution p coefficients another model alpha confidence level credible intervals labels p dimensional string labels coefficient names","code":""},{"path":"https://bking124.github.io/countSTAR/reference/plot_coef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the estimated regression coefficients and credible intervals — plot_coef","text":"plot regression coefficients credible intervals 1-2 models","code":""},{"path":"https://bking124.github.io/countSTAR/reference/plot_fitted.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the fitted values and the data — plot_fitted","title":"Plot the fitted values and the data — plot_fitted","text":"Plot fitted values, plus pointwise credible intervals, data. simulations, one may use true values place data.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/plot_fitted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the fitted values and the data — plot_fitted","text":"","code":"plot_fitted(y, post_y, y_hat = NULL, alpha = 0.05, ...)"},{"path":"https://bking124.github.io/countSTAR/reference/plot_fitted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the fitted values and the data — plot_fitted","text":"y n x 1 vector data post_y Nsims x n matrix simulated fitted values, Nsims number simulations y_hat n x 1 vector fitted values; NULL, use pointwise sample mean colMeans(post_y) alpha confidence level credible intervals ... arguments plotting","code":""},{"path":"https://bking124.github.io/countSTAR/reference/plot_fitted.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the fitted values and the data — plot_fitted","text":"plot fitted values credible intervals data","code":""},{"path":"https://bking124.github.io/countSTAR/reference/plot_pmf.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the empirical and model-based probability mass functions — plot_pmf","title":"Plot the empirical and model-based probability mass functions — plot_pmf","text":"Plot empirical probability mass function, .e., proportion data values y equal j j=0,1,..., together model-based estimate probability mass function based posterior predictive distribution.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/plot_pmf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the empirical and model-based probability mass functions — plot_pmf","text":"","code":"plot_pmf(y, post.pred, error.bars = FALSE, alpha = 0.05)"},{"path":"https://bking124.github.io/countSTAR/reference/plot_pmf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the empirical and model-based probability mass functions — plot_pmf","text":"y n x 1 vector data post.pred nsave draws posterior predictive distribution y error.bars logical; TRUE, include errors bars model-based PMF alpha confidence level credible intervals","code":""},{"path":"https://bking124.github.io/countSTAR/reference/plot_pmf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the empirical and model-based probability mass functions — plot_pmf","text":"plot empirical PMF y along PMF estimate model posterior predictive distribution","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pmaxRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"pmax() in Rcpp — pmaxRcpp","title":"pmax() in Rcpp — pmaxRcpp","text":"Compute pointwise max two vectors equal length","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pmaxRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pmax() in Rcpp — pmaxRcpp","text":"","code":"pmaxRcpp(v1, v2)"},{"path":"https://bking124.github.io/countSTAR/reference/pmaxRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pmax() in Rcpp — pmaxRcpp","text":"v1 m x 1 vector v2 m x 1 vector","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pmaxRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"pmax() in Rcpp — pmaxRcpp","text":"vm m x 1 vector pointwise maxima","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pmaxRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"pmax() in Rcpp — pmaxRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pminRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"pmin() in Rcpp — pminRcpp","title":"pmin() in Rcpp — pminRcpp","text":"Compute pointwise min two vectors equal length","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pminRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pmin() in Rcpp — pminRcpp","text":"","code":"pminRcpp(v1, v2)"},{"path":"https://bking124.github.io/countSTAR/reference/pminRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pmin() in Rcpp — pminRcpp","text":"v1 m x 1 vector v2 m x 1 vector","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pminRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"pmin() in Rcpp — pminRcpp","text":"vm m x 1 vector pointwise minima","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pminRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"pmin() in Rcpp — pminRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/predict.lmstar.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict method for response in STAR linear model — predict.lmstar","title":"Predict method for response in STAR linear model — predict.lmstar","text":"Outputs predicted values based lmstar fit optionally prediction intervals based (plug-) predictive distribution STAR linear model","code":""},{"path":"https://bking124.github.io/countSTAR/reference/predict.lmstar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict method for response in STAR linear model — predict.lmstar","text":"","code":"# S3 method for lmstar predict(object, newdata = NULL, interval = FALSE, level = 0.95, N = 1000, ...)"},{"path":"https://bking124.github.io/countSTAR/reference/predict.lmstar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict method for response in STAR linear model — predict.lmstar","text":"object Object class \"lmstar\" output lm_star newdata optional matrix/data frame  look variables predict. omitted, fitted values used. interval logical; whether include prediction intervals (default FALSE) level Level prediction intervals N number Monte Carlo samples posterior predictive distribution used approximate intervals; default 1000 ... Ignored","code":""},{"path":"https://bking124.github.io/countSTAR/reference/predict.lmstar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict method for response in STAR linear model — predict.lmstar","text":"Either vector predictions (interval=FALSE) matrix predictions bounds column names fit, lwr, upr","code":""},{"path":"https://bking124.github.io/countSTAR/reference/predict.lmstar.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predict method for response in STAR linear model — predict.lmstar","text":"interval=TRUE, predict.lmstar uses Monte Carlo approach estimating (plug-) predictive distribution STAR linear model. algorithm iteratively samples () latent data given observed data, (ii) latent predictive data given latent data (), (iii) (inverse) transforms rounds latent predictive data obtain draw integer-valued predictive distribution. appropriate quantiles Monte Carlo draws computed reported prediction interval.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/predict.lmstar.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Predict method for response in STAR linear model — predict.lmstar","text":"``plug-\" predictive distribution crude approximation. Better approaches available using Bayesian models, e.g. blm_star, provide samples posterior predictive distribution. highly skewed responses, prediction intervals especially lower levels may include predicted value , since mean often much larger median.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/predict.lmstar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict method for response in STAR linear model — predict.lmstar","text":"","code":"# Simulate data with count-valued response y: x = seq(0, 1, length.out = 100) y = rpois(n = length(x), lambda = exp(1.5 + 5*(x -.5)^2))  # Estimate model--assume a quadratic effect (better for illustration purposes) fit = lm_star(y~x+I(x^2), transformation = 'sqrt')  #Compute the predictive draws for the test points (same as observed points here) #Also compute intervals using plug-in predictive distribution y_pred = predict(fit, interval=TRUE)  # Plot the results plot(x, y, ylim = range(y, y_pred), main = 'STAR: Predictions and 95% PI') lines(x,y_pred[,\"fit\"], col='black', type='s', lwd=4) lines(x, y_pred[,\"lwr\"], col='darkgray', type='s', lwd=4) lines(x, y_pred[,\"upr\"], col='darkgray', type='s', lwd=4)"},{"path":"https://bking124.github.io/countSTAR/reference/pvals.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute coefficient p-values for STAR linear regression using likelihood ratio test — pvals","title":"Compute coefficient p-values for STAR linear regression using likelihood ratio test — pvals","text":"linear regression model within STAR framework, compute p-values regression coefficients using likelihood ratio test. also computes p-value excluding predictors, akin (partial) F test.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pvals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute coefficient p-values for STAR linear regression using likelihood ratio test — pvals","text":"","code":"pvals(object)"},{"path":"https://bking124.github.io/countSTAR/reference/pvals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute coefficient p-values for STAR linear regression using likelihood ratio test — pvals","text":"object Object class \"lmstar\" output lm_star","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pvals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute coefficient p-values for STAR linear regression using likelihood ratio test — pvals","text":"list p+1 p-values, one predictor well joint p-value excluding predictors","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pvals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute coefficient p-values for STAR linear regression using likelihood ratio test — pvals","text":"","code":"# Simulate data with count-valued response y: sim_dat = simulate_nb_lm(n = 100, p = 2) y = sim_dat$y; X = sim_dat$X[,-1] # remove intercept  # Select a transformation: transformation = 'np'  #Estimate model fit = lm_star(y~X, transformation = transformation)  #Compute p-values pvals(fit) #>        (Intercept)                  X Any linear effects  #>       3.199957e-01       1.739922e-07       1.739922e-07"},{"path":"https://bking124.github.io/countSTAR/reference/randomForest_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Random Forest STAR with EM algorithm — randomForest_star","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"Compute MLEs log-likelihood Random Forest STAR model. STAR model requires *transformation* *estimation function* conditional mean given observed data. transformation can known (e.g., log sqrt) unknown (Box-Cox estimated nonparametrically) greater flexibility. estimator case random forest. Standard function calls including fitted residuals apply.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/randomForest_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"","code":"randomForest_star(   y,   X,   X.test = NULL,   transformation = \"np\",   y_max = Inf,   sd_init = 10,   tol = 10^-10,   max_iters = 1000,   ntree = 500,   mtry = max(floor(ncol(X)/3), 1),   nodesize = 5 )"},{"path":"https://bking124.github.io/countSTAR/reference/randomForest_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"y n x 1 vector observed counts X n x p matrix predictors X.test m x p matrix --sample predictors transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) y_max fixed known upper bound observations; default Inf sd_init add random noise EM algorithm initialization scaled sd_init times Gaussian MLE standard deviation; default 10 tol tolerance stopping EM algorithm; default 10^-10; max_iters maximum number EM iterations stopping; default 1000 ntree Number trees grow. set small number, ensure every input row gets predicted least times. Default 500. mtry Number variables randomly sampled candidates split. Default p/3. nodesize Minimum size terminal nodes. Setting number larger causes smaller trees grown (thus take less time). Default 5.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/randomForest_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"list following elements: fitted.values: fitted values MLEs based --bag samples (training) fitted.values.test: fitted values MLEs (testing) g.hat function containing (known estimated) transformation sigma.hat MLE standard deviation mu.hat MLE conditional mean (transformed scale) z.hat estimated latent data (transformed scale) MLEs residuals Dunn-Smyth residuals (randomized) residuals_rep Dunn-Smyth residuals (randomized) 10 replicates logLik log-likelihood MLEs logLik0 log-likelihood MLEs *unrounded* initialization lambda Box-Cox nonlinear parameter rfObj: object returned randomForest() MLEs parameters (1) track parameters across EM iterations (2) record model specifications","code":""},{"path":"https://bking124.github.io/countSTAR/reference/randomForest_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. expectation-maximization (EM) algorithm used produce maximum likelihood estimators (MLEs) parameters defined fitted values computed using --bag samples. result, log-likelihood based --bag prediction, similarly straightforward compute --bag squared absolute errors.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/randomForest_star.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"Since random forest produces random predictions, EM algorithm never converge exactly. Infinite latent data values may occur transformed Gaussian model highly inadequate. case, function returns *indices* data points infinite latent values, significant outliers model. Deletion indices re-running model one option, care must taken ensure () appropriate treat observations outliers (ii) model adequate remaining data points.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/randomForest_star.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"Kowal, D. R., & Wu, B. (2021). Semiparametric count data regression self‐reported mental health. Biometrics. doi:10.1111/biom.13617","code":""},{"path":"https://bking124.github.io/countSTAR/reference/randomForest_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"","code":"# \\donttest{ # Simulate data with count-valued response y: sim_dat = simulate_nb_friedman(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # EM algorithm for STAR (using the log-link) fit_em = randomForest_star(y = y, X = X,                  transformation = 'log',                  max_iters = 100)  # Fitted values (out-of-bag) y_hat = fitted(fit_em) plot(y_hat, y);   # Residuals: plot(residuals(fit_em))  qqnorm(residuals(fit_em)); qqline(residuals(fit_em))   # Log-likelihood at MLEs (out-of-bag): fit_em$logLik #> [1] -206.8263 # }"},{"path":"https://bking124.github.io/countSTAR/reference/roaches.html","id":null,"dir":"Reference","previous_headings":"","what":"Data on the efficacy of a pest management system at reducing the number of\nroaches in urban apartments. — roaches","title":"Data on the efficacy of a pest management system at reducing the number of\nroaches in urban apartments. — roaches","text":"Data efficacy pest management system reducing number roaches urban apartments.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/roaches.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data on the efficacy of a pest management system at reducing the number of\nroaches in urban apartments. — roaches","text":"","code":"roaches"},{"path":"https://bking124.github.io/countSTAR/reference/roaches.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data on the efficacy of a pest management system at reducing the number of\nroaches in urban apartments. — roaches","text":"## `roaches` data frame 262 obs. 6 variables: y Number roaches caught roach1 Pretreatment number roaches treatment Treatment indicator senior Indicator elderly residents building exposure2 Number days roach traps used","code":""},{"path":"https://bking124.github.io/countSTAR/reference/roaches.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data on the efficacy of a pest management system at reducing the number of\nroaches in urban apartments. — roaches","text":"Gelman Hill (2007); package `rstanarm`","code":""},{"path":"https://bking124.github.io/countSTAR/reference/round_floor.html","id":null,"dir":"Reference","previous_headings":"","what":"Rounding function — round_floor","title":"Rounding function — round_floor","text":"Define rounding operator associated floor function. function also returns zero whenever input negative caps value y_max, y_max known upper bound data y (specified).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/round_floor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rounding function — round_floor","text":"","code":"round_floor(z, y_max = Inf)"},{"path":"https://bking124.github.io/countSTAR/reference/round_floor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rounding function — round_floor","text":"z real-valued input(s) y_max fixed known upper bound observations; default Inf","code":""},{"path":"https://bking124.github.io/countSTAR/reference/round_floor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rounding function — round_floor","text":"count-valued output(s) rounding function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/round_floor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rounding function — round_floor","text":"","code":"# Floor function: round_floor(1.5) #> [1] 1 round_floor(0.5) #> [1] 0  # Special treatmeant of negative numbers: round_floor(-1) #> [1] 0"},{"path":"https://bking124.github.io/countSTAR/reference/rtruncnormRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a truncated normal distribution — rtruncnormRcpp","title":"Sample from a truncated normal distribution — rtruncnormRcpp","text":"Sample truncated normal distribution. Samples drawn componentwise, component vector allowed mean, standard deviation, upper lower limits. components assumed independent.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/rtruncnormRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a truncated normal distribution — rtruncnormRcpp","text":"","code":"rtruncnormRcpp(y_lower, y_upper, mu, sigma, u_rand)"},{"path":"https://bking124.github.io/countSTAR/reference/rtruncnormRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a truncated normal distribution — rtruncnormRcpp","text":"y_lower m x 1 vector lower endpoints y_upper m x 1 vector upper endpoints mu m x 1 vector conditional expectations sigma m x 1 vector conditional standard deviations u_rand m x 1 vector uniform random variables","code":""},{"path":"https://bking124.github.io/countSTAR/reference/rtruncnormRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a truncated normal distribution — rtruncnormRcpp","text":"z_star m x 1 draw truncated normal distribution","code":""},{"path":"https://bking124.github.io/countSTAR/reference/rtruncnormRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample from a truncated normal distribution — rtruncnormRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sampleFastGaussian.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al. — sampleFastGaussian","title":"Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al. — sampleFastGaussian","text":"Sample N(mu, Sigma) Sigma = solve(crossprod(Phi) + solve(D)) mu = Sigma*crossprod(Phi, alpha):","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sampleFastGaussian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al. — sampleFastGaussian","text":"","code":"sampleFastGaussian(Phi, Ddiag, alpha)"},{"path":"https://bking124.github.io/countSTAR/reference/sampleFastGaussian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al. — sampleFastGaussian","text":"Phi n x p matrix (predictors) Ddiag p x 1 vector diagonal components (prior variance) alpha n x 1 vector (data, scaled variance)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sampleFastGaussian.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al. — sampleFastGaussian","text":"Draw N(mu, Sigma), p x 1, computed O(n^2*p)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sampleFastGaussian.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al. — sampleFastGaussian","text":"Assumes D diagonal, extensions available","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_orthog.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample the parameters for an additive model — sample_bam_orthog","title":"Sample the parameters for an additive model — sample_bam_orthog","text":"Sample parameters additive model, may contain linear nonlinear predictors. nonlinear terms modeled using orthogonalized splines. sampler draws linear terms jointly samples vector nonlinear coefficients using Bayesian backfitting (.e., conditional nonlinear linear terms).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_orthog.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample the parameters for an additive model — sample_bam_orthog","text":"","code":"sample_bam_orthog(   y,   X_lin,   X_nonlin,   params,   A = 10^4,   B_all = NULL,   diagBtB_all = NULL,   XtX = NULL )"},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_orthog.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample the parameters for an additive model — sample_bam_orthog","text":"y n x 1 vector data X_lin n x pL matrix predictors modelled linear X_nonlin n x pNL matrix predictors modelled nonlinear params named list parameters containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu prior scale sigma_beta, assume follows Uniform(0, ) prior. B_all optional pNL-dimensional list n x L[j] dimensional basis matrices nonlinear term j=1,...,pNL; NULL, compute internally diagBtB_all optional pNL-dimensional list diag(crossprod(B_all[[j]])); NULL, compute internally XtX optional p x p matrix crossprod(X) (one-time cost); NULL, compute internally","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_orthog.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample the parameters for an additive model — sample_bam_orthog","text":"updated named list params draws full conditional distributions sigma coefficients (updated mu).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_orthog.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample the parameters for an additive model — sample_bam_orthog","text":"parameters coefficients : beta_lin: p x 1 linear coefficients, including linear terms X_nonlin f_j: n x pNL matrix fitted values nonlinear function theta_j: pNL-dimensional nonlinear basis coefficients sigma_beta: p x 1 vector linear regression coefficient standard deviations sigma_theta_j: pNL x 1 vector nonlinear coefficient standard deviations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_thin.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample the parameters for an additive model — sample_bam_thin","title":"Sample the parameters for an additive model — sample_bam_thin","text":"Sample parameters additive model, may contain linear nonlinear predictors. nonlinear terms modeled using low-rank thin plate splines. sampler draws linear terms jointly samples vector nonlinear coefficients using Bayesian backfitting (.e., conditional nonlinear linear terms).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_thin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample the parameters for an additive model — sample_bam_thin","text":"","code":"sample_bam_thin(   y,   X_lin,   X_nonlin,   params,   A = 10^4,   B_all = NULL,   BtB_all = NULL,   XtX = NULL )"},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_thin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample the parameters for an additive model — sample_bam_thin","text":"y n x 1 vector data X_lin n x pL matrix predictors modelled linear X_nonlin n x pNL matrix predictors modelled nonlinear params named list parameters containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu prior scale sigma_beta, assume follows Uniform(0, ) prior. B_all optional pNL-dimensional list n x L[j] dimensional basis matrices nonlinear term j=1,...,pNL; NULL, compute internally BtB_all optional pNL-dimensional list crossprod(B_all[[j]]); NULL, compute internally XtX optional p x p matrix crossprod(X) (one-time cost); NULL, compute internally","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_thin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample the parameters for an additive model — sample_bam_thin","text":"updated named list params draws full conditional distributions sigma coefficients (updated mu).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_thin.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample the parameters for an additive model — sample_bam_thin","text":"parameters coefficients : beta_lin: p x 1 linear coefficients, including linear terms X_nonlin f_j: n x pNL matrix fitted values nonlinear function theta_j: pNL-dimensional nonlinear basis coefficients sigma_beta: p x 1 vector linear regression coefficient standard deviations sigma_theta_j: pNL x 1 vector nonlinear coefficient standard deviations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_gprior.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","title":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","text":"Sample parameters linear regression model assuming g-prior  coefficients.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_gprior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","text":"","code":"sample_lm_gprior(y, X, params, psi = NULL, XtX = NULL, X_test = NULL)"},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_gprior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","text":"y n x 1 vector data X n x p matrix predictors params named list parameters containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu psi prior variance g-prior XtX p x p matrix crossprod(X) (one-time cost); NULL, compute within function X_test matrix predictors test points (default NULL)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_gprior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","text":"updated named list params draws full conditional distributions sigma coefficients (along updated mu mu_test applicable).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_gprior.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","text":"parameters coefficients : beta: p x 1 vector regression coefficients components beta","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_gprior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","text":"","code":"# Simulate data for illustration: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X # Initialize: params = init_lm_gprior(y = y, X = X) # Sample: params = sample_lm_gprior(y = y, X = X, params = params) names(params) #> [1] \"mu\"           \"sigma\"        \"coefficients\" names(params$coefficients) #> [1] \"beta\""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_hs.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","title":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","text":"Sample parameters linear regression model assuming horseshoe prior (non-intercept) coefficients. number predictors p may exceed number observations n.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_hs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","text":"","code":"sample_lm_hs(y, X, params, XtX = NULL, X_test = NULL)"},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_hs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","text":"y n x 1 vector data X n x p matrix predictors params named list parameters containing mu n x 1 vector conditional means (fitted values) sigma conditional standard deviation coefficients named list parameters determine mu XtX p x p matrix crossprod(X) (one-time cost); NULL, compute within function X_test matrix predictors test points (default NULL)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_hs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","text":"updated named list params draws full conditional distributions sigma coefficients (along updated mu mu_test applicable).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_hs.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","text":"parameters coefficients : beta p x 1 vector regression coefficients sigma_beta p x 1 vector regression coefficient standard deviations (local scale parameters) xi_sigma_beta p x 1 vector parameter-expansion variables sigma_beta lambda_beta global scale parameter xi_lambda_beta parameter-expansion variable lambda_beta components beta","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_ridge.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample linear regression parameters assuming a ridge prior — sample_lm_ridge","title":"Sample linear regression parameters assuming a ridge prior — sample_lm_ridge","text":"Sample parameters linear regression model assuming ridge prior (non-intercept) coefficients. number predictors p may exceed number observations n.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_ridge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample linear regression parameters assuming a ridge prior — sample_lm_ridge","text":"","code":"sample_lm_ridge(y, X, params, A = 10^4, XtX = NULL, X_test = NULL)"},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_ridge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample linear regression parameters assuming a ridge prior — sample_lm_ridge","text":"y n x 1 vector data X n x p matrix predictors params named list parameters containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu prior scale sigma_beta, assume follows Uniform(0, ) prior. XtX p x p matrix crossprod(X) (one-time cost); NULL, compute within function X_test matrix predictors test points (default NULL)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_ridge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample linear regression parameters assuming a ridge prior — sample_lm_ridge","text":"updated named list params draws full conditional distributions sigma coefficients (along updated mu mu_test applicable).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_ridge.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample linear regression parameters assuming a ridge prior — sample_lm_ridge","text":"parameters coefficients : beta: p x 1 vector regression coefficients sigma_beta: prior standard deviation (non-intercept) components beta","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_params_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample the parameters for a simple mean-only model — sample_params_mean","title":"Sample the parameters for a simple mean-only model — sample_params_mean","text":"Sample parameters model y ~ N(mu0, sigma^2) flat prior mu0 sigma ~ Unif(0, ).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_params_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample the parameters for a simple mean-only model — sample_params_mean","text":"","code":"sample_params_mean(y, params)"},{"path":"https://bking124.github.io/countSTAR/reference/sample_params_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample the parameters for a simple mean-only model — sample_params_mean","text":"y n x 1 vector data params named list parameters containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_params_mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample the parameters for a simple mean-only model — sample_params_mean","text":"updated named list params draws full conditional distributions sigma coefficients (updated mu).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_params_mean.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample the parameters for a simple mean-only model — sample_params_mean","text":"parameter coefficients mu0. Although redundant , parametrization useful functions.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simBaS.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Simultaneous Band Scores (SimBaS) — simBaS","title":"Compute Simultaneous Band Scores (SimBaS) — simBaS","text":"Compute simultaneous band scores (SimBaS) Meyer et al. (2015, Biometrics). SimBaS uses MC(MC) simulations function interest compute minimum alpha joint credible bands alpha level include zero. quantity computed grid point (observation point) domain function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simBaS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Simultaneous Band Scores (SimBaS) — simBaS","text":"","code":"simBaS(sampFuns)"},{"path":"https://bking124.github.io/countSTAR/reference/simBaS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Simultaneous Band Scores (SimBaS) — simBaS","text":"sampFuns Nsims x m matrix Nsims MCMC samples m points along curve","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simBaS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Simultaneous Band Scores (SimBaS) — simBaS","text":"m x 1 vector simBaS","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simBaS.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute Simultaneous Band Scores (SimBaS) — simBaS","text":"input needs curves: simBaS may computed vectors achieve multiplicity adjustment. minimum returned value, PsimBaS_t, domain t Global Bayesian P-Value (GBPV) testing whether function zero everywhere.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_friedman.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"Simulate data negative-binomial distribution nonlinear mean function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_friedman.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"","code":"simulate_nb_friedman(   n = 100,   p = 10,   r_nb = 1,   b_int = log(1.5),   b_sig = log(5),   sigma_true = sqrt(2 * log(1)),   seed = NULL )"},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_friedman.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"n number observations p number predictors r_nb dispersion parameter Negative Binomial dispersion; smaller values imply greater overdispersion, larger values approximate Poisson distribution. b_int intercept; default log(1.5). b_sig regression coefficients true signals; default log(5.0). sigma_true standard deviation Gaussian innovation; default zero. seed optional integer set seed reproducible simulation; default NULL results different dataset run","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_friedman.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"named list simulated count response y, simulated design matrix X, true expected counts Ey.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_friedman.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"log-expected counts modeled using Friedman (1991) nonlinear function interactions, possibly additional Gaussian noise (log-scale). assume half predictors associated response, .e., true signals. sufficiently large dispersion parameter r_nb, distribution approximate Poisson distribution. , predictor variables simulated independent uniform distributions.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_friedman.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"Specifying sigma_true = sqrt(2*log(1 + )) implies expected counts inflated 100*% (relative exp(X*beta)), addition providing additional overdispersion.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_friedman.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"","code":"# Simulate and plot the count data: sim_dat = simulate_nb_friedman(n = 100, p = 10); plot(sim_dat$y)"},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate count data from a linear regression — simulate_nb_lm","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"Simulate data negative-binomial distribution linear mean function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"","code":"simulate_nb_lm(   n = 100,   p = 10,   r_nb = 1,   b_int = log(1.5),   b_sig = log(2),   sigma_true = sqrt(2 * log(1)),   ar1 = 0,   seed = NULL )"},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"n number observations p number predictors (including intercept) r_nb dispersion parameter Negative Binomial dispersion; smaller values imply greater overdispersion, larger values approximate Poisson distribution. b_int intercept; default log(1.5), implies expected count 1.5 predictors zero b_sig regression coefficients true signals; default log(2.0), implies twofold increase expected counts one unit increase x sigma_true standard deviation Gaussian innovation; default zero. ar1 autoregressive coefficient among columns X matrix; default zero. seed optional integer set seed reproducible simulation; default NULL results different dataset run","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"named list simulated count response y, simulated design matrix X (including intercept), true expected counts Ey, true regression coefficients beta_true.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_lm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"log-expected counts modeled linear function covariates, possibly additional Gaussian noise (log-scale). assume half predictors associated response, .e., true signals. sufficiently large dispersion parameter r_nb, distribution approximate Poisson distribution. , predictor variables simulated independent standard normal distributions.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_lm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"Specifying sigma_true = sqrt(2*log(1 + )) implies expected counts inflated 100*% (relative exp(X*beta)), addition providing additional overdispersion.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"","code":"# Simulate and plot the count data: sim_dat = simulate_nb_lm(n = 100, p = 10); plot(sim_dat$y)"},{"path":"https://bking124.github.io/countSTAR/reference/splineBasis.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize and reparametrize a spline basis matrix — splineBasis","title":"Initialize and reparametrize a spline basis matrix — splineBasis","text":"Following Wand Ormerod (2008), compute low-rank thin plate spline basis diagonalized prior variance nonlinear component scalar times diagonal matrix. Knot locations determined quantiles penalty integrated squared second derivative.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/splineBasis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize and reparametrize a spline basis matrix — splineBasis","text":"","code":"splineBasis(tau, sumToZero = TRUE, rescale01 = TRUE)"},{"path":"https://bking124.github.io/countSTAR/reference/splineBasis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize and reparametrize a spline basis matrix — splineBasis","text":"tau m x 1 vector observed points sumToZero logical; TRUE, enforce sum--zero constraint (useful additive models) rescale01 logical; TRUE, rescale tau interval [0,1] prior computing basis penalty matrices","code":""},{"path":"https://bking124.github.io/countSTAR/reference/splineBasis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize and reparametrize a spline basis matrix — splineBasis","text":"B_nl: nonlinear component spline basis matrix","code":""},{"path":"https://bking124.github.io/countSTAR/reference/splineBasis.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize and reparametrize a spline basis matrix — splineBasis","text":"form full spline basis matrix, compute cbind(1, tau, B_nl). sum--zero constraint implicitly assumes linear term centered scaled, .e., scale(tau).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/spline_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation for Bayesian STAR spline regression — spline_star","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"Compute samples predictive distributions STAR spline regression model using either Gibbs sampling approach exact Monte Carlo sampling (default Gibbs sampling scales better large n).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/spline_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"","code":"spline_star(   y,   tau = NULL,   transformation = \"np\",   y_max = Inf,   psi = NULL,   nsave = 1000,   use_MCMC = TRUE,   nburn = 1000,   nskip = 0,   verbose = TRUE )"},{"path":"https://bking124.github.io/countSTAR/reference/spline_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"y n x 1 vector observed counts tau n x 1 vector observation points; NULL, assume equally-spaced [0,1] transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"bnp\" (Bayesian nonparametric transformation using Bayesian bootstrap) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) y_max fixed known upper bound observations; default Inf psi prior variance (1/smoothing parameter); NULL, update MCMC nsave number MCMC iterations save (number Monte Carlo simulations) use_MCMC logical; whether run Gibbs sampler Monte Carlo (default TRUE) nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw verbose logical; TRUE, print time remaining","code":""},{"path":"https://bking124.github.io/countSTAR/reference/spline_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"list following elements: post.pred: nsave x n samples posterior predictive distribution observation points tau marg_like: marginal likelihood (use_MCMC=FALSE; otherwise NULL)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/spline_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. , continuous latent data model spline regression. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt'. Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y. distribution-based transformations approximately preserve mean variance count data y latent data scale, lends interpretability model parameters. Lastly, transformation can modeled using Bayesian bootstrap ('bnp'), Bayesian nonparametric model incorporates uncertainty transformation posterior predictive inference.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/spline_star.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"'bnp' transformation numerical stability issues psi modeled unknown. case, better fix psi positive number.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/spline_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"","code":"# Simulate some data: n = 100 tau = seq(0,1, length.out = n) y = round_floor(exp(1 + rnorm(n)/4 + poly(tau, 4)%*%rnorm(n=4, sd = 4:1)))  # Sample from the predictive distribution of a STAR spline model: fit = spline_star(y = y, tau = tau) #> [1] \"Burn-In Period\" #> [1] \"Starting sampling\" #> [1] \"0 seconds remaining\" #> [1] \"Total time:  1 seconds\"  # Compute 90% prediction intervals: pi_y = t(apply(fit$post.pred, 2, quantile, c(0.05, .95)))  # Plot the results: intervals, median, and smoothed mean plot(tau, y, ylim = range(pi_y, y)) polygon(c(tau, rev(tau)),c(pi_y[,2], rev(pi_y[,1])),col='gray', border=NA) lines(tau, apply(fit$post.pred, 2, median), lwd=5, col ='black') lines(tau, smooth.spline(tau, apply(fit$post.pred, 2, mean))$y, lwd=5, col='blue') lines(tau, y, type='p')"},{"path":"https://bking124.github.io/countSTAR/reference/spline_star_exact.html","id":null,"dir":"Reference","previous_headings":"","what":"Monte Carlo predictive sampler for spline regression — spline_star_exact","title":"Monte Carlo predictive sampler for spline regression — spline_star_exact","text":"Compute direct Monte Carlo samples posterior predictive distribution STAR spline regression model.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/spline_star_exact.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Monte Carlo predictive sampler for spline regression — spline_star_exact","text":"","code":"spline_star_exact(   y,   tau = NULL,   transformation = \"np\",   y_max = Inf,   psi = 1000,   nsave = 1000,   compute_marg = TRUE )"},{"path":"https://bking124.github.io/countSTAR/reference/spline_star_exact.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Monte Carlo predictive sampler for spline regression — spline_star_exact","text":"y n x 1 vector observed counts tau n x 1 vector observation points; NULL, assume equally-spaced [0,1] transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"bnp\" (Bayesian nonparametric transformation using Bayesian bootstrap) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) y_max fixed known upper bound observations; default Inf psi prior variance (1/smoothing parameter) nsave number Monte Carlo simulations compute_marg logical; TRUE, compute return marginal likelihood","code":""},{"path":"https://bking124.github.io/countSTAR/reference/spline_star_exact.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Monte Carlo predictive sampler for spline regression — spline_star_exact","text":"list following elements: post.pred: nsave x n samples posterior predictive distribution observation points tau marg_like: marginal likelihood (requested; otherwise NULL)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/spline_star_exact.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Monte Carlo predictive sampler for spline regression — spline_star_exact","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. , continuous latent data model spline regression. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt'. Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y. distribution-based transformations approximately preserve mean variance count data y latent data scale, lends interpretability model parameters. Lastly, transformation can modeled using Bayesian bootstrap ('bnp'), Bayesian nonparametric model incorporates uncertainty transformation posterior predictive inference. Monte Carlo sampler produces direct, discrete, joint draws posterior predictive distribution spline regression model observed tau points.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/truncnorm_mom.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the first and second moment of a truncated normal — truncnorm_mom","title":"Compute the first and second moment of a truncated normal — truncnorm_mom","text":"Given lower upper endpoints mean standard deviation (non-truncated) normal distribution, compute first second moment truncated normal distribution. inputs may scalars vectors.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/truncnorm_mom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the first and second moment of a truncated normal — truncnorm_mom","text":"","code":"truncnorm_mom(a, b, mu, sig)"},{"path":"https://bking124.github.io/countSTAR/reference/truncnorm_mom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the first and second moment of a truncated normal — truncnorm_mom","text":"lower endpoint b upper endpoint mu expected value non-truncated normal distribution sig standard deviation non-truncated normal distribution","code":""},{"path":"https://bking124.github.io/countSTAR/reference/truncnorm_mom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the first and second moment of a truncated normal — truncnorm_mom","text":"list containing first moment m1 second moment m2","code":""},{"path":"https://bking124.github.io/countSTAR/reference/uni.slice.html","id":null,"dir":"Reference","previous_headings":"","what":"Univariate Slice Sampler from Neal (2008) — uni.slice","title":"Univariate Slice Sampler from Neal (2008) — uni.slice","text":"Compute draw univariate distribution using code provided Radford M. Neal. documentation also reproduced Neal (2008).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/uni.slice.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Univariate Slice Sampler from Neal (2008) — uni.slice","text":"","code":"uni.slice(x0, g, w = 1, m = Inf, lower = -Inf, upper = +Inf, gx0 = NULL)"},{"path":"https://bking124.github.io/countSTAR/reference/uni.slice.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Univariate Slice Sampler from Neal (2008) — uni.slice","text":"x0 Initial point g Function returning log probability density (plus constant) w Size steps creating interval (default 1) m Limit steps (default infinite) lower Lower bound support distribution (default -Inf) upper Upper bound support distribution (default +Inf) gx0 Value g(x0), known (default known)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/uni.slice.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Univariate Slice Sampler from Neal (2008) — uni.slice","text":"point sampled, log density attached attribute.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/uni.slice.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Univariate Slice Sampler from Neal (2008) — uni.slice","text":"log density function may return -Inf points outside support distribution.  lower /upper bound specified support, log density function called outside limits.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/update_struct.html","id":null,"dir":"Reference","previous_headings":"","what":"Update parameters for warpDLM model with trend DLM — update_struct","title":"Update parameters for warpDLM model with trend DLM — update_struct","text":"function serves update warpDLM variance parameters underlying DLM structural model (.e. local level local linear trend). assumes Unif(0,=10^4) prior standard deviations.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/update_struct.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update parameters for warpDLM model with trend DLM — update_struct","text":"","code":"update_struct(fit, z_star, theta)"},{"path":"https://bking124.github.io/countSTAR/reference/update_struct.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update parameters for warpDLM model with trend DLM — update_struct","text":"fit KFAS model object describing DLM z_star latest draw z* theta latest draw latent state(s) theta","code":""},{"path":"https://bking124.github.io/countSTAR/reference/update_struct.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update parameters for warpDLM model with trend DLM — update_struct","text":"KFAS model object (class SSModel) updated newly sampled variance parameters","code":""},{"path":"https://bking124.github.io/countSTAR/reference/warpDLM.html","id":null,"dir":"Reference","previous_headings":"","what":"Posterior Inference for warpDLM model with latent structural DLM — warpDLM","title":"Posterior Inference for warpDLM model with latent structural DLM — warpDLM","text":"function outputs posterior quantities forecasts univariate warpDLM model. Currently two latent DLM specifications supported: local level local linear trend.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/warpDLM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posterior Inference for warpDLM model with latent structural DLM — warpDLM","text":"","code":"warpDLM(   y,   type = c(\"level\", \"trend\"),   transformation = c(\"np\", \"identity\", \"log\", \"sqrt\", \"pois\", \"neg-bin\"),   y_max = Inf,   R0 = 10,   nsave = 5000,   nburn = 5000,   nskip = 1,   n.ahead = 1 )"},{"path":"https://bking124.github.io/countSTAR/reference/warpDLM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posterior Inference for warpDLM model with latent structural DLM — warpDLM","text":"y count-valued time series type type latent DLM (must either level trend) transformation transformation use latent process (default np); must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) y_max fixed known upper bound observations; default Inf R0 variance initial state theta_0; default 10 nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw n.ahead number steps forecast ahead","code":""},{"path":"https://bking124.github.io/countSTAR/reference/warpDLM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posterior Inference for warpDLM model with latent structural DLM — warpDLM","text":"list following elements: V_post: posterior draws observation variance W_post: posterior draws state update variance(s) fc_post: draws forecast distribution (length n.ahead) post_pred: draws posterior predictive distribution y g_func: transformation function g_inv_func: inverse transformation function KFAS_mod: final KFAS model representing latent DLM","code":""},{"path":[]},{"path":"https://bking124.github.io/countSTAR/news/index.html","id":"countstar-102","dir":"Changelog","previous_headings":"","what":"countSTAR 1.0.2","title":"countSTAR 1.0.2","text":"CRAN release: 2023-06-30 Added roaches dataset package Fixed bug blm_star function","code":""},{"path":"https://bking124.github.io/countSTAR/news/index.html","id":"countstar-101","dir":"Changelog","previous_headings":"","what":"countSTAR 1.0.1","title":"countSTAR 1.0.1","text":"CRAN release: 2023-04-10 Initial version Added NEWS.md file track changes package.","code":""}]
