[{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Getting Started with countSTAR","text":"countSTAR package implements variety methods analyze diverse count-valued data, based idea Simultaneous Transformation Rounding (STAR). package functionality broadly split three categories: Bayesian estimation STAR models (Kowal Canale (2020), Kowal Wu (2022)), frequentist/classical estimation (Kowal Wu (2021)), time series analysis using warped Dynamic Linear Models (King Kowal (2021)). give brief description STAR framework, diving specific examples show countSTAR functionality.","code":""},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"star-model-overview","dir":"Articles","previous_headings":"","what":"STAR Model Overview","title":"Getting Started with countSTAR","text":"STAR models build upon continuous data models provide valid count-valued data-generating process. example STAR model linear regression follows: \\[\\begin{align*} y_i &= \\mbox{floor}(y_i^*) \\\\ z_i^* &= \\log(y_i^*) \\\\ z_i^* &= x_i'\\beta + \\epsilon_i, \\quad \\epsilon_i \\stackrel{iid}{\\sim}N(0, \\sigma^2) \\end{align*}\\] latent data \\(y_i^*\\) act continuous proxy count data \\(y_i\\), easier model yet simple mapping via floor function observed data. latent data \\(y_i^*\\) transformed \\(z_i^*\\), common practice, modeled using Gaussian linear regression. model inherits structure , data-generating process now count-valued. generally, STAR models defined via rounding operator \\(h\\), (known unknown) transformation \\(g\\), continuous data model \\(\\Pi_\\theta\\) unknown parameters \\(\\theta\\): \\[\\begin{align*} y &= h(y^*) \\quad \\mbox{(rounding)}\\\\ z^* &= g(y^*) \\quad \\mbox{(transformation)}\\\\ z^* & \\sim \\Pi_\\theta \\quad \\mbox{(model)}\\\\ \\end{align*}\\] Importantly, STAR models highly flexible count-valued processes, provide capability model () discrete data, (ii) zero-inflation, (iii) - -dispersion, (iv) bounded censored data. focus conditionally Gaussian models form \\[ z^*(x) = \\mu_\\theta(x) + \\epsilon(x), \\quad \\epsilon(x) \\stackrel{iid}{\\sim}N(0, \\sigma^2) \\] \\(\\mu_\\theta(x)\\) conditional expectation transformed latent data unknown parameters \\(\\theta\\). Examples include linear, additive, tree-based regression models.","code":""},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"the-rounding-operator","dir":"Articles","previous_headings":"STAR Model Overview","what":"The Rounding Operator","title":"Getting Started with countSTAR","text":"rounding operator \\(h\\) many--one function sets \\(y = j\\) whenever \\(y^*\\\\mathcal{}_j\\) equivalently \\(z^*=g(y^*) \\g(\\mathcal{}_j)\\) . take many different forms, generally floor function, .e \\(\\mathcal{}_j := [j, j+1)\\) works well default, modification \\(g(\\mathcal{}_0) := (-\\infty, 0)\\) \\(y = 0\\) whenever \\(z^* < 0\\). latter modification ensures much latent space mapped zero, therefore STAR models can easily account zero-inflation. Furthermore, known upper bound y_max\\(=K\\) data, additional change incorporate structure, namely let \\(g(\\mathcal{}_K) := [g(a_K), \\infty)\\). rounding operator inverse implemented countSTAR functions a_j() round_fun(), although rarely need employed end user. Instead, thing might need specified user whether upper bound data exists, case simple option setting y_max modeling functions passed rounding function.","code":""},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"the-transformation-function","dir":"Articles","previous_headings":"STAR Model Overview","what":"The Transformation Function","title":"Getting Started with countSTAR","text":"variety options transformation function \\(g\\), ranging fixed functions -priori data-driven transformations transformations learned along rest model. models countSTAR support three common fixed transformations: log, square root (‘sqrt’), identity transformation (essentially rounding-model). Furthermore, functions support set transformations learned matching marginal moments data \\(y\\) latent \\(z\\): transformation='pois' uses moment-matched marginal Poisson CDF transformation='neg-bin' uses moment-matched marginal Negative Binomial CDF transformation='np' nonparametric transformation estimated empirical CDF \\(y\\). Details estimation transformations can found Kowal Wu (2021). particular “np” transformation proven effective, especially heaped data, default across functions. STAR methods also support ways learning transformation alongside model: transformation='box-cox': transformation assumed belong Box-Cox family; sampler samples \\(\\lambda\\) parameter transformation='ispline': transformation modeled unknown, monotone function using -splines. Robust Adaptive Metropolis (RAM) sampler used drawing parameter transformation function. transformation='bnp': transformation modeled using Bayesian bootstrap, Bayesian nonparametric model incorporates uncertainty transformation posterior predictive inference. learned transformations always available every function; check appropriate help page see options supported.","code":""},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"count-valued-data-the-roaches-dataset","dir":"Articles","previous_headings":"","what":"Count-Valued Data: The Roaches Dataset","title":"Getting Started with countSTAR","text":"example complex count-valued data, consider roaches data Gelman Hill (2006). response variable, \\(y_i\\), number roaches caught traps apartment \\(\\), \\(=1,\\ldots, n = 262\\).  several notable features data: Zero-inflation: 36% observations zeros. (Right-) Skewness, clear histogram common (zero-inflated) count data. Overdispersion: sample mean 26 sample variance 2585. pest management treatment applied subset 158 apartments, remaining 104 apartments receiving control. Additional data available pre-treatment number roaches, whether apartment building restricted elderly residents, number days traps exposed. interested modeling roach incidence varies predictors.","code":"# Source: http://mc-stan.org/rstanarm/articles/count.html #install.packages(\"rstanarm\") data(roaches, package=\"rstanarm\")   # Roaches: y = roaches$y  # Function to plot the point mass function: stickplot = function(y, ...){   js = 0:max(y);    plot(js,         sapply(js, function(js) mean(js == y)),         type='h', lwd=2, ...) } stickplot(y, main = 'PMF: Roaches Data',           xlab = 'Roaches', ylab = 'Probability mass')"},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"frequentist-inference-for-star-models","dir":"Articles","previous_headings":"","what":"Frequentist inference for STAR models","title":"Getting Started with countSTAR","text":"Frequentist (classical) estimation inference STAR models provided EM algorithm. Sufficient estimation estimator function solves least squares (Gaussian maximum likelihood) problem associated \\(\\mu_\\theta\\)—words, estimator used Gaussian continuous data. Specifically, estimator inputs data outputs list two elements: estimated coefficients \\(\\hat \\theta\\) fitted.values \\(\\hat \\mu_\\theta(x_i) = \\mu_{\\hat \\theta}(x_i)\\).","code":""},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"the-classical-linear-model","dir":"Articles","previous_headings":"Frequentist inference for STAR models","what":"The Classical Linear Model","title":"Getting Started with countSTAR","text":"many applications, STAR linear model often first method try. countSTAR, linear model implemented lm_star function, aims mimic functionality lm allowing users input formula. Standard functions like coef fitted can used output extract coefficients fitted values, respectively. np transformation used, options available; see ?lm_star details. Based fitted STAR linear model, may obtain confidence intervals estimated coefficients using confint: Similarly, p-values available using likelihood ratio tests, can applied individual coefficients, \\[ H_0: \\beta_j= 0 \\quad \\mbox{vs} \\quad H_1: \\beta_j \\ne 0 \\] joint sets variables, analogous (partial) F-test: \\[ H_0: \\beta_1=\\ldots=\\beta_p = 0, \\quad \\mbox{vs.} \\quad H_1: \\beta_j \\ne 0 \\mbox{ } j=1,\\ldots,p \\] P-values individual coefficients well p-value effects computed pvals function. Finally, can get predictions new data points (training data) using predict, actually outputs samples . Optionally, prediction intervals can estimated using (plug-) predictive distribution MLEs (see ?predict.lmstar details). Note “plug-” predictive distribution crude approximation, better approaches uncertainty quantification available using Bayesian models.","code":"library(countSTAR)  # Select a transformation: transformation = 'np' # Estimated transformation using empirical CDF  # EM algorithm for STAR (using the log-link) fit_em = lm_star(y ~ roach1 + treatment + senior + log(exposure2),                  data = roaches, transformation = transformation)   # Dimensions: n = nrow(fit_em$X); p = ncol(fit_em$X)  # Fitted coefficients: round(coef(fit_em), 3) #>    (Intercept)         roach1      treatment         senior log(exposure2)  #>          0.035          0.006         -0.285         -0.321          0.216 # Confidence interval for all coefficients confint(fit_em) #>                      2.5 %       97.5 % #> (Intercept)    -0.13858060  0.198872330 #> roach1          0.00489405  0.007416968 #> treatment      -0.48767161 -0.086081478 #> senior         -0.54811128 -0.098880870 #> log(exposure2) -0.19866938  0.636754371 # P-values: print(pvals(fit_em)) #>        (Intercept)             roach1          treatment             senior  #>       6.973336e-01       1.887407e-18       5.600907e-03       4.862510e-03  #>     log(exposure2) Any linear effects  #>       3.072374e-01       9.271136e-20 #Compute the predictive draws (just using observed points here) y_pred = predict(fit_em)"},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"machine-learning-models","dir":"Articles","previous_headings":"Frequentist inference for STAR models","what":"Machine Learning Models","title":"Getting Started with countSTAR","text":"addition linear model, countSTAR also implementations STAR models paired flexible regression methods, particular random forests (randomForest_star()) generalized boosted machines (gbm_star()). functions, user directly inputs set predictors \\(X\\) alongside test points \\(X_{test}\\), can seen example frequentist models, functions output log-likelihood values MLEs, allows quick comparison model fit. case, seems GBM model better fit data, although backed performing --sample comparison two models.","code":"# Select a transformation: transformation = 'np' # Estimated transformation using empirical CDF  # Construct data matrix y = roaches$y X = roaches[, c(\"roach1\", \"treatment\", \"senior\", \"exposure2\")]  #Fit STAR with random forests fit_rf = randomForest_star(y, X, transformation = transformation)  #Fit STAR with GBM fit_gbm = gbm_star(y, X, transformation = transformation) #Look at -2*log-likelihood print(-2*c(fit_rf$logLik, fit_gbm$logLik)) #> [1] 1668.939 1594.113"},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"bayesian-inference-for-star-models","dir":"Articles","previous_headings":"","what":"Bayesian inference for STAR models","title":"Getting Started with countSTAR","text":"Bayesian model, STAR requires algorithm initializing sampling posterior distribution continuous data model. specifically, posterior inference STAR based Gibbs sampler, augments aforementioned continuous sampler draw \\([z^* | y, \\theta]\\). \\(\\Pi_\\theta\\) conditionally Gaussian, \\([z^* | y, \\theta]\\) truncated Gaussian distribution.","code":""},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"linear-model","dir":"Articles","previous_headings":"Bayesian inference for STAR models","what":"Linear Model","title":"Getting Started with countSTAR","text":"illustration, consider Bayesian linear regression model \\[\\begin{align*} z_i^* &= x_i'\\beta + \\epsilon_i, \\quad \\epsilon_i \\stackrel{iid}{\\sim}N(0, \\sigma^2) \\\\ \\sigma^2 &\\sim \\mbox{Gamma}(\\alpha=0.001, \\beta=0.001) \\;. \\end{align*}\\] model completed assigning prior structure \\(\\beta\\). default countSTAR Zellner’s g-prior, functionality, options available (namely horseshoe ridge priors). model estimated using blm_star(). Note Bayesian models countSTAR, user must supply design matrix \\(X\\) (predictions desired, matrix predictors test points). apply roaches data, now using default nonparametric transformation. default, function uses Gibbs sampler draw posterior, settings exact inference can performed (see Kowal Wu (2022) details). enable , one can simply set use_MCMC=FALSE. either case, output function much , exception \\(\\sigma\\) estimated priori thus posterior draws. Posterior expectations posterior credible intervals model available follows: may evaluate model based posterior diagnostics posterior predictive checks simulated versus observed proportion zeros. Posterior predictive checks easily visualized using bayesplot package.","code":"X = model.matrix(y ~ roach1 + treatment + senior + log(exposure2),                  data = roaches)  # Dimensions: n = nrow(X); p = ncol(X)  fit_blm = blm_star(y = y, X=X, transformation = 'np') # Posterior mean of each coefficient: round(coef(fit_blm),3) #>    (Intercept)         roach1      treatment         senior log(exposure2)  #>          0.029          0.006         -0.289         -0.325          0.222  # Credible intervals for regression coefficients ci_all_bayes = apply(fit_blm$post.beta,       2, function(x) quantile(x, c(.025, .975)))  # Rename and print: rownames(ci_all_bayes) = c('Lower', 'Upper') print(t(round(ci_all_bayes, 3))) #>                 Lower  Upper #> (Intercept)    -0.156  0.206 #> roach1          0.005  0.008 #> treatment      -0.497 -0.075 #> senior         -0.554 -0.101 #> log(exposure2) -0.209  0.653 # MCMC diagnostics for posterior draws of the regression coefficients plot(as.ts(fit_blm$post.beta), main = 'Trace plots', cex.lab = .75) # (Summary of) effective sample sizes across coefficients: getEffSize(fit_blm$post.beta) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>    3449    3613    3814    3835    3910    4390  # Posterior predictive check using bayesplot suppressMessages(library(bayesplot)) prop_zero <- function(y) mean(y == 0) (ppc_stat(y=roaches$y, yrep=fit_blm$post.pred, stat = \"prop_zero\"))"},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"bart-star","dir":"Articles","previous_headings":"Bayesian inference for STAR models","what":"BART STAR","title":"Getting Started with countSTAR","text":"One flexible model options use Bayesian Additive Regression Trees (BART; Chipman, George, McCulloch (2012)) latent regression model: , can perform posterior predictive checks. time plot densities.  Bayesian models, pointwise log-likelihoods WAIC values outputted model comparison. Using information, can see BART STAR model seems better fit linear model.","code":"#Get the model matrix of predictors (no intercept necessary) X = model.matrix(y ~ -1 + roach1 + treatment + senior + exposure2,                  data = roaches)  fit_bart = bart_star(y = y, X=X, transformation = 'np') #> [1] \"Burn-In Period\" #> [1] \"17.18 seconds remaining\" #> [1] \"14.63 seconds remaining\" #> [1] \"Starting sampling\" #> [1] \"19.5 seconds remaining\" #> [1] \"15.09 seconds remaining\" #> [1] \"9.6 seconds remaining\" #> [1] \"4.07 seconds remaining\" #> [1] \"Total time:  25 seconds\" ppc_dens_overlay(y=roaches$y, yrep=fit_bart$post.pred[1:50,]) waic <- c(fit_blm$WAIC, fit_bart$WAIC) names(waic) <- c(\"STAR w/ Linear Model\", \"STAR w/ BART\") print(waic) #> STAR w/ Linear Model         STAR w/ BART  #>             1687.752             1639.008"},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"other-models","dir":"Articles","previous_headings":"Bayesian inference for STAR models","what":"Other Models","title":"Getting Started with countSTAR","text":"countSTAR also implements Bayesian additive models. function bam_star(), can specify covariates modeled linearly others modeled non-linearly using spline bases. word warning, additive models take significantly longer fit. exploring relationship one predictor count outcome \\(y\\), one can also use spline regression implemented spline_star(). See appropriate help pages examples run models.","code":""},{"path":"https://bking124.github.io/countSTAR/articles/countSTAR.html","id":"count-time-series-modeling-warpdlm","dir":"Articles","previous_headings":"","what":"Count Time Series Modeling: warpDLM","title":"Getting Started with countSTAR","text":"point, attention focused static regression data depend time. However, ideas simultaneous transformation rounding extended time series domain King Kowal (2021). work, proposed linking time-dependent count data \\(y_t\\) powerful time series framework known Dynamic Linear Models (DLMs). DLM defined two equations: () observation equation, specifies observations related latent state vector (ii) state evolution equation, describes states updated Markovian fashion. concretely, represent following form: \\[\\begin{align*}     z_t &= F_t \\theta_t + v_t, \\quad v_t \\sim N_n(0, V_t) \\\\     \\theta_t &= G_t \\theta_{t-1} +  w_t, \\quad w_t \\sim N_p( 0, W_t) \\end{align*}\\] \\(t=1,\\ldots, T\\), \\(\\{ v_t, w_t\\}_{t=1}^T\\) mutually independent \\(\\theta_0 \\sim N_p(a_0, R_0)\\). course, given Gaussian assumptions model, DLM alone appropriate count data. Thus, warping operation (simultaneous transformation rounding) applied DLM, resulting count time series framework known warped DLM (warpDLM). explicitly, can written : \\[\\begin{align*}          y_t &= h \\circ g^{-1}(z_t) \\\\         \\{z_t\\}_{t=1}^T &\\sim \\text{DLM} \\end{align*}\\] DLM form shown earlier general. keep things simple, countSTAR implements options DLM, namely local level model local linear trend model. local level model (also known random walk noise model) univariate state \\(\\theta_t:=\\mu_t\\), DLM equations simply \\[\\begin{align*}     z_t &= \\mu_t + v_t, \\quad v_t \\sim N(0, V) \\\\     \\mu_t &= \\mu_{t-1} +  w_t, \\quad w_t \\sim N(0, W) \\end{align*}\\] local linear trend model extends local level model, incorporating time varying drift \\(\\nu_t\\) dynamics. often described following three equation format: \\[\\begin{align*}     z_t &= \\mu_t + v_t, \\quad v_t \\sim N(0, V) \\\\     \\mu_t &= \\mu_{t-1} + \\nu_{t-1} +  w_{\\mu,t}, \\quad w_{\\mu,t} \\sim N( 0, W_     \\mu) \\\\     \\nu_t &= \\nu_{t-1} +  w_{\\nu,t}, \\quad w_{\\nu,t} \\sim N( 0, W_\\nu) \\end{align*}\\] can turn recast general two-equation DLM form. Namely, let \\(\\theta_t:=(\\mu_t, \\nu_t)\\), local linear trend written \\[\\begin{align*} z_t & = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} \\mu_t \\\\ \\nu_t \\end{pmatrix} + v_t, \\quad v_t \\sim N(0, V) \\\\ \\begin{pmatrix} \\mu_t \\\\ \\nu_t \\end{pmatrix} & = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\begin{pmatrix} \\mu_{t-1} \\\\ \\nu_{t-1} \\end{pmatrix}  + \\boldsymbol{w_t}, \\quad \\boldsymbol{w_t} \\sim N\\begin{pmatrix} \\boldsymbol{0}, \\begin{bmatrix} W_     \\mu & 0 \\\\ 0 & W_\\nu \\end{bmatrix} \\end{pmatrix} \\end{align*}\\] two common forms long history also referred structural time series models (implemented base R via StructTS()). countSTAR, warpDLM time series modeling accomplished via warpDLM() function. , apply model time series dataset included base R concerning yearly numbers important discoveries 1860 1959 (?discoveries information).  , can check fit using posterior predictive checks. median posterior predictive draws can act sort count-valued smoother time series.","code":"#Visualize the data plot(discoveries) #Fit the model warpfit <- warpDLM(y=discoveries, type=\"trend\") #> [1] \"Time taken:  71.444  seconds\" ppc_ribbon(y=as.vector(discoveries), yrep=warpfit$post_pred)"},{"path":[]},{"path":"https://bking124.github.io/countSTAR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Brian King. Author, maintainer. Daniel R. Kowal. Author.","code":""},{"path":"https://bking124.github.io/countSTAR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"King B, Kowal DR (2023). countSTAR: Flexible Modeling Count Data. R package version 1.0.0, https://bking124.github.io/countSTAR/https://github.com/bking124/countSTAR.","code":"@Manual{,   title = {countSTAR: Flexible Modeling of Count Data},   author = {Brian King and Daniel R. Kowal},   year = {2023},   note = {R package version 1.0.0},   url = {https://bking124.github.io/countSTAR/ https://github.com/bking124/countSTAR}, }"},{"path":[]},{"path":"https://bking124.github.io/countSTAR/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Flexible Modeling of Count Data ","text":"Count-valued data common many fields. Frequently, count data observed jointly predictors, time intervals, across spatial locations. Furthermore, often exhibit variety complex distributional features, including zero-inflation, skewness, - underdispersion, cases may bounded censored. Flexible interpretable models count-valued processes therefore highly useful practice. countSTAR implements variety methods modeling processes, based idea Simultaneous Transformation Rounding (STAR). Estimation, inference, prediction STAR available Bayesian frequentist models. bulk methods serve static regression problems, package also supports time series analysis via warped Dynamic Linear Model (DLM) framework. Broadly, STAR defines count-valued probability model (1) specifying (conditionally) Gaussian model continuous latent data (2) connecting latent data observed data via transformation rounding operation. Importantly, STAR models highly flexible count-valued processes, provide capability model () discrete data, (ii) zero-inflation, (iii) - -dispersion, (iv) heaping, (v) bounded censored data. modularity STAR framework allows ability utilize wide variety different latent data models, can range simple forms like linear regression advanced machine learning methods random forests gradient boosting machines. countSTAR can installed loaded follows: Detailed information different options STAR models implemented countSTAR can found vignette, accessible website running command vignette(\"countSTAR\"). basic breakdown available modeling functions shown : addition ready use functions, users can also implement STAR methods custom latent regression models using genEM_star() genMCMC_star() functions. Please submit issues feature requests https://github.com/bking124/countSTAR/issues.","code":"#Development version remotes::install_github(\"bking124/countSTAR\") library(\"countSTAR\")"},{"path":"https://bking124.github.io/countSTAR/reference/BrentMethod.html","id":null,"dir":"Reference","previous_headings":"","what":"Brent's method for optimization — BrentMethod","title":"Brent's method for optimization — BrentMethod","text":"Implementation Brent's algorithm minimizing univariate function interval. code based function stsm package.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/BrentMethod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Brent's method for optimization — BrentMethod","text":"","code":"BrentMethod(a = 0, b, fcn, tol = .Machine$double.eps^0.25)"},{"path":"https://bking124.github.io/countSTAR/reference/BrentMethod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Brent's method for optimization — BrentMethod","text":"lower limit search b upper limit search fcn function minimize tol tolerance level convergence optimization procedure","code":""},{"path":"https://bking124.github.io/countSTAR/reference/BrentMethod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Brent's method for optimization — BrentMethod","text":"list containing following elements: fx minimum value input function x argument minimizes function iter number iterations converge vx vector stores arguments convergence","code":""},{"path":"https://bking124.github.io/countSTAR/reference/a_j.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse rounding function — a_j","title":"Inverse rounding function — a_j","text":"Define intervals associated y = j based flooring function. function returns -Inf j = 0 (smaller) Inf j >= y_max + 1, y_max known upper bound data y (specified).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/a_j.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse rounding function — a_j","text":"","code":"a_j(j, y_max = Inf)"},{"path":"https://bking124.github.io/countSTAR/reference/a_j.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse rounding function — a_j","text":"j integer-valued input(s) y_max fixed known upper bound observations; default Inf","code":""},{"path":"https://bking124.github.io/countSTAR/reference/a_j.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse rounding function — a_j","text":"(lower) interval endpoint(s) associated j.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/a_j.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse rounding function — a_j","text":"","code":"# Standard cases: a_j(1) #> [1] 1 a_j(20) #> [1] 20  # Boundary cases: a_j(0) #> [1] -Inf a_j(20, y_max = 15) #> [1] Inf"},{"path":"https://bking124.github.io/countSTAR/reference/bam_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Bayesian Additive STAR Model with MCMC — bam_star","title":"Fit Bayesian Additive STAR Model with MCMC — bam_star","text":"Run MCMC algorithm STAR Bayesian additive model transformation can known (e.g., log sqrt) unknown (Box-Cox estimated nonparametrically) greater flexibility.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bam_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Bayesian Additive STAR Model with MCMC — bam_star","text":"","code":"bam_star(   y,   X_lin,   X_nonlin,   splinetype = \"orthogonal\",   transformation = \"np\",   y_max = Inf,   nsave = 5000,   nburn = 5000,   nskip = 2,   save_y_hat = FALSE,   verbose = TRUE )"},{"path":"https://bking124.github.io/countSTAR/reference/bam_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Bayesian Additive STAR Model with MCMC — bam_star","text":"y n x 1 vector observed counts X_lin n x pL matrix predictors modelled linear X_nonlin n x pNL matrix predictors modelled nonlinear splinetype Type spline use modelling nonlinear predictors; must either \"orthogonal\" (orthogonalized splines--default) \"thinplate\" (low-rank thin plate splines) transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) \"ispline\" (transformation modeled unknown, monotone function using -splines) y_max fixed known upper bound observations; default Inf nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw save_y_hat logical; TRUE, compute save posterior draws expected counts, E(y), may slow compute verbose logical; TRUE, print time remaining","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bam_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Bayesian Additive STAR Model with MCMC — bam_star","text":"list least following elements: coefficients: posterior mean coefficients fitted.values: posterior mean conditional expectation counts y post.coefficients: posterior draws coefficients post.fitted.values: posterior draws conditional mean counts y post.pred: draws posterior predictive distribution y post.lambda: draws posterior distribution lambda post.sigma: draws posterior distribution sigma post.log.like.point: draws log-likelihood n observations WAIC: Widely-Applicable/Watanabe-Akaike Information Criterion p_waic: Effective number parameters based WAIC case transformation=\"ispline\", list also contains post.g: draws posterior distribution transformation g post.sigma.gamma: draws posterior distribution sigma.gamma, prior standard deviation transformation g() coefficients","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bam_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit Bayesian Additive STAR Model with MCMC — bam_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. Posterior predictive inference obtained via Gibbs sampler combines () latent data augmentation step (like probit regression) (ii) existing sampler continuous data model. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt', well version Box-Cox parameter inferred within MCMC sampler ('box-cox'). Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y. Third, transformation can modeled unknown, monotone function using -splines ('ispline'). Robust Adaptive Metropolis (RAM) sampler used drawing parameter transformation function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bam_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Bayesian Additive STAR Model with MCMC — bam_star","text":"","code":"if (FALSE) { # Simulate data with count-valued response y: sim_dat = simulate_nb_friedman(n = 100, p = 5, seed=32) y = sim_dat$y; X = sim_dat$X  # Linear and nonlinear components: X_lin = as.matrix(X[,-(1:3)]) X_nonlin = as.matrix(X[,(1:3)])  # STAR: nonparametric transformation fit <- bam_star(y,X_lin, X_nonlin)  # Posterior mean of each coefficient: coef(fit)  # WAIC: fit$WAIC  # MCMC diagnostics: plot(as.ts(fit$post.coefficients[,1:3]))  # Posterior predictive check: hist(apply(fit$post.pred, 1,            function(x) mean(x==0)), main = 'Proportion of Zeros', xlab=''); abline(v = mean(y==0), lwd=4, col ='blue')  }"},{"path":"https://bking124.github.io/countSTAR/reference/bart_star.html","id":null,"dir":"Reference","previous_headings":"","what":"MCMC Algorithm for BART-STAR — bart_star","title":"MCMC Algorithm for BART-STAR — bart_star","text":"Run MCMC algorithm BART model count-valued responses using STAR. transformation can known (e.g., log sqrt) unknown (Box-Cox estimated nonparametrically) greater flexibility.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bart_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MCMC Algorithm for BART-STAR — bart_star","text":"","code":"bart_star(   y,   X,   X_test = NULL,   y_test = NULL,   transformation = \"np\",   y_max = Inf,   n.trees = 200,   sigest = NULL,   sigdf = 3,   sigquant = 0.9,   k = 2,   power = 2,   base = 0.95,   nsave = 5000,   nburn = 5000,   nskip = 2,   save_y_hat = FALSE,   verbose = TRUE )"},{"path":"https://bking124.github.io/countSTAR/reference/bart_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MCMC Algorithm for BART-STAR — bart_star","text":"y n x 1 vector observed counts X n x p matrix predictors X_test n0 x p matrix predictors test data y_test n0 x 1 vector test data responses (used computing log-predictive scores) transformation transformation use latent process; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) \"ispline\" (transformation modeled unknown, monotone function using -splines) y_max fixed known upper bound observations; default Inf n.trees number trees use BART; default 200 sigest positive numeric estimate residual standard deviation (see ?bart) sigdf degrees freedom error variance prior (see ?bart) sigquant quantile error variance prior rough estimate (sigest) placed . closer quantile 1, aggressive fit (see ?bart) k number prior standard deviations E(Y|x) = f(x) away +/- 0.5. response internally scaled range -0.5 0.5. bigger k , conservative fitting (see ?bart) power power parameter tree prior (see ?bart) base base parameter tree prior (see ?bart) nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw save_y_hat logical; TRUE, compute save posterior draws expected counts, E(y), may slow compute verbose logical; TRUE, print time remaining","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bart_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MCMC Algorithm for BART-STAR — bart_star","text":"list following elements: post.pred: draws posterior predictive distribution y post.sigma: draws posterior distribution sigma post.log.like.point: draws log-likelihood n observations WAIC: Widely-Applicable/Watanabe-Akaike Information Criterion p_waic: Effective number parameters based WAIC post.pred.test: draws posterior predictive distribution test points X_test (NULL X_test given) post.fitted.values.test: posterior draws conditional mean test points X_test (NULL X_test given) post.mu.test: draws conditional mean z_star test points X_test (NULL X_test given) post.log.pred.test: draws log-predictive distribution n0 test cases (NULL X_test given) fitted.values: posterior mean conditional expectation counts y (NULL save_y_hat=FALSE) post.fitted.values: posterior draws conditional mean counts y (NULL save_y_hat=FALSE) case transformation=\"ispline\", list also contains post.g: draws posterior distribution transformation g post.sigma.gamma: draws posterior distribution sigma.gamma, prior standard deviation transformation g() coefficients transformation=\"box-cox\", list also contains post.lambda: draws posterior distribution lambda","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bart_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MCMC Algorithm for BART-STAR — bart_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. , model (1) Bayesian additive regression tree (BART) model. Posterior predictive inference obtained via Gibbs sampler combines () latent data augmentation step (like probit regression) (ii) existing sampler continuous data model. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt', well version Box-Cox parameter inferred within MCMC sampler ('box-cox'). Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y. Third, transformation can modeled unknown, monotone function using -splines ('ispline'). Robust Adaptive Metropolis (RAM) sampler used drawing parameter transformation function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bart_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MCMC Algorithm for BART-STAR — bart_star","text":"","code":"if (FALSE) { # Simulate data with count-valued response y: sim_dat = simulate_nb_friedman(n = 100, p = 10) y = sim_dat$y; X = sim_dat$X  # BART-STAR with log-transformation: fit_log = bart_star(y = y, X = X,                          transformation = 'log', save_y_hat = TRUE)  # Fitted values plot_fitted(y = sim_dat$Ey,             post_y = fit_log$post.fitted.values,             main = 'Fitted Values: BART-STAR-log')  # WAIC for BART-STAR-log: fit_log$WAIC  # MCMC diagnostics: plot(as.ts(fit_log$post.fitted.values[,1:10]))  # Posterior predictive check: hist(apply(fit_log$post.pred, 1,            function(x) mean(x==0)), main = 'Proportion of Zeros', xlab=''); abline(v = mean(y==0), lwd=4, col ='blue')  # BART-STAR with nonparametric transformation: fit = bart_star(y = y, X = X,                      transformation = 'np', save_y_hat = TRUE)  # Fitted values plot_fitted(y = sim_dat$Ey,             post_y = fit$post.fitted.values,             main = 'Fitted Values: BART-STAR-np')  # WAIC for BART-STAR-np: fit$WAIC  # MCMC diagnostics: plot(as.ts(fit$post.fitted.values[,1:10]))  # Posterior predictive check: hist(apply(fit$post.pred, 1,            function(x) mean(x==0)), main = 'Proportion of Zeros', xlab=''); abline(v = mean(y==0), lwd=4, col ='blue') }"},{"path":"https://bking124.github.io/countSTAR/reference/bart_star_ispline.html","id":null,"dir":"Reference","previous_headings":"","what":"MCMC sampler for BART-STAR with a monotone spline model\nfor the transformation — bart_star_ispline","title":"MCMC sampler for BART-STAR with a monotone spline model\nfor the transformation — bart_star_ispline","text":"Run MCMC algorithm BART model count-valued responses using STAR. transformation modeled unknown, monotone function using -splines. Robust Adaptive Metropolis (RAM) sampler used drawing parameter transformation function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bart_star_ispline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MCMC sampler for BART-STAR with a monotone spline model\nfor the transformation — bart_star_ispline","text":"","code":"bart_star_ispline(   y,   X,   X_test = NULL,   y_test = NULL,   lambda_prior = 1/2,   y_max = Inf,   n.trees = 200,   sigest = NULL,   sigdf = 3,   sigquant = 0.9,   k = 2,   power = 2,   base = 0.95,   nsave = 5000,   nburn = 5000,   nskip = 2,   save_y_hat = FALSE,   target_acc_rate = 0.3,   adapt_rate = 0.75,   stop_adapt_perc = 0.5,   verbose = TRUE )"},{"path":"https://bking124.github.io/countSTAR/reference/bart_star_ispline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MCMC sampler for BART-STAR with a monotone spline model\nfor the transformation — bart_star_ispline","text":"y n x 1 vector observed counts X n x p matrix predictors X_test n0 x p matrix predictors test data y_test n0 x 1 vector test data responses (used computing log-predictive scores) lambda_prior prior mean transformation g() Box-Cox function parameter lambda_prior y_max fixed known upper bound observations; default Inf n.trees number trees use BART; default 200 sigest positive numeric estimate residual standard deviation (see ?bart) sigdf degrees freedom error variance prior (see ?bart) sigquant quantile error variance prior rough estimate (sigest) placed . closer quantile 1, aggresive fit (see ?bart) k number prior standard deviations E(Y|x) = f(x) away +/- 0.5. response internally scaled range -0.5 0.5. bigger k , conservative fitting (see ?bart) power power parameter tree prior (see ?bart) base base parameter tree prior (see ?bart) nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw save_y_hat logical; TRUE, compute save posterior draws expected counts, E(y), may slow compute target_acc_rate target acceptance rate (zero one) adapt_rate rate adaptation RAM sampler (zero one) stop_adapt_perc stop adapting proposal covariance stop_adapt_perc*nburn verbose logical; TRUE, print time remaining","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bart_star_ispline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MCMC sampler for BART-STAR with a monotone spline model\nfor the transformation — bart_star_ispline","text":"list following elements: fitted.values: posterior mean conditional expectation counts y post.fitted.values: posterior draws conditional mean counts y post.pred.test: draws posterior predictive distribution test points X_test post.fitted.values.test: posterior draws conditional mean test points X_test post.pred: draws posterior predictive distribution y post.sigma: draws posterior distribution sigma post.mu.test: draws conditional mean z_star test points post.log.like.point: draws log-likelihood n observations post.log.pred.test: draws log-predictive distribution n0 test cases WAIC: Widely-Applicable/Watanabe-Akaike Information Criterion p_waic: Effective number parameters based WAIC post.g: draws posterior distribution transformation g post.sigma.gamma: draws posterior distribution sigma.gamma, prior standard deviation transformation g coefficients","code":""},{"path":"https://bking124.github.io/countSTAR/reference/bart_star_ispline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MCMC sampler for BART-STAR with a monotone spline model\nfor the transformation — bart_star_ispline","text":"","code":"if (FALSE) { # Simulate data with count-valued response y: sim_dat = simulate_nb_friedman(n = 100, p = 10) y = sim_dat$y; X = sim_dat$X  # BART-STAR with unknown I-spline transformation fit = countSTAR:::bart_star_ispline(y = y, X = X)  # Fitted values plot_fitted(y = sim_dat$Ey,             post_y = fit$post.fitted.values,             main = 'Fitted Values: BART-STAR-np')  # WAIC for BART-STAR-np: fit$WAIC  # MCMC diagnostics: plot(as.ts(fit$post.fitted.values[,1:10]))  # Posterior predictive check: hist(apply(fit$post.pred, 1,            function(x) mean(x==0)), main = 'Proportion of Zeros', xlab=''); abline(v = mean(y==0), lwd=4, col ='blue') }"},{"path":"https://bking124.github.io/countSTAR/reference/blm_star.html","id":null,"dir":"Reference","previous_headings":"","what":"STAR Bayesian Linear Regression — blm_star","title":"STAR Bayesian Linear Regression — blm_star","text":"Posterior inference STAR linear model","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"STAR Bayesian Linear Regression — blm_star","text":"","code":"blm_star(   y,   X,   X_test = NULL,   transformation = \"np\",   y_max = Inf,   prior = \"gprior\",   use_MCMC = TRUE,   nsave = 5000,   nburn = 5000,   nskip = 0,   method_sigma = \"mle\",   approx_Fz = FALSE,   approx_Fy = FALSE,   psi = NULL,   compute_marg = FALSE )"},{"path":"https://bking124.github.io/countSTAR/reference/blm_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"STAR Bayesian Linear Regression — blm_star","text":"y n x 1 vector observed counts X n x p matrix predictors X_test n0 x p matrix predictors test data transformation transformation use latent process; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) \"ispline\" (transformation modeled unknown, monotone function using -splines) \"bnp\" (Bayesian nonparametric transformation using Bayesian bootstrap) y_max fixed known upper bound observations; default Inf prior prior use latent linear regression; currently implemented options \"gprior\", \"horseshoe\", \"ridge\". modeling options transformations available latter two priors. use_MCMC = TRUE, nsave number MCMC iterations save (MC samples draw use_MCMC=FALSE) nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw method_sigma method estimate latent data standard deviation exact sampler; must one \"mle\" use MLE STAR EM algorithm \"mmle\" use marginal MLE (Note: slower!) approx_Fz logical; BNP transformation, apply (fast stable) normal approximation marginal CDF latent data approx_Fy logical; BNP transformation, approximate marginal CDF y using empirical CDF psi prior variance (g-prior) compute_marg logical; TRUE, compute return marginal likelihood (available using exact sampler, .e. use_MCMC=FALSE)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"STAR Bayesian Linear Regression — blm_star","text":"list least following elements: coefficients: posterior mean regression coefficients post.beta: posterior draws regression coefficients post.pred: draws posterior predictive distribution y post.log.like.point: draws log-likelihood n observations WAIC: Widely-Applicable/Watanabe-Akaike Information Criterion p_waic: Effective number parameters based WAIC test points passed , list also post.predtest, contains draws posterior predictive distribution test points. elements may present depending choice prior, transformation, sampling approach.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"STAR Bayesian Linear Regression — blm_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. , continuous latent data model linear regression. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt', well version Box-Cox parameter inferred within MCMC sampler ('box-cox'). Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y. distribution-based transformations approximately preserve mean variance count data y latent data scale, lends interpretability model parameters. Lastly, transformation can modeled using Bayesian bootstrap ('bnp'), Bayesian nonparametric model incorporates uncertainty transformation posterior predictive inference. Monte Carlo sampler (use_MCMC=FALSE) produces direct, discrete, joint draws posterior distribution posterior predictive distribution linear regression model g-prior.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"STAR Bayesian Linear Regression — blm_star","text":"'bnp' transformation (without Fy approximation) slower transformations way TruncatedNormal sampler must updated lower upper limits change (due sampling g). Thus, computational improvements likely available.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_bnpgibbs.html","id":null,"dir":"Reference","previous_headings":"","what":"Gibbs sampler for STAR linear regression with BNP transformation — blm_star_bnpgibbs","title":"Gibbs sampler for STAR linear regression with BNP transformation — blm_star_bnpgibbs","text":"Compute MCMC samples posterior predictive distributions STAR linear regression model g-prior BNP transformation.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_bnpgibbs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gibbs sampler for STAR linear regression with BNP transformation — blm_star_bnpgibbs","text":"","code":"blm_star_bnpgibbs(   y,   X,   X_test = X,   y_max = Inf,   psi = NULL,   approx_Fz = FALSE,   approx_Fy = FALSE,   nsave = 1000,   nburn = 1000,   nskip = 0,   verbose = TRUE )"},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_bnpgibbs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gibbs sampler for STAR linear regression with BNP transformation — blm_star_bnpgibbs","text":"y n x 1 vector observed counts X n x p matrix predictors X_test n0 x p matrix predictors test data; default observed covariates X y_max fixed known upper bound observations; default Inf psi prior variance (g-prior) approx_Fz logical; BNP transformation, apply (fast stable) normal approximation marginal CDF latent data approx_Fy logical; BNP transformation, approximate marginal CDF y using empirical CDF nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_bnpgibbs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gibbs sampler for STAR linear regression with BNP transformation — blm_star_bnpgibbs","text":"list following elements: coefficients posterior mean regression coefficients post_beta: nsave x p samples posterior distribution regression coefficients post_ytilde: nsave x n0 samples posterior predictive distribution test points X_test post_g: nsave posterior samples transformation evaluated unique y values (applies 'bnp' transformations)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_bnpgibbs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gibbs sampler for STAR linear regression with BNP transformation — blm_star_bnpgibbs","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. , continuous latent data model linear regression. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt'. Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y. distribution-based transformations approximately preserve mean variance count data y latent data scale, lends interpretability model parameters. Lastly, transformation can modeled using Bayesian bootstrap ('bnp'), Bayesian nonparametric model incorporates uncertainty transformation posterior predictive inference.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_bnpgibbs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gibbs sampler for STAR linear regression with BNP transformation — blm_star_bnpgibbs","text":"","code":"if (FALSE) { # Simulate some data: sim_dat = simulate_nb_lm(n = 500, p = 10) y = sim_dat$y; X = sim_dat$X  # Fit a linear model: fit = countSTAR:::blm_star_bnpgibbs(y, X, nsave = 1000, nburn = 1000) names(fit)  # Check the efficiency of the MCMC samples: getEffSize(fit$post_beta) }"},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_exact.html","id":null,"dir":"Reference","previous_headings":"","what":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"Compute direct Monte Carlo samples posterior predictive distributions STAR linear regression model g-prior.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_exact.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"","code":"blm_star_exact(   y,   X,   X_test = X,   transformation = \"np\",   y_max = Inf,   psi = NULL,   method_sigma = \"mle\",   approx_Fz = FALSE,   approx_Fy = FALSE,   nsave = 5000,   compute_marg = FALSE )"},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_exact.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"y n x 1 vector observed counts X n x p matrix predictors X_test n0 x p matrix predictors test data transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"bnp\" (Bayesian nonparametric transformation using Bayesian bootstrap) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) y_max fixed known upper bound observations; default Inf psi prior variance (g-prior) method_sigma method estimate latent data standard deviation; must one \"mle\" use MLE STAR EM algorithm \"mmle\" use marginal MLE (Note: slower!) approx_Fz logical; BNP transformation, apply (fast stable) normal approximation marginal CDF latent data approx_Fy logical; BNP transformation, approximate marginal CDF y using empirical CDF nsave number Monte Carlo simulations compute_marg logical; TRUE, compute return marginal likelihood","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_exact.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"list following elements: coefficients posterior mean regression coefficients post.beta: nsave x p samples posterior distribution regression coefficients post.pred: draws posterior predictive distribution y post.pred.test: nsave x n0 samples posterior predictive distribution test points X_test (given, otherwise NULL) sigma: estimated latent data standard deviation post.g: nsave posterior samples transformation evaluated unique y values (applies 'bnp' transformations) marg.like: marginal likelihood (requested; otherwise NULL)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_exact.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. , continuous latent data model linear regression. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt'. Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y. distribution-based transformations approximately preserve mean variance count data y latent data scale, lends interpretability model parameters. Lastly, transformation can modeled using Bayesian bootstrap ('bnp'), Bayesian nonparametric model incorporates uncertainty transformation posterior predictive inference. Monte Carlo sampler produces direct, discrete, joint draws posterior distribution posterior predictive distribution linear regression model g-prior.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_exact.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"'bnp' transformation (without Fy approximation) slower transformations way TruncatedNormal sampler must updated lower upper limits change (due sampling g). Thus, computational improvements likely available.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/blm_star_exact.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"","code":"if (FALSE) { # Simulate some data: sim_dat = simulate_nb_lm(n = 100, p = 10) y = sim_dat$y; X = sim_dat$X  # Fit a linear model: fit = countSTAR:::blm_star_exact(y, X) names(fit)  # Check the efficiency of the Monte Carlo samples: getEffSize(fit$post_beta) }"},{"path":"https://bking124.github.io/countSTAR/reference/computeTimeRemaining.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the remaining time in the MCMC based on previous samples — computeTimeRemaining","title":"Estimate the remaining time in the MCMC based on previous samples — computeTimeRemaining","text":"Estimate remaining time MCMC based previous samples","code":""},{"path":"https://bking124.github.io/countSTAR/reference/computeTimeRemaining.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the remaining time in the MCMC based on previous samples — computeTimeRemaining","text":"","code":"computeTimeRemaining(nsi, timer0, nsims, nrep = 1000)"},{"path":"https://bking124.github.io/countSTAR/reference/computeTimeRemaining.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the remaining time in the MCMC based on previous samples — computeTimeRemaining","text":"nsi Current iteration timer0 Initial timer value, returned proc.time()[3] nsims Total number simulations nrep Print estimated time remaining every nrep iterations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/computeTimeRemaining.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the remaining time in the MCMC based on previous samples — computeTimeRemaining","text":"Table summary statistics using function summary","code":""},{"path":"https://bking124.github.io/countSTAR/reference/confint.lmstar.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute asymptotic confidence intervals for STAR linear regression — confint.lmstar","title":"Compute asymptotic confidence intervals for STAR linear regression — confint.lmstar","text":"linear regression model within STAR framework, compute (asymptotic) confidence intervals regression coefficient interest. Confidence intervals computed inverting likelihood ratio test profiling log-likelihood.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/confint.lmstar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute asymptotic confidence intervals for STAR linear regression — confint.lmstar","text":"","code":"# S3 method for lmstar confint(object, parm, level = 0.95, ...)"},{"path":"https://bking124.github.io/countSTAR/reference/confint.lmstar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute asymptotic confidence intervals for STAR linear regression — confint.lmstar","text":"object Object class \"lmstar\" output lm_star parm specification parameters given confidence intervals, either vector numbers vector names. missing, parameters considered. level confidence level; default 0.95 ... Ignored","code":""},{"path":"https://bking124.github.io/countSTAR/reference/confint.lmstar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute asymptotic confidence intervals for STAR linear regression — confint.lmstar","text":"matrix (vector) columns giving lower upper confidence limits parameter. labelled (1-level)/2 1 - (1-level)/2 ","code":""},{"path":"https://bking124.github.io/countSTAR/reference/confint.lmstar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute asymptotic confidence intervals for STAR linear regression — confint.lmstar","text":"","code":"#Simulate data with count-valued response y: sim_dat = simulate_nb_lm(n = 100, p = 2) y = sim_dat$y; X = sim_dat$X  #Select a transformation: transformation = 'np'  #Estimate model fit = lm_star(y~X, transformation=transformation)  #Confidence interval for all parameters confint(fit) #>                  2.5 %    97.5 % #> (Intercept) -0.2518003 0.1193671 #> X            0.3052383 0.7190117"},{"path":"https://bking124.github.io/countSTAR/reference/credBands.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Simultaneous Credible Bands — credBands","title":"Compute Simultaneous Credible Bands — credBands","text":"Compute (1-alpha)% credible BANDS function based MCMC samples using Crainiceanu et al. (2007)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/credBands.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Simultaneous Credible Bands — credBands","text":"","code":"credBands(sampFuns, alpha = 0.05)"},{"path":"https://bking124.github.io/countSTAR/reference/credBands.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Simultaneous Credible Bands — credBands","text":"sampFuns Nsims x m matrix Nsims MCMC samples m points along curve alpha confidence level","code":""},{"path":"https://bking124.github.io/countSTAR/reference/credBands.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Simultaneous Credible Bands — credBands","text":"m x 2 matrix credible bands; first column lower band, second upper band","code":""},{"path":"https://bking124.github.io/countSTAR/reference/credBands.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute Simultaneous Credible Bands — credBands","text":"input needs curves: simultaneous credible \"bands\" may computed vectors. resulting credible intervals provide joint coverage (1-alpha) level across components vector.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/ergMean.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the ergodic (running) mean. — ergMean","title":"Compute the ergodic (running) mean. — ergMean","text":"Compute ergodic (running) mean.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/ergMean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the ergodic (running) mean. — ergMean","text":"","code":"ergMean(x)"},{"path":"https://bking124.github.io/countSTAR/reference/ergMean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the ergodic (running) mean. — ergMean","text":"x vector compute running mean","code":""},{"path":"https://bking124.github.io/countSTAR/reference/ergMean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the ergodic (running) mean. — ergMean","text":"vector y element defined y[] = mean(x[1:])","code":""},{"path":"https://bking124.github.io/countSTAR/reference/ergMean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the ergodic (running) mean. — ergMean","text":"","code":"# Compare: ergMean(1:10) #>  [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 mean(1:10) #> [1] 5.5  # Running mean for iid N(5, 1) samples: x = rnorm(n = 10^4, mean = 5, sd = 1) plot(ergMean(x)) abline(h=5)"},{"path":"https://bking124.github.io/countSTAR/reference/expectation2_gRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute E(Y^2) for a STAR process — expectation2_gRcpp","title":"Compute E(Y^2) for a STAR process — expectation2_gRcpp","text":"Compute conditional expectation Y^2 STAR process Y generic link function g.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation2_gRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute E(Y^2) for a STAR process — expectation2_gRcpp","text":"","code":"expectation2_gRcpp(g_a_j, g_a_jp1, mu, sigma, Jmax)"},{"path":"https://bking124.github.io/countSTAR/reference/expectation2_gRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute E(Y^2) for a STAR process — expectation2_gRcpp","text":"g_a_j Jmax x 1 vector g((j)) g_a_jp1 Jmax x 1 vector g((j + 1)) mu m x 1 vector conditional expectations sigma m x 1 vector conditional standard deviations Jmax m x 1 vector maximum integer values consider","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation2_gRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute E(Y^2) for a STAR process — expectation2_gRcpp","text":"y2_hat m x 1 vector conditional expectations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation2_gRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute E(Y^2) for a STAR process — expectation2_gRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_gRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the mean for a STAR process — expectation_gRcpp","title":"Estimate the mean for a STAR process — expectation_gRcpp","text":"Estimate conditional expectation STAR process generic link function g.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_gRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the mean for a STAR process — expectation_gRcpp","text":"","code":"expectation_gRcpp(g_a_j, g_a_jp1, mu, sigma, Jmax)"},{"path":"https://bking124.github.io/countSTAR/reference/expectation_gRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the mean for a STAR process — expectation_gRcpp","text":"g_a_j Jmax x 1 vector g((j)) g_a_jp1 Jmax x 1 vector g((j + 1)) mu m x 1 vector conditional expectations sigma m x 1 vector conditional standard deviations Jmax m x 1 vector maximum integer values consider","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_gRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the mean for a STAR process — expectation_gRcpp","text":"y_hat m x 1 vector conditional expectations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_gRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimate the mean for a STAR process — expectation_gRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_identity.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the mean for a STAR process — expectation_identity","title":"Estimate the mean for a STAR process — expectation_identity","text":"Estimate conditional expectation STAR process identity link function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_identity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the mean for a STAR process — expectation_identity","text":"","code":"expectation_identity(a, Jmax, Mu, sigma_t, Offset)"},{"path":"https://bking124.github.io/countSTAR/reference/expectation_identity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the mean for a STAR process — expectation_identity","text":"Jmaxmax-dimensional vector STAR integers a_j Jmax T x m matrix maximum integer values consider Mu T x m matrix latent means sigma_t T-dimensional vector time-dependent latent error sd's Offset T x m matrix offsets","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_identity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the mean for a STAR process — expectation_identity","text":"Zhat T x m matrix conditional expectations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_identity.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimate the mean for a STAR process — expectation_identity","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_log.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the mean for a STAR process — expectation_log","title":"Estimate the mean for a STAR process — expectation_log","text":"Estimate conditional expectation STAR process log link function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the mean for a STAR process — expectation_log","text":"","code":"expectation_log(a, Jmax, Mu, sigma_t, Offset)"},{"path":"https://bking124.github.io/countSTAR/reference/expectation_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the mean for a STAR process — expectation_log","text":"Jmaxmax-dimensional vector STAR integers a_j Jmax T x m matrix maximum integer values consider Mu T x m matrix latent means sigma_t T-dimensional vector time-dependent latent error sd's Offset T x m matrix offsets","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_log.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the mean for a STAR process — expectation_log","text":"Zhat T x m matrix conditional expectations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_log.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimate the mean for a STAR process — expectation_log","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_sqrt.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the mean for a STAR process — expectation_sqrt","title":"Estimate the mean for a STAR process — expectation_sqrt","text":"Estimate conditional expectation STAR process square root link function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_sqrt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the mean for a STAR process — expectation_sqrt","text":"","code":"expectation_sqrt(a, Jmax, Mu, sigma_t, Offset)"},{"path":"https://bking124.github.io/countSTAR/reference/expectation_sqrt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the mean for a STAR process — expectation_sqrt","text":"Jmaxmax-dimensional vector STAR integers a_j Jmax T x m matrix maximum integer values consider Mu T x m matrix latent means sigma_t T-dimensional vector time-dependent latent error sd's Offset T x m matrix offsets","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_sqrt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the mean for a STAR process — expectation_sqrt","text":"Zhat T x m matrix conditional expectations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/expectation_sqrt.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimate the mean for a STAR process — expectation_sqrt","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_bc.html","id":null,"dir":"Reference","previous_headings":"","what":"Box-Cox transformation — g_bc","title":"Box-Cox transformation — g_bc","text":"Evaluate Box-Cox transformation, scaled power transformation preserve continuity index lambda zero. Negative values permitted.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_bc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Box-Cox transformation — g_bc","text":"","code":"g_bc(t, lambda)"},{"path":"https://bking124.github.io/countSTAR/reference/g_bc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Box-Cox transformation — g_bc","text":"t argument(s) evaluate function lambda Box-Cox parameter","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_bc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Box-Cox transformation — g_bc","text":"evaluation(s) Box-Cox function given input(s) t.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_bc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Box-Cox transformation — g_bc","text":"Special cases include identity transformation (lambda = 1), square-root transformation (lambda = 1/2), log transformation (lambda = 0).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_bc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Box-Cox transformation — g_bc","text":"","code":"# Log-transformation: g_bc(1:5, lambda = 0); log(1:5) #> [1] 0.0000000 0.6931472 1.0986123 1.3862944 1.6094379 #> [1] 0.0000000 0.6931472 1.0986123 1.3862944 1.6094379  # Square-root transformation: note the shift and scaling g_bc(1:5, lambda = 1/2); sqrt(1:5) #> [1] 0.0000000 0.8284271 1.4641016 2.0000000 2.4721360 #> [1] 1.000000 1.414214 1.732051 2.000000 2.236068"},{"path":"https://bking124.github.io/countSTAR/reference/g_bnp.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian bootstrap-based transformation — g_bnp","title":"Bayesian bootstrap-based transformation — g_bnp","text":"Compute one posterior draw smoothed transformation implied (separate) Bayesian bootstrap models CDFs y X.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_bnp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian bootstrap-based transformation — g_bnp","text":"","code":"g_bnp(   y,   xtSigmax = rep(0, length(y)),   zgrid = NULL,   sigma_epsilon = 1,   approx_Fz = FALSE )"},{"path":"https://bking124.github.io/countSTAR/reference/g_bnp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian bootstrap-based transformation — g_bnp","text":"y n x 1 vector observed counts xtSigmax n x 1 vector t(X_i) Sigma_theta X_i, Sigma_theta prior variance zgrid optional vector grid points evaluating CDF z (Fz) sigma_epsilon latent standard deviation approx_Fz logical; TRUE, use normal approximation Fz, marginal CDF latent z, faster stable","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_bnp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian bootstrap-based transformation — g_bnp","text":"smooth monotone function can used evaluations transformation posterior draw.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_bnp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian bootstrap-based transformation — g_bnp","text":"","code":"if (FALSE) { # Sample some data: y = rpois(n = 200, lambda = 5) # Compute 200 draws of g on a grid: t = seq(0, max(y), length.out = 100) # grid g_post = t(sapply(1:500, function(s) g_bnp(y)(t))) # Plot together: plot(t, t, ylim = range(g_post), type='n', ylab = 'g(t)',  main = 'Bayesian bootstrap posterior: g') apply(g_post, 1, function(g) lines(t, g, col='gray')) # And the posterior mean of g: lines(t, colMeans(g_post), lwd=3) }"},{"path":"https://bking124.github.io/countSTAR/reference/g_cdf.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative distribution function (CDF)-based transformation — g_cdf","title":"Cumulative distribution function (CDF)-based transformation — g_cdf","text":"Compute CDF-based transformation using observed count data. CDF can estimated nonparametrically parametrically based Poisson Negative Binomial distributions. parametric case, parameters determined based moments y. Note fixed quantity come uncertainty quantification.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_cdf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative distribution function (CDF)-based transformation — g_cdf","text":"","code":"g_cdf(y, distribution = \"np\")"},{"path":"https://bking124.github.io/countSTAR/reference/g_cdf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative distribution function (CDF)-based transformation — g_cdf","text":"y n x 1 vector observed counts distribution distribution used CDF; must one \"np\" (empirical CDF) \"pois\" (moment-matched marginal Poisson CDF) \"neg-bin\" (moment-matched marginal Negative Binomial CDF)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_cdf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative distribution function (CDF)-based transformation — g_cdf","text":"smooth monotone function can used evaluations transformation.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_cdf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative distribution function (CDF)-based transformation — g_cdf","text":"","code":"# Sample some data: y = rpois(n = 500, lambda = 5)  # Empirical CDF version: g_np = g_cdf(y, distribution = 'np')  # Poisson version: g_pois = g_cdf(y, distribution = 'pois')  # Negative binomial version: g_negbin = g_cdf(y, distribution = 'neg-bin') #> Warning: 'neg-bin' not recommended for underdispersed data  # Plot together: t = 1:max(y) # grid plot(t, g_np(t), type='l') lines(t, g_pois(t), lty = 2) lines(t, g_negbin(t), lty = 3)"},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_approx.html","id":null,"dir":"Reference","previous_headings":"","what":"Approximate inverse transformation — g_inv_approx","title":"Approximate inverse transformation — g_inv_approx","text":"Compute inverse function transformation g based grid search.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_approx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Approximate inverse transformation — g_inv_approx","text":"","code":"g_inv_approx(g, t_grid)"},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_approx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Approximate inverse transformation — g_inv_approx","text":"g transformation function t_grid grid arguments evaluate transformation function","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_approx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Approximate inverse transformation — g_inv_approx","text":"function can used evaluations (approximate) inverse transformation function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_approx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Approximate inverse transformation — g_inv_approx","text":"","code":"# Sample some data: y = rpois(n = 500, lambda = 5)  # Empirical CDF transformation: g_np = g_cdf(y, distribution = 'np')  # Grid for approximation: t_grid = seq(1, max(y), length.out = 100)  # Approximate inverse: g_inv = g_inv_approx(g = g_np, t_grid = t_grid)  # Check the approximation: plot(t_grid, g_inv(g_np(t_grid)), type='p') lines(t_grid, t_grid)"},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_bc.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse Box-Cox transformation — g_inv_bc","title":"Inverse Box-Cox transformation — g_inv_bc","text":"Evaluate inverse Box-Cox transformation. Negative values permitted.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_bc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse Box-Cox transformation — g_inv_bc","text":"","code":"g_inv_bc(s, lambda)"},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_bc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse Box-Cox transformation — g_inv_bc","text":"s argument(s) evaluate function lambda Box-Cox parameter","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_bc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse Box-Cox transformation — g_inv_bc","text":"evaluation(s) inverse Box-Cox function given input(s) s.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/g_inv_bc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Inverse Box-Cox transformation — g_inv_bc","text":"Special cases include identity transformation (lambda = 1), square-root transformation (lambda = 1/2), log transformation (lambda = 0). #' @examples # (Inverse) log-transformation: g_inv_bc(1:5, lambda = 0); exp(1:5) # (Inverse) square-root transformation: note shift scaling g_inv_bc(1:5, lambda = 1/2); (1:5)^2","code":""},{"path":"https://bking124.github.io/countSTAR/reference/gbm_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"Compute MLEs log-likelihood Gradient Boosting Machines (GBM) STAR model. STAR model requires *transformation* *estimation function* conditional mean given observed data. transformation can known (e.g., log sqrt) unknown (Box-Cox estimated nonparametrically) greater flexibility. estimator case GBM. Standard function calls including fitted residuals apply.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/gbm_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"","code":"gbm_star(   y,   X,   X.test = NULL,   transformation = \"np\",   y_max = Inf,   sd_init = 10,   tol = 10^-10,   max_iters = 1000,   n.trees = 100,   interaction.depth = 1,   shrinkage = 0.1,   bag.fraction = 1 )"},{"path":"https://bking124.github.io/countSTAR/reference/gbm_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"y n x 1 vector observed counts X n x p matrix predictors X.test m x p matrix --sample predictors transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) y_max fixed known upper bound observations; default Inf sd_init add random noise EM algorithm initialization scaled sd_init times Gaussian MLE standard deviation; default 10 tol tolerance stopping EM algorithm; default 10^-10; max_iters maximum number EM iterations stopping; default 1000 n.trees Integer specifying total number trees fit. equivalent number iterations number basis functions additive expansion. Default 100. interaction.depth Integer specifying maximum depth tree (.e., highest level variable interactions allowed). value 1 implies additive model, value 2 implies model 2-way interactions, etc. Default 1. shrinkage shrinkage parameter applied tree expansion. Also known learning rate step-size reduction; 0.001 0.1 usually work, smaller learning rate typically requires trees. Default 0.1. bag.fraction fraction training set observations randomly selected propose next tree expansion. introduces randomnesses model fit. bag.fraction < 1 running model twice result similar different fits. Default 1 (deterministic prediction).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/gbm_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"list following elements: fitted.values: fitted values MLEs (training) fitted.values.test: fitted values MLEs (testing) g.hat function containing (known estimated) transformation sigma.hat MLE standard deviation mu.hat MLE conditional mean (transformed scale) z.hat estimated latent data (transformed scale) MLEs residuals Dunn-Smyth residuals (randomized) residuals_rep Dunn-Smyth residuals (randomized) 10 replicates logLik log-likelihood MLEs logLik0 log-likelihood MLEs *unrounded* initialization lambda Box-Cox nonlinear parameter gbmObj: object returned gbm() MLEs parameters (1) track parameters across EM iterations (2) record model specifications","code":""},{"path":"https://bking124.github.io/countSTAR/reference/gbm_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. Gaussian model case GBM.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/gbm_star.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"Infinite latent data values may occur transformed Gaussian model highly inadequate. case, function returns *indices* data points infinite latent values, significant outliers model. Deletion indices re-running model one option, care must taken ensure () appropriate treat observations outliers (ii) model adequate remaining data points.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/gbm_star.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"Kowal, D. R., & Wu, B. (2021). Semiparametric count data regression self‐reported mental health. Biometrics. doi:10.1111/biom.13617","code":""},{"path":"https://bking124.github.io/countSTAR/reference/gbm_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"","code":"# Simulate data with count-valued response y: sim_dat = simulate_nb_friedman(n = 100, p = 10) y = sim_dat$y; X = sim_dat$X  # EM algorithm for STAR (using the log-link) fit_em = gbm_star(y = y, X = X,                  transformation = 'log')  # Evaluate convergence: plot(fit_em$logLik_all, type='l', main = 'GBM-STAR-log', xlab = 'Iteration', ylab = 'log-lik')   # Fitted values: y_hat = fitted(fit_em) plot(y_hat, y);   # Residuals: plot(residuals(fit_em))  qqnorm(residuals(fit_em)); qqline(residuals(fit_em))   # Log-likelihood at MLEs: fit_em$logLik #> [1] -178.4761"},{"path":"https://bking124.github.io/countSTAR/reference/genEM_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized EM estimation for STAR — genEM_star","title":"Generalized EM estimation for STAR — genEM_star","text":"Compute MLEs log-likelihood generalized STAR model. STAR model requires *transformation* *estimation function* conditional mean given observed data. transformation can known (e.g., log sqrt) unknown (Box-Cox estimated nonparametrically) greater flexibility. estimator can least squares estimator, including nonlinear models. Standard function calls including coefficients(), fitted(), residuals() apply.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genEM_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized EM estimation for STAR — genEM_star","text":"","code":"genEM_star(   y,   estimator,   transformation = \"np\",   y_max = Inf,   sd_init = 10,   tol = 10^-10,   max_iters = 1000 )"},{"path":"https://bking124.github.io/countSTAR/reference/genEM_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized EM estimation for STAR — genEM_star","text":"y n x 1 vector observed counts estimator function inputs data y outputs list two elements: fitted values fitted.values parameter estimates coefficients transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) y_max fixed known upper bound observations; default Inf sd_init add random noise EM algorithm initialization scaled sd_init times Gaussian MLE standard deviation; default 10 tol tolerance stopping EM algorithm; default 10^-10; max_iters maximum number EM iterations stopping; default 1000","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genEM_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized EM estimation for STAR — genEM_star","text":"list following elements: coefficients MLEs coefficients fitted.values fitted values MLEs g.hat function containing (known estimated) transformation sigma.hat MLE standard deviation mu.hat MLE conditional mean (transformed scale) z.hat estimated latent data (transformed scale) MLEs residuals Dunn-Smyth residuals (randomized) residuals_rep Dunn-Smyth residuals (randomized) 10 replicates logLik log-likelihood MLEs logLik0 log-likelihood MLEs *unrounded* initialization lambda Box-Cox nonlinear parameter parameters (1) track parameters across EM iterations (2) record model specifications","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genEM_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized EM estimation for STAR — genEM_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. expectation-maximization (EM) algorithm used produce maximum likelihood estimators (MLEs) parameters defined estimator function, linear regression coefficients, define Gaussian model continuous latent data. Fitted values (point predictions), residuals, log-likelihood values also available. Inference estimators proceeds via classical maximum likelihood. Initialization EM algorithm can randomized monitor convergence. However, log-likelihood concave transformations (except 'box-cox'), global convergence guaranteed. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt', well version Box-Cox parameter estimated within EM algorithm ('box-cox'). Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genEM_star.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Generalized EM estimation for STAR — genEM_star","text":"Infinite latent data values may occur transformed Gaussian model highly inadequate. case, function returns *indices* data points infinite latent values, significant outliers model. Deletion indices re-running model one option, care must taken ensure () appropriate treat observations outliers (ii) model adequate remaining data points.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genEM_star.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized EM estimation for STAR — genEM_star","text":"Kowal, D. R., & Wu, B. (2021). Semiparametric count data regression self‐reported mental health. Biometrics. doi:10.1111/biom.13617","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genEM_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized EM estimation for STAR — genEM_star","text":"","code":"# Simulate data with count-valued response y: sim_dat = simulate_nb_friedman(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Select a transformation: transformation = 'np'  # Example using GAM as underlying estimator (for illustration purposes only) if(require(\"mgcv\")){   fit_em = genEM_star(y = y,                       estimator = function(y) gam(y ~ s(X1)+s(X2),                       data=data.frame(y,X)),                       transformation = transformation) } #> Loading required package: mgcv #> Loading required package: nlme #> This is mgcv 1.8-42. For overview type 'help(\"mgcv-package\")'.  # Fitted coefficients: coef(fit_em) #>   (Intercept)       s(X1).1       s(X1).2       s(X1).3       s(X1).4  #> -6.057058e-03  4.874655e-02 -9.795958e-02  2.061233e-02 -8.906490e-02  #>       s(X1).5       s(X1).6       s(X1).7       s(X1).8       s(X1).9  #> -3.218578e-02  9.005593e-02 -3.790662e-02  4.430970e-01  2.723014e-01  #>       s(X2).1       s(X2).2       s(X2).3       s(X2).4       s(X2).5  #>  1.961179e-11 -1.781289e-11  8.387266e-12  1.904315e-11  4.664960e-12  #>       s(X2).6       s(X2).7       s(X2).8       s(X2).9  #>  2.078905e-11 -1.438439e-12  9.635761e-11  1.544797e-01   # Fitted values: y_hat = fitted(fit_em) plot(y_hat, y);   # Log-likelihood at MLEs: fit_em$logLik #> [1] -205.719"},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized MCMC Algorithm for STAR — genMCMC_star","title":"Generalized MCMC Algorithm for STAR — genMCMC_star","text":"Run MCMC algorithm STAR given function initialize model parameters; function sample (.e., update) model parameters. transformation can known (e.g., log sqrt) unknown (Box-Cox estimated nonparametrically) greater flexibility.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized MCMC Algorithm for STAR — genMCMC_star","text":"","code":"genMCMC_star(   y,   sample_params,   init_params,   transformation = \"np\",   y_max = Inf,   nsave = 5000,   nburn = 5000,   nskip = 0,   save_y_hat = FALSE,   verbose = TRUE )"},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized MCMC Algorithm for STAR — genMCMC_star","text":"y n x 1 vector observed counts sample_params function inputs data y named list params containing mu: n x 1 vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu outputs updated list params samples full conditional posterior distribution coefficients sigma (updates mu) init_params initializing function inputs data y initializes named list params mu, sigma, coefficients transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) y_max fixed known upper bound observations; default Inf nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw save_y_hat logical; TRUE, compute save posterior draws expected counts, E(y), may slow compute verbose logical; TRUE, print time remaining","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized MCMC Algorithm for STAR — genMCMC_star","text":"list least following elements: post.pred: draws posterior predictive distribution y post.sigma: draws posterior distribution sigma post.log.like.point: draws log-likelihood n observations WAIC: Widely-Applicable/Watanabe-Akaike Information Criterion p_waic: Effective number parameters based WAIC post.lambda: draws posterior distribution lambda (NULL unless transformation='box-cox') fitted.values: posterior mean conditional expectation counts y (NULL save_y_hat=FALSE) post.fitted.values: posterior draws conditional mean counts y (NULL save_y_hat=FALSE) coefficients list init_params sample_params contains named element beta, e.g. linear regression, function output contains coefficients: posterior mean beta coefficients post.beta: draws posterior distribution beta post.othercoefs: draws posterior distribution sampled coefficients, e.g. variance terms beta exists parameter coefficients, output list just contains coefficients: posterior mean coefficients post.beta: draws posterior distribution coefficients Additionally, init_params sample_params output mu_test, sampler output post.predtest, contains draws posterior predictive distribution test points.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized MCMC Algorithm for STAR — genMCMC_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. Posterior predictive inference obtained via Gibbs sampler combines () latent data augmentation step (like probit regression) (ii) existing sampler continuous data model. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt', well version Box-Cox parameter inferred within MCMC sampler ('box-cox'). Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized MCMC Algorithm for STAR — genMCMC_star","text":"","code":"if (FALSE) { # Simulate data with count-valued response y: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # STAR: log-transformation: fit_log = genMCMC_star(y = y,                          sample_params = function(y, params) rSTAR:::sample_lm_gprior(y, X, params),                          init_params = function(y) rSTAR:::init_lm_gprior(y, X),                          transformation = 'log') # Posterior mean of each coefficient: coef(fit_log)  # WAIC for STAR-log: fit_log$WAIC  # MCMC diagnostics: plot(as.ts(fit_log$post.coefficients[,1:3]))  # Posterior predictive check: hist(apply(fit_log$post.pred, 1,            function(x) mean(x==0)), main = 'Proportion of Zeros', xlab=''); abline(v = mean(y==0), lwd=4, col ='blue')  }"},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star_ispline.html","id":null,"dir":"Reference","previous_headings":"","what":"MCMC sampler for STAR with a monotone spline model\nfor the transformation — genMCMC_star_ispline","title":"MCMC sampler for STAR with a monotone spline model\nfor the transformation — genMCMC_star_ispline","text":"Run MCMC algorithm STAR given function initialize model parameters; function sample (.e., update) model parameters. transformation modeled unknown, monotone function using -splines. Robust Adaptive Metropolis (RAM) sampler used drawing parameter transformation function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star_ispline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MCMC sampler for STAR with a monotone spline model\nfor the transformation — genMCMC_star_ispline","text":"","code":"genMCMC_star_ispline(   y,   sample_params,   init_params,   lambda_prior = 1/2,   y_max = Inf,   nsave = 5000,   nburn = 5000,   nskip = 0,   save_y_hat = FALSE,   target_acc_rate = 0.3,   adapt_rate = 0.75,   stop_adapt_perc = 0.5,   verbose = TRUE )"},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star_ispline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MCMC sampler for STAR with a monotone spline model\nfor the transformation — genMCMC_star_ispline","text":"y n x 1 vector observed counts sample_params function inputs data y named list params containing least mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu optionally fourth element mu_test contains vector conditional means test points. output updated list params samples full conditional posterior distribution coefficients sigma (along updates mu mu_test applicable) init_params initializing function inputs data y initializes named list params mu, sigma, coefficients mu_test (desired) lambda_prior prior mean transformation g() Box-Cox function parameter lambda_prior y_max fixed known upper bound observations; default Inf nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw save_y_hat logical; TRUE, compute save posterior draws expected counts, E(y), may slow compute target_acc_rate target acceptance rate (zero one) adapt_rate rate adaptation RAM sampler (zero one) stop_adapt_perc stop adapting proposal covariance stop_adapt_perc*nburn verbose logical; TRUE, print time remaining","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star_ispline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MCMC sampler for STAR with a monotone spline model\nfor the transformation — genMCMC_star_ispline","text":"list least following elements: post.pred: draws posterior predictive distribution y post.sigma: draws posterior distribution sigma post.log.like.point: draws log-likelihood n observations WAIC: Widely-Applicable/Watanabe-Akaike Information Criterion p_waic: Effective number parameters based WAIC post.g: draws posterior distribution transformation g post.sigma.gamma: draws posterior distribution sigma.gamma, prior standard deviation transformation g() coefficients fitted.values: posterior mean conditional expectation counts y (NULL save_y_hat=FALSE) post.fitted.values: posterior draws conditional mean counts y (NULL save_y_hat=FALSE) along elements depending nature initialization sampling functions. See details info.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star_ispline.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MCMC sampler for STAR with a monotone spline model\nfor the transformation — genMCMC_star_ispline","text":"coefficients list init_params sample_params contains named element beta, e.g. linear regression, function output contains coefficients: posterior mean beta coefficients post.beta: draws posterior distribution beta post.othercoefs: draws posterior distribution sampled coefficients, e.g. variance terms beta exists parameter coefficients, output list just contains coefficients: posterior mean coefficients post.beta: draws posterior distribution coefficients Additionally, init_params sample_params output mu_test, sampler output post.predtest, contains draws posterior predictive distribution test points.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/genMCMC_star_ispline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MCMC sampler for STAR with a monotone spline model\nfor the transformation — genMCMC_star_ispline","text":"","code":"if (FALSE) { # Simulate data with count-valued response y: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # STAR: unknown I-spline transformation fit = countSTAR:::genMCMC_star_ispline(y = y,                          sample_params = function(y, params) rSTAR:::sample_lm_gprior(y, X, params),                          init_params = function(y) rSTAR:::init_lm_gprior(y, X))  # Posterior mean of each coefficient: coef(fit)  # WAIC for STAR-np: fit$WAIC  # MCMC diagnostics: plot(as.ts(fit$post.coefficients[,1:3]))  # Posterior predictive check: hist(apply(fit$post.pred, 1,            function(x) mean(x==0)), main = 'Proportion of Zeros', xlab=''); abline(v = mean(y==0), lwd=4, col ='blue')  }"},{"path":"https://bking124.github.io/countSTAR/reference/getEffSize.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize of effective sample size — getEffSize","title":"Summarize of effective sample size — getEffSize","text":"Compute summary statistics effective sample size (ESS) across posterior samples possibly many variables","code":""},{"path":"https://bking124.github.io/countSTAR/reference/getEffSize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize of effective sample size — getEffSize","text":"","code":"getEffSize(postX)"},{"path":"https://bking124.github.io/countSTAR/reference/getEffSize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize of effective sample size — getEffSize","text":"postX array arbitrary dimension (nsims x ... x ...), nsims number posterior samples","code":""},{"path":"https://bking124.github.io/countSTAR/reference/getEffSize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize of effective sample size — getEffSize","text":"Table summary statistics using function summary().","code":""},{"path":"https://bking124.github.io/countSTAR/reference/getEffSize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize of effective sample size — getEffSize","text":"","code":"# ESS for iid simulations: rand_iid = rnorm(n = 10^4) getEffSize(rand_iid) #>  var1  #> 10000   # ESS for several AR(1) simulations with coefficients 0.1, 0.2,...,0.9: rand_ar1 = sapply(seq(0.1, 0.9, by = 0.1), function(x) arima.sim(n = 10^4, list(ar = x))) getEffSize(rand_ar1) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   545.9  1809.4  3284.2  3729.5  5152.0  7949.9"},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_orthog.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize the parameters for an additive model — init_bam_orthog","title":"Initialize the parameters for an additive model — init_bam_orthog","text":"Initialize parameters additive model, may contain linear nonlinear predictors. nonlinear terms modeled using orthogonalized splines.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_orthog.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize the parameters for an additive model — init_bam_orthog","text":"","code":"init_bam_orthog(y, X_lin, X_nonlin, B_all = NULL)"},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_orthog.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize the parameters for an additive model — init_bam_orthog","text":"y n x 1 vector data X_lin n x pL matrix predictors modelled linear X_nonlin n x pNL matrix predictors modelled nonlinear B_all optional pNL-dimensional list n x L[j] dimensional basis matrices nonlinear term j=1,...,pNL; NULL, compute internally","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_orthog.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize the parameters for an additive model — init_bam_orthog","text":"named list params containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_orthog.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize the parameters for an additive model — init_bam_orthog","text":"parameters coefficients : beta: p x 1 linear coefficients, including linear terms X_nonlin f_j: n x pNL matrix fitted values nonlinear function theta_j: pNL-dimensional nonlinear basis coefficients sigma_beta: p x 1 vector linear regression coefficient standard deviations sigma_theta_j: pNL x 1 vector nonlinear coefficient standard deviations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_orthog.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize the parameters for an additive model — init_bam_orthog","text":"","code":"if (FALSE) { # Simulate data for illustration: sim_dat = simulate_nb_friedman(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Linear and nonlinear components: X_lin = as.matrix(X[,-(1:3)]) X_nonlin = as.matrix(X[,(1:3)])  # Initialize: params = countSTAR:::init_bam_orthog(y = y,                          X_lin = X_lin,                          X_nonlin = X_nonlin) names(params) names(params$coefficients) }"},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_thin.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize the parameters for an additive model — init_bam_thin","title":"Initialize the parameters for an additive model — init_bam_thin","text":"Initialize parameters additive model, may contain linear nonlinear predictors. nonlinear terms modeled using low-rank thin plate splines.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_thin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize the parameters for an additive model — init_bam_thin","text":"","code":"init_bam_thin(y, X_lin, X_nonlin, B_all = NULL)"},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_thin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize the parameters for an additive model — init_bam_thin","text":"y n x 1 vector data X_lin n x pL matrix predictors modelled linear X_nonlin n x pNL matrix predictors modelled nonlinear B_all optional pNL-dimensional list n x L[j] dimensional basis matrices nonlinear term j=1,...,pNL; NULL, compute internally","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_thin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize the parameters for an additive model — init_bam_thin","text":"named list params containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_thin.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize the parameters for an additive model — init_bam_thin","text":"parameters coefficients : beta: p x 1 linear coefficients, including linear terms X_nonlin f_j: n x pNL matrix fitted values nonlinear function theta_j: pNL-dimensional nonlinear basis coefficients sigma_beta: p x 1 vector linear regression coefficient standard deviations sigma_theta_j: pNL x 1 vector nonlinear coefficient standard deviations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_bam_thin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize the parameters for an additive model — init_bam_thin","text":"","code":"if (FALSE) { # Simulate data for illustration: sim_dat = simulate_nb_friedman(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Linear and nonlinear components: X_lin = as.matrix(X[,-(1:3)]) X_nonlin = as.matrix(X[,(1:3)])  # Initialize: params = countSTAR:::init_bam_thin(y = y,                               X_lin = X_lin,                               X_nonlin = X_nonlin) names(params) names(params$coefficients) }"},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_gprior.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","title":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","text":"Initialize parameters linear regression model assuming g-prior coefficients.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_gprior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","text":"","code":"init_lm_gprior(y, X, X_test = NULL)"},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_gprior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","text":"y n x 1 vector data X n x p matrix predictors X_test n0 x p matrix predictors test points (default NULL)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_gprior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","text":"named list params containing least mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu Additionally, X_test NULL, list includes element mu_test, vector conditional means test points","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_gprior.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","text":"parameters coefficients : beta: p x 1 vector regression coefficients components beta","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_gprior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","text":"","code":"if (FALSE) { # Simulate data for illustration: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Initialize: params = countSTAR:::init_lm_gprior(y = y, X = X) names(params) names(params$coefficients) }"},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_hs.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","title":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","text":"Initialize parameters linear regression model assuming horseshoe prior (non-intercept) coefficients. number predictors p may exceed number observations n.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_hs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","text":"","code":"init_lm_hs(y, X, X_test = NULL)"},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_hs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","text":"y n x 1 vector data X n x p matrix predictors X_test n0 x p matrix predictors test points (default NULL)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_hs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","text":"named list params containing least mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu Additionally, X_test NULL, list includes element mu_test, vector conditional means test points","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_hs.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","text":"parameters coefficients : beta: p x 1 vector regression coefficients sigma_beta: p x 1 vector regression coefficient standard deviations (local scale parameters) xi_sigma_beta: p x 1 vector parameter-expansion variables sigma_beta lambda_beta: global scale parameter xi_lambda_beta: parameter-expansion variable lambda_beta components beta","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_hs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","text":"","code":"if (FALSE) { # Simulate data for illustration: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Initialize: params = countSTAR:::init_lm_hs(y = y, X = X) names(params) names(params$coefficients) }"},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_ridge.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","title":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","text":"Initialize parameters linear regression model assuming ridge prior (non-intercept) coefficients. number predictors p may exceed number observations n.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_ridge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","text":"","code":"init_lm_ridge(y, X, X_test = NULL)"},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_ridge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","text":"y n x 1 vector data X n x p matrix predictors X_test n0 x p matrix predictors test points (default NULL)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_ridge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","text":"named list params containing least mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu Additionally, X_test NULL, list includes element mu_test, vector conditional means test points","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_ridge.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","text":"parameters coefficients : beta: p x 1 vector regression coefficients sigma_beta: prior standard deviation (non-intercept) components beta","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_lm_ridge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","text":"","code":"if (FALSE) { # Simulate data for illustration: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Initialize: params = countSTAR:::init_lm_ridge(y = y, X = X) names(params) names(params$coefficients) }"},{"path":"https://bking124.github.io/countSTAR/reference/init_params_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize the parameters for a simple mean-only model — init_params_mean","title":"Initialize the parameters for a simple mean-only model — init_params_mean","text":"Initialize parameters model y ~ N(mu0, sigma^2) flat prior mu0.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_params_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize the parameters for a simple mean-only model — init_params_mean","text":"","code":"init_params_mean(y)"},{"path":"https://bking124.github.io/countSTAR/reference/init_params_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize the parameters for a simple mean-only model — init_params_mean","text":"y n x 1 vector data","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_params_mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize the parameters for a simple mean-only model — init_params_mean","text":"named list params containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu","code":""},{"path":"https://bking124.github.io/countSTAR/reference/init_params_mean.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize the parameters for a simple mean-only model — init_params_mean","text":"parameter coefficients mu0. Although redundant , parametrization useful functions.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/interval_gRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate confidence intervals/bands for a STAR process — interval_gRcpp","title":"Estimate confidence intervals/bands for a STAR process — interval_gRcpp","text":"Compute confidence intervals/bands expected value count-valued STAR process y based intervals/bands Gaussian process mu.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/interval_gRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate confidence intervals/bands for a STAR process — interval_gRcpp","text":"","code":"interval_gRcpp(g_a_j, g_a_jp1, L_mu, U_mu, sigma, Jmax)"},{"path":"https://bking124.github.io/countSTAR/reference/interval_gRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate confidence intervals/bands for a STAR process — interval_gRcpp","text":"g_a_j Jmax x 1 vector g((j)) g_a_jp1 Jmax x 1 vector g((j + 1)) L_mu m x 1 vector lower intervals mu U_mu m x 1 vector upper intervals mu sigma m x 1 vector conditional standard deviations Jmax m x 1 vector maximum integer values consider","code":""},{"path":"https://bking124.github.io/countSTAR/reference/interval_gRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate confidence intervals/bands for a STAR process — interval_gRcpp","text":"LU_y m x 2 vector intervals y.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/interval_gRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimate confidence intervals/bands for a STAR process — interval_gRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/invlogit.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the inverse log-odds — invlogit","title":"Compute the inverse log-odds — invlogit","text":"Compute inverse log-odds","code":""},{"path":"https://bking124.github.io/countSTAR/reference/invlogit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the inverse log-odds — invlogit","text":"","code":"invlogit(x)"},{"path":"https://bking124.github.io/countSTAR/reference/invlogit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the inverse log-odds — invlogit","text":"x scalar vector compute (componentwise) inverse log-odds","code":""},{"path":"https://bking124.github.io/countSTAR/reference/invlogit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the inverse log-odds — invlogit","text":"scalar vector values (0,1)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/invlogit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the inverse log-odds — invlogit","text":"","code":"if (FALSE) { x = seq(-5, 5, length.out = 10^3) plot(x, countSTAR:::invlogit(x)) }"},{"path":"https://bking124.github.io/countSTAR/reference/lm_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting frequentist STAR linear model via EM algorithm — lm_star","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"Compute MLEs log-likelihood STAR linear model. regression coefficients estimated using least squares within EM algorithm.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/lm_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"","code":"lm_star(   formula,   data = NULL,   transformation = \"np\",   y_max = Inf,   sd_init = 10,   tol = 10^-10,   max_iters = 1000 )"},{"path":"https://bking124.github.io/countSTAR/reference/lm_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"formula object class \"formula\" (see lm details model specification) data optional data frame, list environment (object coercible .data.frame data frame) containing variables model; like lm, found data, variables taken environment(formula) transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) y_max fixed known upper bound observations; default Inf sd_init add random noise EM algorithm initialization scaled sd_init times Gaussian MLE standard deviation; default 10 tol tolerance stopping EM algorithm; default 10^-10; max_iters maximum number EM iterations stopping; default 1000","code":""},{"path":"https://bking124.github.io/countSTAR/reference/lm_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"object class \"lmstar\", list following elements: coefficients MLEs coefficients fitted.values fitted values MLEs g.hat function containing (known estimated) transformation ginv.hat function containing inverse transformation sigma.hat MLE standard deviation mu.hat MLE conditional mean (transformed scale) z.hat estimated latent data (transformed scale) MLEs residuals Dunn-Smyth residuals (randomized) residuals_rep Dunn-Smyth residuals (randomized) 10 replicates logLik log-likelihood MLEs logLik0 log-likelihood MLEs *unrounded* initialization lambda Box-Cox nonlinear parameter parameters (1) track parameters across EM iterations (2) record model specifications","code":""},{"path":"https://bking124.github.io/countSTAR/reference/lm_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"Standard function calls including coefficients, fitted, residuals apply. Fitted values expectation MLEs, necessarily count-valued.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/lm_star.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"Infinite latent data values may occur transformed Gaussian model highly inadequate. case, function returns *indices* data points infinite latent values, significant outliers model. Deletion indices re-running model one option, care must taken ensure () appropriate treat observations outliers (ii) model adequate remaining data points.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/lm_star.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"Kowal, D. R., & Wu, B. (2021). Semiparametric count data regression self‐reported mental health. Biometrics. doi:10.1111/biom.13617","code":""},{"path":"https://bking124.github.io/countSTAR/reference/lm_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"","code":"# Simulate data with count-valued response y: sim_dat = simulate_nb_lm(n = 100, p = 3) y = sim_dat$y; X = sim_dat$X  # Fit model fit_em = lm_star(y~X)  # Fitted coefficients: coef(fit_em) #> (Intercept)          X1          X2  #>  0.02571273  0.43177374 -0.03639216  # Fitted values: y_hat = fitted(fit_em) plot(y_hat, y);   # Residuals: plot(residuals(fit_em))  qqnorm(residuals(fit_em)); qqline(residuals(fit_em))"},{"path":"https://bking124.github.io/countSTAR/reference/logLikePointRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the pointwise log-likelihood for STAR — logLikePointRcpp","title":"Compute the pointwise log-likelihood for STAR — logLikePointRcpp","text":"Compute pointwise log-likelihood STAR model. code assumes transformed real-valued process (z_star) conditionally independent components means mu standard deviations sigma.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logLikePointRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the pointwise log-likelihood for STAR — logLikePointRcpp","text":"","code":"logLikePointRcpp(g_a_j, g_a_jp1, mu, sigma)"},{"path":"https://bking124.github.io/countSTAR/reference/logLikePointRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the pointwise log-likelihood for STAR — logLikePointRcpp","text":"g_a_j m x 1 vector g((j)) g_a_jp1 m x 1 vector g((j + 1)) mu m x 1 vector conditional expectations sigma m x 1 vector conditional standard deviations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logLikePointRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the pointwise log-likelihood for STAR — logLikePointRcpp","text":"loglike m x 1 log-likelihood value","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logLikePointRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute the pointwise log-likelihood for STAR — logLikePointRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logLikeRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the log-likelihood for STAR — logLikeRcpp","title":"Compute the log-likelihood for STAR — logLikeRcpp","text":"Compute log-likelihood STAR model. code assumes transformed real-valued process (z_star) conditionally independent components means mu standard deviations sigma.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logLikeRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the log-likelihood for STAR — logLikeRcpp","text":"","code":"logLikeRcpp(g_a_j, g_a_jp1, mu, sigma)"},{"path":"https://bking124.github.io/countSTAR/reference/logLikeRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the log-likelihood for STAR — logLikeRcpp","text":"g_a_j m x 1 vector g((j)) g_a_jp1 m x 1 vector g((j + 1)) mu m x 1 vector conditional expectations sigma m x 1 vector conditional standard deviations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logLikeRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the log-likelihood for STAR — logLikeRcpp","text":"loglike scalar log-likelihood value","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logLikeRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute the log-likelihood for STAR — logLikeRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logit.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the log-odds — logit","title":"Compute the log-odds — logit","text":"Compute log-odds","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the log-odds — logit","text":"","code":"logit(x)"},{"path":"https://bking124.github.io/countSTAR/reference/logit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the log-odds — logit","text":"x scalar vector (0,1) compute (componentwise) log-odds","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the log-odds — logit","text":"scalar vector log-odds","code":""},{"path":"https://bking124.github.io/countSTAR/reference/logit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the log-odds — logit","text":"","code":"if (FALSE) { x = seq(0, 1, length.out = 10^3) plot(x, countSTAR:::logit(x)) }"},{"path":"https://bking124.github.io/countSTAR/reference/plot_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the estimated regression coefficients and credible intervals — plot_coef","title":"Plot the estimated regression coefficients and credible intervals — plot_coef","text":"Plot estimated regression coefficients credible intervals linear effects two models.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/plot_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the estimated regression coefficients and credible intervals — plot_coef","text":"","code":"plot_coef(   post_coefficients_1,   post_coefficients_2 = NULL,   alpha = 0.05,   labels = NULL )"},{"path":"https://bking124.github.io/countSTAR/reference/plot_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the estimated regression coefficients and credible intervals — plot_coef","text":"post_coefficients_1 Nsims x p matrix simulations posterior distribution p coefficients, Nsims number simulations post_coefficients_2 Nsims x p matrix simulations posterior distribution p coefficients another model alpha confidence level credible intervals labels p dimensional string labels coefficient names","code":""},{"path":"https://bking124.github.io/countSTAR/reference/plot_fitted.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the fitted values and the data — plot_fitted","title":"Plot the fitted values and the data — plot_fitted","text":"Plot fitted values, plus pointwise credible intervals, data. simulations, one may use true values place data.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/plot_fitted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the fitted values and the data — plot_fitted","text":"","code":"plot_fitted(y, post_y, y_hat = NULL, alpha = 0.05, ...)"},{"path":"https://bking124.github.io/countSTAR/reference/plot_fitted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the fitted values and the data — plot_fitted","text":"y n x 1 vector data post_y Nsims x n matrix simulated fitted values, Nsims number simulations y_hat n x 1 vector fitted values; NULL, use pointwise sample mean colMeans(post_y) alpha confidence level credible intervals ... arguments plotting","code":""},{"path":"https://bking124.github.io/countSTAR/reference/plot_pmf.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the empirical and model-based probability mass functions — plot_pmf","title":"Plot the empirical and model-based probability mass functions — plot_pmf","text":"Plot empirical probability mass function, .e., proportion data values y equal j j=0,1,..., together model-based estimate probability mass function based posterior predictive distribution.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/plot_pmf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the empirical and model-based probability mass functions — plot_pmf","text":"","code":"plot_pmf(y, post.pred, error.bars = FALSE, alpha = 0.05)"},{"path":"https://bking124.github.io/countSTAR/reference/plot_pmf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the empirical and model-based probability mass functions — plot_pmf","text":"y n x 1 vector data post.pred nsave draws posterior predictive distribution y error.bars logical; TRUE, include errors bars model-based PMF alpha confidence level credible intervals","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pmaxRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"pmax() in Rcpp — pmaxRcpp","title":"pmax() in Rcpp — pmaxRcpp","text":"Compute pointwise max two vectors equal length","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pmaxRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pmax() in Rcpp — pmaxRcpp","text":"","code":"pmaxRcpp(v1, v2)"},{"path":"https://bking124.github.io/countSTAR/reference/pmaxRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pmax() in Rcpp — pmaxRcpp","text":"v1 m x 1 vector v2 m x 1 vector","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pmaxRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"pmax() in Rcpp — pmaxRcpp","text":"vm m x 1 vector pointwise maxima","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pmaxRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"pmax() in Rcpp — pmaxRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pminRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"pmin() in Rcpp — pminRcpp","title":"pmin() in Rcpp — pminRcpp","text":"Compute pointwise min two vectors equal length","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pminRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pmin() in Rcpp — pminRcpp","text":"","code":"pminRcpp(v1, v2)"},{"path":"https://bking124.github.io/countSTAR/reference/pminRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pmin() in Rcpp — pminRcpp","text":"v1 m x 1 vector v2 m x 1 vector","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pminRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"pmin() in Rcpp — pminRcpp","text":"vm m x 1 vector pointwise minima","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pminRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"pmin() in Rcpp — pminRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/predict.lmstar.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict method for response in STAR linear model — predict.lmstar","title":"Predict method for response in STAR linear model — predict.lmstar","text":"Outputs predicted values based lmstar fit optionally prediction intervals based (plug-) predictive distribution STAR linear model","code":""},{"path":"https://bking124.github.io/countSTAR/reference/predict.lmstar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict method for response in STAR linear model — predict.lmstar","text":"","code":"# S3 method for lmstar predict(object, newdata = NULL, interval = FALSE, level = 0.95, N = 1000, ...)"},{"path":"https://bking124.github.io/countSTAR/reference/predict.lmstar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict method for response in STAR linear model — predict.lmstar","text":"object Object class \"lmstar\" output lm_star newdata optional matrix/data frame  look variables predict. omitted, fitted values used. interval logical; whether include prediction intervals (default FALSE) level Level prediction intervals N number Monte Carlo samples posterior predictive distribution used approximate intervals; default 1000 ... Ignored","code":""},{"path":"https://bking124.github.io/countSTAR/reference/predict.lmstar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict method for response in STAR linear model — predict.lmstar","text":"Either vector predictions (interval=FALSE) matrix predictions bounds column names fit, lwr, upr","code":""},{"path":"https://bking124.github.io/countSTAR/reference/predict.lmstar.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predict method for response in STAR linear model — predict.lmstar","text":"interval=TRUE, predict.lmstar uses Monte Carlo approach estimating (plug-) predictive distribution STAR linear model. algorithm iteratively samples () latent data given observed data, (ii) latent predictive data given latent data (), (iii) (inverse) transforms rounds latent predictive data obtain draw integer-valued predictive distribution. appropriate quantiles Monte Carlo draws computed reported prediction interval.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/predict.lmstar.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Predict method for response in STAR linear model — predict.lmstar","text":"``plug-\" predictive distribution crude approximation. Better approaches available using Bayesian models, e.g. blm_star, provide samples posterior predictive distribution. highly skewed responses, prediction intervals especially lower levels may include predicted value , since mean often much larger median.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/predict.lmstar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict method for response in STAR linear model — predict.lmstar","text":"","code":"# Simulate data with count-valued response y: x = seq(0, 1, length.out = 100) y = rpois(n = length(x), lambda = exp(1.5 + 5*(x -.5)^2))  # Estimate model--assume a quadratic effect (better for illustration purposes) fit = lm_star(y~x+I(x^2), transformation = 'sqrt')  #Compute the predictive draws for the test points (same as observed points here) #Also compute intervals using plug-in predictive distribution y_pred = predict(fit, interval=TRUE)  # Plot the results plot(x, y, ylim = range(y, y_pred), main = 'STAR: Predictions and 95% PI') lines(x,y_pred[,\"fit\"], col='black', type='s', lwd=4) lines(x, y_pred[,\"lwr\"], col='darkgray', type='s', lwd=4) lines(x, y_pred[,\"upr\"], col='darkgray', type='s', lwd=4)"},{"path":"https://bking124.github.io/countSTAR/reference/pvals.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute coefficient p-values for STAR linear regression using likelihood ratio test — pvals","title":"Compute coefficient p-values for STAR linear regression using likelihood ratio test — pvals","text":"linear regression model within STAR framework, compute p-values regression coefficients using likelihood ratio test. also computes p-value excluding predictors, akin (partial) F test.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pvals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute coefficient p-values for STAR linear regression using likelihood ratio test — pvals","text":"","code":"pvals(object)"},{"path":"https://bking124.github.io/countSTAR/reference/pvals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute coefficient p-values for STAR linear regression using likelihood ratio test — pvals","text":"object Object class \"lmstar\" output lm_star","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pvals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute coefficient p-values for STAR linear regression using likelihood ratio test — pvals","text":"list p+1 p-values, one predictor well joint p-value excluding predictors","code":""},{"path":"https://bking124.github.io/countSTAR/reference/pvals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute coefficient p-values for STAR linear regression using likelihood ratio test — pvals","text":"","code":"# Simulate data with count-valued response y: sim_dat = simulate_nb_lm(n = 100, p = 2) y = sim_dat$y; X = sim_dat$X  # Select a transformation: transformation = 'np'  #Estimate model fit = lm_star(y~X, transformation = transformation)  #Compute p-values pvals(fit) #>        (Intercept)                  X Any linear effects  #>       7.416366e-01       1.870461e-06       1.870468e-06"},{"path":"https://bking124.github.io/countSTAR/reference/randomForest_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Random Forest STAR with EM algorithm — randomForest_star","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"Compute MLEs log-likelihood Random Forest STAR model. STAR model requires *transformation* *estimation function* conditional mean given observed data. transformation can known (e.g., log sqrt) unknown (Box-Cox estimated nonparametrically) greater flexibility. estimator case random forest. Standard function calls including fitted residuals apply.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/randomForest_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"","code":"randomForest_star(   y,   X,   X.test = NULL,   transformation = \"np\",   y_max = Inf,   sd_init = 10,   tol = 10^-10,   max_iters = 1000,   ntree = 500,   mtry = max(floor(ncol(X)/3), 1),   nodesize = 5 )"},{"path":"https://bking124.github.io/countSTAR/reference/randomForest_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"y n x 1 vector observed counts X n x p matrix predictors X.test m x p matrix --sample predictors transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) y_max fixed known upper bound observations; default Inf sd_init add random noise EM algorithm initialization scaled sd_init times Gaussian MLE standard deviation; default 10 tol tolerance stopping EM algorithm; default 10^-10; max_iters maximum number EM iterations stopping; default 1000 ntree Number trees grow. set small number, ensure every input row gets predicted least times. Default 500. mtry Number variables randomly sampled candidates split. Default p/3. nodesize Minimum size terminal nodes. Setting number larger causes smaller trees grown (thus take less time). Default 5.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/randomForest_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"list following elements: fitted.values: fitted values MLEs based --bag samples (training) fitted.values.test: fitted values MLEs (testing) g.hat function containing (known estimated) transformation sigma.hat MLE standard deviation mu.hat MLE conditional mean (transformed scale) z.hat estimated latent data (transformed scale) MLEs residuals Dunn-Smyth residuals (randomized) residuals_rep Dunn-Smyth residuals (randomized) 10 replicates logLik log-likelihood MLEs logLik0 log-likelihood MLEs *unrounded* initialization lambda Box-Cox nonlinear parameter rfObj: object returned randomForest() MLEs parameters (1) track parameters across EM iterations (2) record model specifications","code":""},{"path":"https://bking124.github.io/countSTAR/reference/randomForest_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. expectation-maximization (EM) algorithm used produce maximum likelihood estimators (MLEs) parameters defined fitted values computed using --bag samples. result, log-likelihood based --bag prediction, similarly straightforward compute --bag squared absolute errors.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/randomForest_star.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"Since random forest produces random predictions, EM algorithm never converge exactly. Infinite latent data values may occur transformed Gaussian model highly inadequate. case, function returns *indices* data points infinite latent values, significant outliers model. Deletion indices re-running model one option, care must taken ensure () appropriate treat observations outliers (ii) model adequate remaining data points.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/randomForest_star.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"Kowal, D. R., & Wu, B. (2021). Semiparametric count data regression self‐reported mental health. Biometrics. doi:10.1111/biom.13617","code":""},{"path":"https://bking124.github.io/countSTAR/reference/randomForest_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"","code":"if (FALSE) { # Simulate data with count-valued response y: sim_dat = simulate_nb_friedman(n = 100, p = 10) y = sim_dat$y; X = sim_dat$X  # EM algorithm for STAR (using the log-link) fit_em = randomForest_star(y = y, X = X,                  transformation = 'log',                  max_iters = 100)  # Fitted values (out-of-bag) y_hat = fitted(fit_em) plot(y_hat, y);  # Residuals: plot(residuals(fit_em)) qqnorm(residuals(fit_em)); qqline(residuals(fit_em))  # Log-likelihood at MLEs (out-of-bag): fit_em$logLik }"},{"path":"https://bking124.github.io/countSTAR/reference/round_floor.html","id":null,"dir":"Reference","previous_headings":"","what":"Rounding function — round_floor","title":"Rounding function — round_floor","text":"Define rounding operator associated floor function. function also returns zero whenever input negative caps value y_max, y_max known upper bound data y (specified).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/round_floor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rounding function — round_floor","text":"","code":"round_floor(z, y_max = Inf)"},{"path":"https://bking124.github.io/countSTAR/reference/round_floor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rounding function — round_floor","text":"z real-valued input(s) y_max fixed known upper bound observations; default Inf","code":""},{"path":"https://bking124.github.io/countSTAR/reference/round_floor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rounding function — round_floor","text":"count-valued output(s) rounding function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/round_floor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rounding function — round_floor","text":"","code":"# Floor function: round_floor(1.5) #> [1] 1 round_floor(0.5) #> [1] 0  # Special treatmeant of negative numbers: round_floor(-1) #> [1] 0"},{"path":"https://bking124.github.io/countSTAR/reference/rtruncnormRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a truncated normal distribution — rtruncnormRcpp","title":"Sample from a truncated normal distribution — rtruncnormRcpp","text":"Sample truncated normal distribution. Samples drawn componentwise, component vector allowed mean, standard deviation, upper lower limits. components assumed independent.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/rtruncnormRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a truncated normal distribution — rtruncnormRcpp","text":"","code":"rtruncnormRcpp(y_lower, y_upper, mu, sigma, u_rand)"},{"path":"https://bking124.github.io/countSTAR/reference/rtruncnormRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a truncated normal distribution — rtruncnormRcpp","text":"y_lower m x 1 vector lower endpoints y_upper m x 1 vector upper endpoints mu m x 1 vector conditional expectations sigma m x 1 vector conditional standard deviations u_rand m x 1 vector uniform random variables","code":""},{"path":"https://bking124.github.io/countSTAR/reference/rtruncnormRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a truncated normal distribution — rtruncnormRcpp","text":"z_star m x 1 draw truncated normal distribution","code":""},{"path":"https://bking124.github.io/countSTAR/reference/rtruncnormRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample from a truncated normal distribution — rtruncnormRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sampleFastGaussian.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al. — sampleFastGaussian","title":"Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al. — sampleFastGaussian","text":"Sample N(mu, Sigma) Sigma = solve(crossprod(Phi) + solve(D)) mu = Sigma*crossprod(Phi, alpha):","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sampleFastGaussian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al. — sampleFastGaussian","text":"","code":"sampleFastGaussian(Phi, Ddiag, alpha)"},{"path":"https://bking124.github.io/countSTAR/reference/sampleFastGaussian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al. — sampleFastGaussian","text":"Phi n x p matrix (predictors) Ddiag p x 1 vector diagonal components (prior variance) alpha n x 1 vector (data, scaled variance)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sampleFastGaussian.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al. — sampleFastGaussian","text":"Draw N(mu, Sigma), p x 1, computed O(n^2*p)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sampleFastGaussian.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al. — sampleFastGaussian","text":"Assumes D diagonal, extensions available","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_orthog.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample the parameters for an additive model — sample_bam_orthog","title":"Sample the parameters for an additive model — sample_bam_orthog","text":"Sample parameters additive model, may contain linear nonlinear predictors. nonlinear terms modeled using orthogonalized splines. sampler draws linear terms jointly samples vector nonlinear coefficients using Bayesian backfitting (.e., conditional nonlinear linear terms).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_orthog.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample the parameters for an additive model — sample_bam_orthog","text":"","code":"sample_bam_orthog(   y,   X_lin,   X_nonlin,   params,   A = 10^4,   B_all = NULL,   diagBtB_all = NULL,   XtX = NULL )"},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_orthog.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample the parameters for an additive model — sample_bam_orthog","text":"y n x 1 vector data X_lin n x pL matrix predictors modelled linear X_nonlin n x pNL matrix predictors modelled nonlinear params named list parameters containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu prior scale sigma_beta, assume follows Uniform(0, ) prior. B_all optional pNL-dimensional list n x L[j] dimensional basis matrices nonlinear term j=1,...,pNL; NULL, compute internally diagBtB_all optional pNL-dimensional list diag(crossprod(B_all[[j]])); NULL, compute internally XtX optional p x p matrix crossprod(X) (one-time cost); NULL, compute internally","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_orthog.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample the parameters for an additive model — sample_bam_orthog","text":"updated named list params draws full conditional distributions sigma coefficients (updated mu).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_orthog.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample the parameters for an additive model — sample_bam_orthog","text":"parameters coefficients : beta: p x 1 linear coefficients, including linear terms X_nonlin f_j: n x pNL matrix fitted values nonlinear function theta_j: pNL-dimensional nonlinear basis coefficients sigma_beta: p x 1 vector linear regression coefficient standard deviations sigma_theta_j: pNL x 1 vector nonlinear coefficient standard deviations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_orthog.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample the parameters for an additive model — sample_bam_orthog","text":"","code":"if (FALSE) { # Simulate data for illustration: sim_dat = simulate_nb_friedman(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Linear and nonlinear components: X_lin = as.matrix(X[,-(1:3)]) X_nonlin = as.matrix(X[,(1:3)])  # Initialize: params = countSTAR:::init_bam_orthog(y = y, X_lin = X_lin, X_nonlin = X_nonlin)  # Sample: params = countSTAR:::sample_bam_orthog(y = y,                                 X_lin = X_lin,                                 X_nonlin = X_nonlin,                                 params = params) names(params) names(params$coefficients)  # And plot an example: plot(X_nonlin[,1], params$coefficients$f_j[,1]) }"},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_thin.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample the parameters for an additive model — sample_bam_thin","title":"Sample the parameters for an additive model — sample_bam_thin","text":"Sample parameters additive model, may contain linear nonlinear predictors. nonlinear terms modeled using low-rank thin plate splines. sampler draws linear terms jointly samples vector nonlinear coefficients using Bayesian backfitting (.e., conditional nonlinear linear terms).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_thin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample the parameters for an additive model — sample_bam_thin","text":"","code":"sample_bam_thin(   y,   X_lin,   X_nonlin,   params,   A = 10^4,   B_all = NULL,   BtB_all = NULL,   XtX = NULL )"},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_thin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample the parameters for an additive model — sample_bam_thin","text":"y n x 1 vector data X_lin n x pL matrix predictors modelled linear X_nonlin n x pNL matrix predictors modelled nonlinear params named list parameters containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu prior scale sigma_beta, assume follows Uniform(0, ) prior. B_all optional pNL-dimensional list n x L[j] dimensional basis matrices nonlinear term j=1,...,pNL; NULL, compute internally BtB_all optional pNL-dimensional list crossprod(B_all[[j]]); NULL, compute internally XtX optional p x p matrix crossprod(X) (one-time cost); NULL, compute internally","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_thin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample the parameters for an additive model — sample_bam_thin","text":"updated named list params draws full conditional distributions sigma coefficients (updated mu).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_thin.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample the parameters for an additive model — sample_bam_thin","text":"parameters coefficients : beta: p x 1 linear coefficients, including linear terms X_nonlin f_j: n x pNL matrix fitted values nonlinear function theta_j: pNL-dimensional nonlinear basis coefficients sigma_beta: p x 1 vector linear regression coefficient standard deviations sigma_theta_j: pNL x 1 vector nonlinear coefficient standard deviations","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_bam_thin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample the parameters for an additive model — sample_bam_thin","text":"","code":"if (FALSE) { # Simulate data for illustration: sim_dat = simulate_nb_friedman(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Linear and nonlinear components: X_lin = as.matrix(X[,-(1:3)]) X_nonlin = as.matrix(X[,(1:3)])  # Initialize: params = countSTAR:::init_bam_thin(y = y, X_lin = X_lin, X_nonlin = X_nonlin)  # Sample: params = countSTAR:::sample_bam_thin(y = y,                                 X_lin = X_lin,                                 X_nonlin = X_nonlin,                                 params = params) names(params) names(params$coefficients)  # And plot an example: plot(X_nonlin[,1], params$coefficients$f_j[,1]) }"},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_gprior.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","title":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","text":"Sample parameters linear regression model assuming g-prior  coefficients.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_gprior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","text":"","code":"sample_lm_gprior(y, X, params, psi = NULL, XtX = NULL, X_test = NULL)"},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_gprior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","text":"y n x 1 vector data X n x p matrix predictors params named list parameters containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu psi prior variance g-prior XtX p x p matrix crossprod(X) (one-time cost); NULL, compute within function X_test matrix predictors test points (default NULL)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_gprior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","text":"updated named list params draws full conditional distributions sigma coefficients (along updated mu mu_test applicable).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_gprior.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","text":"parameters coefficients : beta: p x 1 vector regression coefficients components beta","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_gprior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","text":"","code":"if (FALSE) { # Simulate data for illustration: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Initialize: params = countSTAR:::init_lm_gprior(y = y, X = X)  # Sample: params = countSTAR:::sample_lm_gprior(y = y, X = X, params = params) names(params) names(params$coefficients) }"},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_hs.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","title":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","text":"Sample parameters linear regression model assuming horseshoe prior (non-intercept) coefficients. number predictors p may exceed number observations n.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_hs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","text":"","code":"sample_lm_hs(y, X, params, XtX = NULL, X_test = NULL)"},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_hs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","text":"y n x 1 vector data X n x p matrix predictors params named list parameters containing mu n x 1 vector conditional means (fitted values) sigma conditional standard deviation coefficients named list parameters determine mu XtX p x p matrix crossprod(X) (one-time cost); NULL, compute within function X_test matrix predictors test points (default NULL)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_hs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","text":"updated named list params draws full conditional distributions sigma coefficients (along updated mu mu_test applicable).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_hs.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","text":"parameters coefficients : beta p x 1 vector regression coefficients sigma_beta p x 1 vector regression coefficient standard deviations (local scale parameters) xi_sigma_beta p x 1 vector parameter-expansion variables sigma_beta lambda_beta global scale parameter xi_lambda_beta parameter-expansion variable lambda_beta components beta","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_hs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","text":"","code":"if (FALSE) { # Simulate data for illustration: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Initialize: params = countSTAR:::init_lm_hs(y = y, X = X)  # Sample: params = countSTAR:::sample_lm_hs(y = y, X = X, params = params) names(params) names(params$coefficients) }"},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_ridge.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample linear regression parameters assuming a ridge prior — sample_lm_ridge","title":"Sample linear regression parameters assuming a ridge prior — sample_lm_ridge","text":"Sample parameters linear regression model assuming ridge prior (non-intercept) coefficients. number predictors p may exceed number observations n.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_ridge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample linear regression parameters assuming a ridge prior — sample_lm_ridge","text":"","code":"sample_lm_ridge(y, X, params, A = 10^4, XtX = NULL, X_test = NULL)"},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_ridge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample linear regression parameters assuming a ridge prior — sample_lm_ridge","text":"y n x 1 vector data X n x p matrix predictors params named list parameters containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu prior scale sigma_beta, assume follows Uniform(0, ) prior. XtX p x p matrix crossprod(X) (one-time cost); NULL, compute within function X_test matrix predictors test points (default NULL)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_ridge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample linear regression parameters assuming a ridge prior — sample_lm_ridge","text":"updated named list params draws full conditional distributions sigma coefficients (along updated mu mu_test applicable).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_ridge.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample linear regression parameters assuming a ridge prior — sample_lm_ridge","text":"parameters coefficients : beta: p x 1 vector regression coefficients sigma_beta: prior standard deviation (non-intercept) components beta","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_lm_ridge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample linear regression parameters assuming a ridge prior — sample_lm_ridge","text":"","code":"if (FALSE) { # Simulate data for illustration: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Initialize: params = countSTAR:::init_lm_ridge(y = y, X = X)  # Sample: params = countSTAR:::sample_lm_ridge(y = y, X = X, params = params) names(params) names(params$coefficients) }"},{"path":"https://bking124.github.io/countSTAR/reference/sample_params_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample the parameters for a simple mean-only model — sample_params_mean","title":"Sample the parameters for a simple mean-only model — sample_params_mean","text":"Sample parameters model y ~ N(mu0, sigma^2) flat prior mu0 sigma ~ Unif(0, ).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_params_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample the parameters for a simple mean-only model — sample_params_mean","text":"","code":"sample_params_mean(y, params)"},{"path":"https://bking124.github.io/countSTAR/reference/sample_params_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample the parameters for a simple mean-only model — sample_params_mean","text":"y n x 1 vector data params named list parameters containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_params_mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample the parameters for a simple mean-only model — sample_params_mean","text":"updated named list params draws full conditional distributions sigma coefficients (updated mu).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_params_mean.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample the parameters for a simple mean-only model — sample_params_mean","text":"parameter coefficients mu0. Although redundant , parametrization useful functions.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/sample_params_mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample the parameters for a simple mean-only model — sample_params_mean","text":"","code":"if (FALSE) { # Example: y = 1:10 params0 = countSTAR:::init_params_mean(y) params = countSTAR:::sample_params_mean(y = y, params = params0) names(params) }"},{"path":"https://bking124.github.io/countSTAR/reference/simBaS.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Simultaneous Band Scores (SimBaS) — simBaS","title":"Compute Simultaneous Band Scores (SimBaS) — simBaS","text":"Compute simultaneous band scores (SimBaS) Meyer et al. (2015, Biometrics). SimBaS uses MC(MC) simulations function interest compute minimum alpha joint credible bands alpha level include zero. quantity computed grid point (observation point) domain function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simBaS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Simultaneous Band Scores (SimBaS) — simBaS","text":"","code":"simBaS(sampFuns)"},{"path":"https://bking124.github.io/countSTAR/reference/simBaS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Simultaneous Band Scores (SimBaS) — simBaS","text":"sampFuns Nsims x m matrix Nsims MCMC samples m points along curve","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simBaS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Simultaneous Band Scores (SimBaS) — simBaS","text":"m x 1 vector simBaS","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simBaS.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute Simultaneous Band Scores (SimBaS) — simBaS","text":"input needs curves: simBaS may computed vectors achieve multiplicity adjustment. minimum returned value, PsimBaS_t, domain t Global Bayesian P-Value (GBPV) testing whether function zero everywhere.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_friedman.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"Simulate data negative-binomial distribution nonlinear mean function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_friedman.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"","code":"simulate_nb_friedman(   n = 100,   p = 10,   r_nb = 1,   b_int = log(1.5),   b_sig = log(5),   sigma_true = sqrt(2 * log(1)),   seed = NULL )"},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_friedman.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"n number observations p number predictors r_nb dispersion parameter Negative Binomial dispersion; smaller values imply greater overdispersion, larger values approximate Poisson distribution. b_int intercept; default log(1.5). b_sig regression coefficients true signals; default log(5.0). sigma_true standard deviation Gaussian innovation; default zero. seed optional integer set seed reproducible simulation; default NULL results different dataset run","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_friedman.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"named list simulated count response y, simulated design matrix X, true expected counts Ey.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_friedman.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"log-expected counts modeled using Friedman (1991) nonlinear function interactions, possibly additional Gaussian noise (log-scale). assume half predictors associated response, .e., true signals. sufficiently large dispersion parameter r_nb, distribution approximate Poisson distribution. , predictor variables simulated independent uniform distributions.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_friedman.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"Specifying sigma_true = sqrt(2*log(1 + )) implies expected counts inflated 100*% (relative exp(X*beta)), addition providing additional overdispersion.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_friedman.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"","code":"# Simulate and plot the count data: sim_dat = simulate_nb_friedman(n = 100, p = 10); plot(sim_dat$y)"},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate count data from a linear regression — simulate_nb_lm","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"Simulate data negative-binomial distribution linear mean function.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"","code":"simulate_nb_lm(   n = 100,   p = 10,   r_nb = 1,   b_int = log(1.5),   b_sig = log(2),   sigma_true = sqrt(2 * log(1)),   ar1 = 0,   intercept = FALSE,   seed = NULL )"},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"n number observations p number predictors (including intercept) r_nb dispersion parameter Negative Binomial dispersion; smaller values imply greater overdispersion, larger values approximate Poisson distribution. b_int intercept; default log(1.5), implies expected count 1.5 predictors zero b_sig regression coefficients true signals; default log(2.0), implies twofold increase expected counts one unit increase x sigma_true standard deviation Gaussian innovation; default zero. ar1 autoregressive coefficient among columns X matrix; default zero. intercept Boolean indicating whether intercept column included returned design matrix; default FALSE seed optional integer set seed reproducible simulation; default NULL results different dataset run","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"named list simulated count response y, simulated design matrix X (possibly including intercept), true expected counts Ey, true regression coefficients beta_true.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_lm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"log-expected counts modeled linear function covariates, possibly additional Gaussian noise (log-scale). assume half predictors associated response, .e., true signals. sufficiently large dispersion parameter r_nb, distribution approximate Poisson distribution. , predictor variables simulated independent standard normal distributions.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_lm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"Specifying sigma_true = sqrt(2*log(1 + )) implies expected counts inflated 100*% (relative exp(X*beta)), addition providing additional overdispersion.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/simulate_nb_lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"","code":"# Simulate and plot the count data: sim_dat = simulate_nb_lm(n = 100, p = 10); plot(sim_dat$y)"},{"path":"https://bking124.github.io/countSTAR/reference/splineBasis.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize and reparametrize a spline basis matrix — splineBasis","title":"Initialize and reparametrize a spline basis matrix — splineBasis","text":"Following Wand Ormerod (2008), compute low-rank thin plate spline basis diagonalized prior variance nonlinear component scalar times diagonal matrix. Knot locations determined quantiles penalty integrated squared second derivative.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/splineBasis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize and reparametrize a spline basis matrix — splineBasis","text":"","code":"splineBasis(tau, sumToZero = TRUE, rescale01 = TRUE)"},{"path":"https://bking124.github.io/countSTAR/reference/splineBasis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize and reparametrize a spline basis matrix — splineBasis","text":"tau m x 1 vector observed points sumToZero logical; TRUE, enforce sum--zero constraint (useful additive models) rescale01 logical; TRUE, rescale tau interval [0,1] prior computing basis penalty matrices","code":""},{"path":"https://bking124.github.io/countSTAR/reference/splineBasis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize and reparametrize a spline basis matrix — splineBasis","text":"B_nl: nonlinear component spline basis matrix","code":""},{"path":"https://bking124.github.io/countSTAR/reference/splineBasis.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize and reparametrize a spline basis matrix — splineBasis","text":"form full spline basis matrix, compute cbind(1, tau, B_nl). sum--zero constraint implicitly assumes linear term centered scaled, .e., scale(tau).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/spline_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation for Bayesian STAR spline regression — spline_star","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"Compute samples predictive distributions STAR spline regression model using either Gibbs sampling approach exact Monte Carlo sampling (default Gibbs sampling scales better large n)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/spline_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"","code":"spline_star(   y,   tau = NULL,   transformation = \"np\",   y_max = Inf,   psi = NULL,   approx_Fz = FALSE,   approx_Fy = FALSE,   nsave = 1000,   use_MCMC = TRUE,   nburn = 1000,   nskip = 0,   verbose = TRUE,   method_sigma = \"mle\" )"},{"path":"https://bking124.github.io/countSTAR/reference/spline_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"y n x 1 vector observed counts tau n x 1 vector observation points; NULL, assume equally-spaced [0,1] transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"bnp\" (Bayesian nonparametric transformation using Bayesian bootstrap) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) y_max fixed known upper bound observations; default Inf psi prior variance (1/smoothing parameter); NULL, update MCMC approx_Fz logical; BNP transformation, apply (fast stable) normal approximation marginal CDF latent data approx_Fy logical; BNP transformation, approximate marginal CDF y using empirical CDF nsave number MCMC iterations save (number Monte Carlo simulations) use_MCMC logical; whether run Gibbs sampler Monte Carlo (default TRUE) nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw verbose logical; TRUE, print time remaining method_sigma method estimate latent data standard deviation (applicable use_MCMC=FALSE); must one \"mle\" use MLE STAR EM algorithm (default) \"mmle\" use marginal MLE (Note: slower!)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/spline_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"list following elements: post_ytilde: nsave x n samples posterior predictive distribution observation points tau marg_like: marginal likelihood (use_MCMC=FALSE; otherwise NULL)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/spline_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. , continuous latent data model spline regression. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt'. Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y. distribution-based transformations approximately preserve mean variance count data y latent data scale, lends interpretability model parameters. Lastly, transformation can modeled using Bayesian bootstrap ('bnp'), Bayesian nonparametric model incorporates uncertainty transformation posterior predictive inference.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/spline_star.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"'bnp' transformation (without Fy approximation), numerical stability issues psi modeled unknown. case, better fix psi positive number.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/spline_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"","code":"# Simulate some data: n = 100 tau = seq(0,1, length.out = n) y = round_floor(exp(1 + rnorm(n)/4 + poly(tau, 4)%*%rnorm(n=4, sd = 4:1)))  # Sample from the predictive distribution of a STAR spline model: fit = spline_star(y = y, tau = tau) #> [1] \"Burn-In Period\" #> [1] \"Starting sampling\" #> [1] \"0 seconds remaining\" #> [1] \"Total time:  1 seconds\"  # Compute 90% prediction intervals: pi_y = t(apply(fit$post_ytilde, 2, quantile, c(0.05, .95)))  # Plot the results: intervals, median, and smoothed mean plot(tau, y, ylim = range(pi_y, y)) polygon(c(tau, rev(tau)),c(pi_y[,2], rev(pi_y[,1])),col='gray', border=NA) lines(tau, apply(fit$post_ytilde, 2, median), lwd=5, col ='black') lines(tau, smooth.spline(tau, apply(fit$post_ytilde, 2, mean))$y, lwd=5, col='blue') lines(tau, y, type='p')"},{"path":"https://bking124.github.io/countSTAR/reference/spline_star_exact.html","id":null,"dir":"Reference","previous_headings":"","what":"Monte Carlo predictive sampler for spline regression — spline_star_exact","title":"Monte Carlo predictive sampler for spline regression — spline_star_exact","text":"Compute direct Monte Carlo samples posterior predictive distribution STAR spline regression model.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/spline_star_exact.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Monte Carlo predictive sampler for spline regression — spline_star_exact","text":"","code":"spline_star_exact(   y,   tau = NULL,   transformation = \"np\",   y_max = Inf,   psi = 1000,   method_sigma = \"mle\",   approx_Fz = FALSE,   approx_Fy = FALSE,   nsave = 1000,   compute_marg = TRUE )"},{"path":"https://bking124.github.io/countSTAR/reference/spline_star_exact.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Monte Carlo predictive sampler for spline regression — spline_star_exact","text":"y n x 1 vector observed counts tau n x 1 vector observation points; NULL, assume equally-spaced [0,1] transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"bnp\" (Bayesian nonparametric transformation using Bayesian bootstrap) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) y_max fixed known upper bound observations; default Inf psi prior variance (1/smoothing parameter) method_sigma method estimate latent data standard deviation; must one \"mle\" use MLE STAR EM algorithm \"mmle\" use marginal MLE (Note: slower!) approx_Fz logical; BNP transformation, apply (fast stable) normal approximation marginal CDF latent data approx_Fy logical; BNP transformation, approximate marginal CDF y using empirical CDF nsave number Monte Carlo simulations compute_marg logical; TRUE, compute return marginal likelihood","code":""},{"path":"https://bking124.github.io/countSTAR/reference/spline_star_exact.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Monte Carlo predictive sampler for spline regression — spline_star_exact","text":"list following elements: post_ytilde: nsave x n samples posterior predictive distribution observation points tau marg_like: marginal likelihood (requested; otherwise NULL)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/spline_star_exact.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Monte Carlo predictive sampler for spline regression — spline_star_exact","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. , continuous latent data model spline regression. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt'. Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y. distribution-based transformations approximately preserve mean variance count data y latent data scale, lends interpretability model parameters. Lastly, transformation can modeled using Bayesian bootstrap ('bnp'), Bayesian nonparametric model incorporates uncertainty transformation posterior predictive inference. Monte Carlo sampler produces direct, discrete, joint draws posterior predictive distribution spline regression model observed tau points.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/spline_star_exact.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Monte Carlo predictive sampler for spline regression — spline_star_exact","text":"","code":"if (FALSE) { # Simulate some data: n = 100 tau = seq(0,1, length.out = n) y = round_floor(exp(1 + rnorm(n)/4 + poly(tau, 4)%*%rnorm(n=4, sd = 4:1)))  # Sample from the predictive distribution of a STAR spline model: fit_star = countSTAR:::spline_star_exact(y = y, tau = tau) post_ytilde = fit_star$post_ytilde  # Compute 90% prediction intervals: pi_y = t(apply(post_ytilde, 2, quantile, c(0.05, .95)))  # Plot the results: intervals, median, and smoothed mean plot(tau, y, ylim = range(pi_y, y)) polygon(c(tau, rev(tau)),c(pi_y[,2], rev(pi_y[,1])),col='gray', border=NA) lines(tau, apply(post_ytilde, 2, median), lwd=5, col ='black') lines(tau, smooth.spline(tau, apply(post_ytilde, 2, mean))$y, lwd=5, col='blue') lines(tau, y, type='p') }"},{"path":"https://bking124.github.io/countSTAR/reference/truncnorm_mom.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the first and second moment of a truncated normal — truncnorm_mom","title":"Compute the first and second moment of a truncated normal — truncnorm_mom","text":"Given lower upper endpoints mean standard deviation (non-truncated) normal distribution, compute first second moment truncated normal distribution. inputs may scalars vectors.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/truncnorm_mom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the first and second moment of a truncated normal — truncnorm_mom","text":"","code":"truncnorm_mom(a, b, mu, sig)"},{"path":"https://bking124.github.io/countSTAR/reference/truncnorm_mom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the first and second moment of a truncated normal — truncnorm_mom","text":"lower endpoint b upper endpoint mu expected value non-truncated normal distribution sig standard deviation non-truncated normal distribution","code":""},{"path":"https://bking124.github.io/countSTAR/reference/truncnorm_mom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the first and second moment of a truncated normal — truncnorm_mom","text":"list containing first moment m1 second moment m2","code":""},{"path":"https://bking124.github.io/countSTAR/reference/uni.slice.html","id":null,"dir":"Reference","previous_headings":"","what":"Univariate Slice Sampler from Neal (2008) — uni.slice","title":"Univariate Slice Sampler from Neal (2008) — uni.slice","text":"Compute draw univariate distribution using code provided Radford M. Neal. documentation also reproduced Neal (2008).","code":""},{"path":"https://bking124.github.io/countSTAR/reference/uni.slice.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Univariate Slice Sampler from Neal (2008) — uni.slice","text":"","code":"uni.slice(x0, g, w = 1, m = Inf, lower = -Inf, upper = +Inf, gx0 = NULL)"},{"path":"https://bking124.github.io/countSTAR/reference/uni.slice.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Univariate Slice Sampler from Neal (2008) — uni.slice","text":"x0 Initial point g Function returning log probability density (plus constant) w Size steps creating interval (default 1) m Limit steps (default infinite) lower Lower bound support distribution (default -Inf) upper Upper bound support distribution (default +Inf) gx0 Value g(x0), known (default known)","code":""},{"path":"https://bking124.github.io/countSTAR/reference/uni.slice.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Univariate Slice Sampler from Neal (2008) — uni.slice","text":"point sampled, log density attached attribute.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/uni.slice.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Univariate Slice Sampler from Neal (2008) — uni.slice","text":"log density function may return -Inf points outside support distribution.  lower /upper bound specified support, log density function called outside limits.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/update_struct.html","id":null,"dir":"Reference","previous_headings":"","what":"Update parameters for warpDLM model with trend DLM — update_struct","title":"Update parameters for warpDLM model with trend DLM — update_struct","text":"function serves update warpDLM variance parameters underlying DLM structural model (.e. local level local linear trend). assumes Unif(0,=10^4) prior standard deviations.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/update_struct.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update parameters for warpDLM model with trend DLM — update_struct","text":"","code":"update_struct(fit, z_star, theta)"},{"path":"https://bking124.github.io/countSTAR/reference/update_struct.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update parameters for warpDLM model with trend DLM — update_struct","text":"fit KFAS model object describing DLM z_star latest draw z* theta latest draw latent state(s) theta","code":""},{"path":"https://bking124.github.io/countSTAR/reference/update_struct.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update parameters for warpDLM model with trend DLM — update_struct","text":"KFAS model object (class SSModel) updated newly sampled variance parameters","code":""},{"path":"https://bking124.github.io/countSTAR/reference/warpDLM.html","id":null,"dir":"Reference","previous_headings":"","what":"Posterior Inference for warpDLM model with latent structural DLM — warpDLM","title":"Posterior Inference for warpDLM model with latent structural DLM — warpDLM","text":"function outputs posterior quantities forecasts univariate warpDLM model. Currently two latent DLM specifications supported: local level local linear trend.","code":""},{"path":"https://bking124.github.io/countSTAR/reference/warpDLM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posterior Inference for warpDLM model with latent structural DLM — warpDLM","text":"","code":"warpDLM(   y,   type = c(\"level\", \"trend\"),   transformation = c(\"np\", \"identity\", \"log\", \"sqrt\", \"pois\", \"neg-bin\"),   y_max = Inf,   R0 = 10,   nsave = 5000,   nburn = 5000,   nskip = 1,   n.ahead = 1 )"},{"path":"https://bking124.github.io/countSTAR/reference/warpDLM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posterior Inference for warpDLM model with latent structural DLM — warpDLM","text":"y count-valued time series type type latent DLM (must either level trend) transformation transformation use latent process (default np); must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) y_max fixed known upper bound observations; default Inf R0 variance initial state theta_0; default 10 nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw n.ahead number steps forecast ahead","code":""},{"path":"https://bking124.github.io/countSTAR/reference/warpDLM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posterior Inference for warpDLM model with latent structural DLM — warpDLM","text":"list following elements: V_post: posterior draws observation variance W_post: posterior draws state update variance(s) fc_post: draws forecast distribution (length n.ahead) post_pred: draws posterior predictive distribution y g_func: transformation function g_inv_func: inverse transformation function KFAS_mod: final KFAS model representing latent DLM","code":""}]
