[{"path":"https://bking124.github.io/rSTAR/articles/rSTAR.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Getting Started with rSTAR","text":"rSTAR package implements variety methods analyze diverse integer-valued data, special focus count-valued data. package functionality broadly split three categories: Bayesian estimation STAR models (Kowal Canale (2020), Kowal Wu (2021)), frequentist/classical estimation (Kowal Wu (2022)), time series analysis using warped Dynamic Linear Models (King Kowal (2021)). give brief description STAR framework, diving specific examples show rSTAR functionality.","code":""},{"path":"https://bking124.github.io/rSTAR/articles/rSTAR.html","id":"simultaneous-transformation-and-rounding-star-models","dir":"Articles","previous_headings":"","what":"Simultaneous Transformation and Rounding (STAR) Models","title":"Getting Started with rSTAR","text":"STAR models build upon continuous data models provide valid integer-valued data-generating process. example STAR model linear regression follows: \\[\\begin{align*} y_i &= \\mbox{floor}(y_i^*) \\\\ z_i^* &= \\log(y_i^*) \\\\ z_i^* &= x_i'\\beta + \\epsilon_i, \\quad \\epsilon_i \\stackrel{iid}{\\sim}N(0, \\sigma^2) \\end{align*}\\] latent data \\(y_i^*\\) act continuous proxy count data \\(y_i\\), easier model yet simple mapping via floor function observed data. latent data \\(y_i^*\\) transformed \\(z_i^*\\), common practice, modeled using Gaussian linear regression. model inherits structure , data-generating process now integer-valued. generally, STAR models defined via rounding operator \\(h\\), (known unknown) transformation \\(g\\), continuous data model \\(\\Pi_\\theta\\) unknown parameters \\(\\theta\\): \\[\\begin{align*} y &= h(y^*) \\quad \\mbox{(rounding)}\\\\ z^* &= g(y^*) \\quad \\mbox{(transformation)}\\\\ z^* & \\sim \\Pi_\\theta \\quad \\mbox{(model)}\\\\ \\end{align*}\\] Importantly, STAR models highly flexible integer-valued processes, provide capability model () discrete data, (ii) zero-inflation, (iii) - -dispersion, (iv) bounded censored data. focus conditionally Gaussian models form \\[ z^*(x) = \\mu_\\theta(x) + \\epsilon(x), \\quad \\epsilon(x) \\stackrel{iid}{\\sim}N(0, \\sigma^2) \\] \\(\\mu_\\theta(x)\\) conditional expectation transformed latent data unknown parameters \\(\\theta\\). Examples include linear, additive, tree-based regression models.","code":""},{"path":"https://bking124.github.io/rSTAR/articles/rSTAR.html","id":"integer-valued-data-the-roaches-dataset","dir":"Articles","previous_headings":"","what":"Integer-Valued Data: The Roaches Dataset","title":"Getting Started with rSTAR","text":"example complex count-valued data, consider roaches data Gelman Hill (2006). response variable, \\(y_i\\), number roaches caught traps apartment \\(\\), \\(=1,\\ldots, n = 262\\).  several notable features data: Zero-inflation: 36% observations zeros. (Right-) Skewness, clear histogram common (zero-inflated) count data. Overdispersion: sample mean 26 sample variance 2585. pest management treatment applied subset 158 apartments, remaining 104 apartments receiving control. Additional data available pre-treatment number roaches, whether apartment building restricted elderly residents, number days traps exposed. interested modeling roach incidence varies predictors.","code":"# Source: http://mc-stan.org/rstanarm/articles/count.html #install.packages(\"rstanarm\") data(roaches, package=\"rstanarm\")   # Roaches: y = roaches$y  # Function to plot the point mass function: stickplot = function(y, ...){   js = 0:max(y);    plot(js,         sapply(js, function(js) mean(js == y)),         type='h', lwd=2, ...) } stickplot(y, main = 'PMF: Roaches Data',           xlab = 'Roaches', ylab = 'Probability mass')"},{"path":"https://bking124.github.io/rSTAR/articles/rSTAR.html","id":"frequentist-inference-for-star-models","dir":"Articles","previous_headings":"","what":"Frequentist inference for STAR models","title":"Getting Started with rSTAR","text":"Frequentist (classical) estimation inference STAR models provided EM algorithm. Sufficient estimation estimator function solves least squares (Gaussian maximum likelihood) problem associated \\(\\mu_\\theta\\)—words, estimator used Gaussian continuous data. Specifically, estimator inputs data outputs list two elements: estimated coefficients \\(\\hat \\theta\\) fitted.values \\(\\hat \\mu_\\theta(x_i) = \\mu_{\\hat \\theta}(x_i)\\).","code":""},{"path":"https://bking124.github.io/rSTAR/articles/rSTAR.html","id":"the-classical-linear-model","dir":"Articles","previous_headings":"Frequentist inference for STAR models","what":"The Classical Linear Model","title":"Getting Started with rSTAR","text":"many applications, STAR linear model often first method try. rSTAR, linear model implemented lm_star function, aims mimic functionality lm allowing users input formula. Standard functions like coef fitted can used output extract coefficients fitted values, respectively. log transformation used, options available; see ?lm_star details. Based fitted STAR linear model, may obtain confidence intervals estimated coefficients using confint: Similarly, p-values available using likelihood ratio tests, can applied individual coefficients, \\[ H_0: \\beta_j= 0 \\quad \\mbox{vs} \\quad H_1: \\beta_j \\ne 0 \\] joint sets variables, analogous (partial) F-test: \\[ H_0: \\beta_1=\\ldots=\\beta_p = 0, \\quad \\mbox{vs.} \\quad H_1: \\beta_j \\ne 0 \\mbox{ } j=1,\\ldots,p \\] P-values individual coefficients well p-value effects computed pvals function. Finally, can get predictions new data points (training data) using predict, actually outputs samples (plug-) predictive distribution MLEs. output can used create prediction intervals desired, alternatively samples can compared empirical PMF \\(y\\) using plot_pmf.","code":"library(rSTAR)  # Select a transformation: transformation = 'log' # Log transformation #transformation = 'np' # Estimated transformation using empirical CDF  # EM algorithm for STAR (using the log-link) fit_em = lm_star(y ~ roach1 + treatment + senior + log(exposure2),                  data = roaches, transformation = transformation)   # Dimensions: n = nrow(fit_em$X); p = ncol(fit_em$X)  # Fitted coefficients: round(coef(fit_em), 3) #>    (Intercept)         roach1      treatment         senior log(exposure2)  #>          1.260          0.015         -0.715         -0.912          0.560 # Confidence interval for the j=2 column: j = 2 ci_j = confint(fit_em, level = 0.95,         j = j,         include_plot = FALSE) print(round(ci_j, 3)) #> [1] 0.012 0.019  # Confidence for all columns: ci_all = sapply(1:p, function(j)   confint(fit_em, level = 0.95,         j = j,         include_plot = FALSE)) colnames(ci_all) = colnames(fit_em$X);  rownames(ci_all) = c('Lower', 'Upper') print(t(round(ci_all, 3))) #>                 Lower  Upper #> (Intercept)     0.775  1.721 #> roach1          0.012  0.019 #> treatment      -1.262 -0.176 #> senior         -1.526 -0.320 #> log(exposure2) -0.557  1.699 # P-values: print(pvals(fit_em)) #>        (Intercept)             roach1          treatment             senior  #>       1.705446e-06       2.980644e-16       1.027887e-02       3.090894e-03  #>     log(exposure2) Any linear effects  #>       3.263341e-01       1.078663e-17 #Compute the predictive draws (just using observed points here) y_pred = predict(fit_em)  # Using these draws, compute prediction intervals for STAR PI_y = t(apply(y_pred, 2, quantile, c(0.05, 1 - 0.05)))  # Plot empirical PMf of y vs PMF from predictive draws plot_pmf(y, y_pred)"},{"path":"https://bking124.github.io/rSTAR/articles/rSTAR.html","id":"machine-learning-models","dir":"Articles","previous_headings":"Frequentist inference for STAR models","what":"Machine Learning Models","title":"Getting Started with rSTAR","text":"addition linear model, rSTAR also implementations STAR models paired flexible regression methods, particular random forests generalized boosted machines.","code":""},{"path":"https://bking124.github.io/rSTAR/articles/rSTAR.html","id":"a-generic-em-algorithm","dir":"Articles","previous_headings":"Frequentist inference for STAR models","what":"A Generic EM Algorithm","title":"Getting Started with rSTAR","text":"EM algorithm updates parameters convergence maximum likelihood estimators (MLEs), implemented star_EM:","code":""},{"path":"https://bking124.github.io/rSTAR/articles/rSTAR.html","id":"bayesian-inference-for-star-models","dir":"Articles","previous_headings":"","what":"Bayesian inference for STAR models","title":"Getting Started with rSTAR","text":"Bayesian model, STAR requires algorithm initializing sampling posterior distribution continuous data model. specifically, posterior inference STAR based Gibbs sampler, augments aforementioned continuous sampler draw \\([z^* | y, \\theta]\\). \\(\\Pi_\\theta\\) conditionally Gaussian, \\([z^* | y, \\theta]\\) truncated Gaussian distribution. illustration, consider Bayesian linear regression model \\[\\begin{align*} z_i^* &= x_i'\\beta + \\epsilon_i, \\quad \\epsilon_i \\stackrel{iid}{\\sim}N(0, \\sigma^2)\\\\ \\beta_j & \\stackrel{iid}{\\sim}N(0, \\sigma_\\beta^2), \\quad \\sigma_\\beta \\sim \\mbox{Uniform}(0, 10^4) \\end{align*}\\] STAR log transformation, posterior samples \\((\\beta, \\sigma_\\beta, \\sigma)\\) obtained using star_MCMC follows: function sample_params computes single draw parameters params conditional continuous data. , update Bayesian linear Gaussian regression, samples posterior \\((\\beta, \\sigma_\\beta, \\sigma)\\) conditional continuous latent data \\(z^*\\). function init_params simply initializes parameters params. Posterior expectations posterior credible intervals available follows: may evaluate model based posterior diagnostics posterior predictive checks simulated versus observed proportion zeros:","code":"X = model.matrix(y ~ roach1 + treatment + senior + log(exposure2),                  data = roaches)  # Dimensions: n = nrow(X); p = ncol(X)  fit_mcmc = genMCMC_star(y = y,                           sample_params = function(y, params)                             rSTAR:::sample_lm_ridge(y, X, params),                          init_params = function(y)                             rSTAR:::init_lm_ridge(y,X),                          transformation = 'log', verbose = FALSE) # Posterior mean of each coefficient: round(coef(fit_mcmc),3) #>  beta1  beta2  beta3  beta4  beta5  #>  1.129  0.016 -0.603 -0.753  0.356  # Credible intervals for regression coefficients ci_all_bayes = apply(fit_mcmc$post.beta,       2, function(x) quantile(x, c(.025, .975)))  # Rename and print: colnames(ci_all_bayes) = colnames(X); rownames(ci_all_bayes) = c('Lower', 'Upper') print(t(round(ci_all_bayes, 3))) #>                 Lower  Upper #> (Intercept)     0.591  1.628 #> roach1          0.012  0.019 #> treatment      -1.158 -0.046 #> senior         -1.386 -0.121 #> log(exposure2) -0.488  1.351 # Posterior draws of the regression coefficients: post.coef = fit_mcmc$post.beta[,2:p] colnames(post.coef) = colnames(X)[2:p]  # MCMC diagnostics: plot(as.ts(post.coef), main = 'Trace plots', cex.lab = .75) # (Summary of) effective sample sizes across coefficients: getEffSize(post.coef) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>    3667    3707    4146    4151    4590    4644  # Posterior predictive check: hist(apply(fit_mcmc$post.pred, 1,            function(x) mean(x==0)), main = 'Proportion of Zeros', xlab=''); abline(v = mean(y==0), lwd=4, col ='blue')"},{"path":"https://bking124.github.io/rSTAR/articles/rSTAR.html","id":"additional-features-in-rstar","dir":"Articles","previous_headings":"","what":"Additional features in rSTAR","title":"Getting Started with rSTAR","text":"fixed upper bound, y_max, \\(y(x) \\le \\mbox{}\\) y_max \\(x\\) Residual diagnostics star_EM Log-likelihood MLEs star_EM model comparison information criteria (AIC BIC) Customized functions STAR gradient boosting gbm_star STAR random forests randomForest_star Fitted values \\(\\hat y(x) = E\\{y(x)\\}\\) posterior samples \\([\\hat y(x) | y]\\) star_MCMC Samples integer-valued posterior predictive distribution \\([\\tilde y(x) | y]\\) star_MCMC, \\(\\tilde y\\) denotes future unobserved data Customized samplers Bayesian additive models sample_params_additive linear models horseshoe priors sample_params_lm_hs WAIC pointwise log-likelihoods (Bayesian) model comparisons customized STAR model Bayesian additive regression trees (BART) bart_star_MCMC Posterior samplers STAR unknown nonparametric transformation \\(g\\) Monte Carlo samplers posterior predictive inference linear regression spline regression","code":""},{"path":"https://bking124.github.io/rSTAR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Brian King. Author, maintainer. Daniel R. Kowal. Author.","code":""},{"path":"https://bking124.github.io/rSTAR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"King B, Kowal DR (2023). rSTAR: Modeling Integer-Valued Data  via Simultaneous Transformation Rounding (STAR). R package version 1.0.0, https://bking124.github.io/rSTAR/https://github.com/bking124/rSTAR.","code":"@Manual{,   title = {rSTAR: Modeling Integer-Valued Data  via Simultaneous Transformation and Rounding (STAR)},   author = {Brian King and Daniel R. Kowal},   year = {2023},   note = {R package version 1.0.0},   url = {https://bking124.github.io/rSTAR/ https://github.com/bking124/rSTAR}, }"},{"path":[]},{"path":"https://bking124.github.io/rSTAR/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Modeling Integer-Valued Data  via Simultaneous Transformation and Rounding (STAR)","text":"Integer-valued count data common many fields. Frequently, integer-valued data observed jointly predictors, time intervals, across spatial locations. Integer-valued data also exhibit variety complex distributional features, including zero-inflation, skewness, - underdispersion, cases may bounded censored. Flexible interpretable models integer-valued processes therefore highly useful practice. rSTAR implements variety methods modeling processes, based idea Simultaneous Transformation Rounding (STAR). Estimation, inference, prediction STAR available Bayesian frequentist models. bulk methods serve static regression problems, package also supports time series analysis via warped Dynamic Linear Model (DLM) framework. Broadly, STAR defines integer-valued probability model (1) specifying (conditionally) Gaussian model continuous latent data (2) connecting latent data observed data via transformation rounding operation. Importantly, STAR models highly flexible integer-valued processes, provide capability model () discrete data, (ii) zero-inflation, (iii) - -dispersion, (iv) heaping, (v) bounded censored data. Detailed information different options STAR models implemented rSTAR can found vignette, accessible website running command vignette(\"rSTAR\"). basic breakdown available modeling functions shown : addition ready use functions, users can also implement STAR methods custom latent regression models using genEM_star() genMCMC_star() functions. Please submit issues feature requests https://github.com/bking124/rSTAR.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/BrentMethod.html","id":null,"dir":"Reference","previous_headings":"","what":"Brent's method for optimization — BrentMethod","title":"Brent's method for optimization — BrentMethod","text":"Implementation Brent's algorithm minimizing univariate function interval. code based function stsm package.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/BrentMethod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Brent's method for optimization — BrentMethod","text":"","code":"BrentMethod(a = 0, b, fcn, tol = .Machine$double.eps^0.25)"},{"path":"https://bking124.github.io/rSTAR/reference/BrentMethod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Brent's method for optimization — BrentMethod","text":"lower limit search b upper limit search fcn function minimize tol tolerance level convergence optimization procedure","code":""},{"path":"https://bking124.github.io/rSTAR/reference/BrentMethod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Brent's method for optimization — BrentMethod","text":"list containing following elements: fx minimum value input function x argument minimizes function iter number iterations converge vx vector stores arguments convergence","code":""},{"path":"https://bking124.github.io/rSTAR/reference/a_j.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse rounding function — a_j","title":"Inverse rounding function — a_j","text":"Define intervals associated y = j based flooring function. function returns -Inf j = 0 (smaller) Inf j >= y_max + 1, y_max known upper bound data y (specified).","code":""},{"path":"https://bking124.github.io/rSTAR/reference/a_j.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse rounding function — a_j","text":"","code":"a_j(j, y_max = Inf)"},{"path":"https://bking124.github.io/rSTAR/reference/a_j.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse rounding function — a_j","text":"j integer-valued input(s) y_max fixed known upper bound observations; default Inf","code":""},{"path":"https://bking124.github.io/rSTAR/reference/a_j.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse rounding function — a_j","text":"(lower) interval endpoint(s) associated j.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/a_j.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse rounding function — a_j","text":"","code":"# Standard cases: a_j(1) #> [1] 1 a_j(20) #> [1] 20  # Boundary cases: a_j(0) #> [1] -Inf a_j(20, y_max = 15) #> [1] Inf"},{"path":"https://bking124.github.io/rSTAR/reference/bam_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Bayesian Additive STAR Model with MCMC — bam_star","title":"Fit Bayesian Additive STAR Model with MCMC — bam_star","text":"Run MCMC algorithm STAR Bayesian additive model transformation can known (e.g., log sqrt) unknown (Box-Cox estimated nonparametrically) greater flexibility.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/bam_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Bayesian Additive STAR Model with MCMC — bam_star","text":"","code":"bam_star(   y,   X_lin,   X_nonlin,   splinetype = \"orthogonal\",   transformation = \"np\",   y_max = Inf,   nsave = 5000,   nburn = 5000,   nskip = 2,   save_y_hat = FALSE,   verbose = TRUE )"},{"path":"https://bking124.github.io/rSTAR/reference/bam_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Bayesian Additive STAR Model with MCMC — bam_star","text":"y n x 1 vector observed counts X_lin n x pL matrix predictors modelled linear X_nonlin n x pNL matrix predictors modelled nonlinear splinetype Type spline use modelling nonlinear predictors; must either \"orthogonal\" (orthogonalized splines--default) \"thinplate\" (low-rank thin plate splines) transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) \"ispline\" (transformation modeled unknown, monotone function using -splines) y_max fixed known upper bound observations; default Inf nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw save_y_hat logical; TRUE, compute save posterior draws expected counts, E(y), may slow compute verbose logical; TRUE, print time remaining","code":""},{"path":"https://bking124.github.io/rSTAR/reference/bam_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Bayesian Additive STAR Model with MCMC — bam_star","text":"list following elements: coefficients: posterior mean coefficients fitted.values: posterior mean conditional expectation counts y post.coefficients: posterior draws coefficients post.fitted.values: posterior draws conditional mean counts y post.pred: draws posterior predictive distribution y post.lambda: draws posterior distribution lambda post.sigma: draws posterior distribution sigma post.log.like.point: draws log-likelihood n observations WAIC: Widely-Applicable/Watanabe-Akaike Information Criterion p_waic: Effective number parameters based WAIC case transformation=\"ispline\", list also contains post.g: draws posterior distribution transformation g post.sigma.gamma: draws posterior distribution sigma.gamma, prior standard deviation transformation g() coefficients","code":""},{"path":"https://bking124.github.io/rSTAR/reference/bam_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit Bayesian Additive STAR Model with MCMC — bam_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. Posterior predictive inference obtained via Gibbs sampler combines () latent data augmentation step (like probit regression) (ii) existing sampler continuous data model. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt', well version Box-Cox parameter inferred within MCMC sampler ('box-cox'). Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y. Third, transformation can modeled unknown, monotone function using -splines ('ispline'). Robust Adaptive Metropolis (RAM) sampler used drawing parameter transformation function.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/bam_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Bayesian Additive STAR Model with MCMC — bam_star","text":"","code":"if (FALSE) { # Simulate data with count-valued response y: sim_dat = simulate_nb_friedman(n = 100, p = 5, seed=32) y = sim_dat$y; X = sim_dat$X  # Linear and nonlinear components: X_lin = as.matrix(X[,-(1:3)]) X_nonlin = as.matrix(X[,(1:3)])  # STAR: nonparametric transformation fit <- bam_star(y,X_lin, X_nonlin)  # Posterior mean of each coefficient: coef(fit)  # WAIC: fit$WAIC  # MCMC diagnostics: plot(as.ts(fit$post.coefficients[,1:3]))  # Posterior predictive check: hist(apply(fit$post.pred, 1,            function(x) mean(x==0)), main = 'Proportion of Zeros', xlab=''); abline(v = mean(y==0), lwd=4, col ='blue')  }"},{"path":"https://bking124.github.io/rSTAR/reference/bart_star.html","id":null,"dir":"Reference","previous_headings":"","what":"MCMC Algorithm for BART-STAR — bart_star","title":"MCMC Algorithm for BART-STAR — bart_star","text":"Run MCMC algorithm BART model count-valued responses using STAR. transformation can known (e.g., log sqrt) unknown (Box-Cox estimated nonparametrically) greater flexibility.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/bart_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MCMC Algorithm for BART-STAR — bart_star","text":"","code":"bart_star(   y,   X,   X_test = NULL,   y_test = NULL,   transformation = \"np\",   y_max = Inf,   n.trees = 200,   sigest = NULL,   sigdf = 3,   sigquant = 0.9,   k = 2,   power = 2,   base = 0.95,   nsave = 5000,   nburn = 5000,   nskip = 2,   save_y_hat = FALSE,   verbose = TRUE )"},{"path":"https://bking124.github.io/rSTAR/reference/bart_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MCMC Algorithm for BART-STAR — bart_star","text":"y n x 1 vector observed counts X n x p matrix predictors X_test n0 x p matrix predictors test data y_test n0 x 1 vector test data responses (used computing log-predictive scores) transformation transformation use latent process; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) \"ispline\" (transformation modeled unknown, monotone function using -splines) y_max fixed known upper bound observations; default Inf n.trees number trees use BART; default 200 sigest positive numeric estimate residual standard deviation (see ?bart) sigdf degrees freedom error variance prior (see ?bart) sigquant quantile error variance prior rough estimate (sigest) placed . closer quantile 1, aggresive fit (see ?bart) k number prior standard deviations E(Y|x) = f(x) away +/- 0.5. response internally scaled range -0.5 0.5. bigger k , conservative fitting (see ?bart) power power parameter tree prior (see ?bart) base base parameter tree prior (see ?bart) nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw save_y_hat logical; TRUE, compute save posterior draws expected counts, E(y), may slow compute verbose logical; TRUE, print time remaining","code":""},{"path":"https://bking124.github.io/rSTAR/reference/bart_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MCMC Algorithm for BART-STAR — bart_star","text":"list following elements: post.pred: draws posterior predictive distribution y post.sigma: draws posterior distribution sigma post.log.like.point: draws log-likelihood n observations WAIC: Widely-Applicable/Watanabe-Akaike Information Criterion p_waic: Effective number parameters based WAIC post.pred.test: draws posterior predictive distribution test points X_test (NULL X_test given) post.fitted.values.test: posterior draws conditional mean test points X_test (NULL X_test given) post.mu.test: draws conditional mean z_star test points X_test (NULL X_test given) post.log.pred.test: draws log-predictive distribution n0 test cases (NULL X_test given) fitted.values: posterior mean conditional expectation counts y (NULL save_y_hat=FALSE) post.fitted.values: posterior draws conditional mean counts y (NULL save_y_hat=FALSE) case transformation=\"ispline\", list also contains post.g: draws posterior distribution transformation g post.sigma.gamma: draws posterior distribution sigma.gamma, prior standard deviation transformation g() coefficients transformation=\"box-cox\", list also contains post.lambda: draws posterior distribution lambda","code":""},{"path":"https://bking124.github.io/rSTAR/reference/bart_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MCMC Algorithm for BART-STAR — bart_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. , model (1) Bayesian additive regression tree (BART) model. Posterior predictive inference obtained via Gibbs sampler combines () latent data augmentation step (like probit regression) (ii) existing sampler continuous data model. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt', well version Box-Cox parameter inferred within MCMC sampler ('box-cox'). Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y. Third, transformation can modeled unknown, monotone function using -splines ('ispline'). Robust Adaptive Metropolis (RAM) sampler used drawing parameter transformation function.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/bart_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MCMC Algorithm for BART-STAR — bart_star","text":"","code":"if (FALSE) { # Simulate data with count-valued response y: sim_dat = simulate_nb_friedman(n = 100, p = 10) y = sim_dat$y; X = sim_dat$X  # BART-STAR with log-transformation: fit_log = bart_star_MCMC(y = y, X = X,                          transformation = 'log', save_y_hat = TRUE)  # Fitted values plot_fitted(y = sim_dat$Ey,             post_y = fit_log$post.fitted.values,             main = 'Fitted Values: BART-STAR-log')  # WAIC for BART-STAR-log: fit_log$WAIC  # MCMC diagnostics: plot(as.ts(fit_log$post.fitted.values[,1:10]))  # Posterior predictive check: hist(apply(fit_log$post.pred, 1,            function(x) mean(x==0)), main = 'Proportion of Zeros', xlab=''); abline(v = mean(y==0), lwd=4, col ='blue')  # BART-STAR with nonparametric transformation: fit = bart_star(y = y, X = X,                      transformation = 'np', save_y_hat = TRUE)  # Fitted values plot_fitted(y = sim_dat$Ey,             post_y = fit$post.fitted.values,             main = 'Fitted Values: BART-STAR-np')  # WAIC for BART-STAR-np: fit$WAIC  # MCMC diagnostics: plot(as.ts(fit$post.fitted.values[,1:10]))  # Posterior predictive check: hist(apply(fit$post.pred, 1,            function(x) mean(x==0)), main = 'Proportion of Zeros', xlab=''); abline(v = mean(y==0), lwd=4, col ='blue') }"},{"path":"https://bking124.github.io/rSTAR/reference/bart_star_ispline.html","id":null,"dir":"Reference","previous_headings":"","what":"MCMC sampler for BART-STAR with a monotone spline model\nfor the transformation — bart_star_ispline","title":"MCMC sampler for BART-STAR with a monotone spline model\nfor the transformation — bart_star_ispline","text":"Run MCMC algorithm BART model count-valued responses using STAR. transformation modeled unknown, monotone function using -splines. Robust Adaptive Metropolis (RAM) sampler used drawing parameter transformation function.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/bart_star_ispline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MCMC sampler for BART-STAR with a monotone spline model\nfor the transformation — bart_star_ispline","text":"","code":"bart_star_ispline(   y,   X,   X_test = NULL,   y_test = NULL,   lambda_prior = 1/2,   y_max = Inf,   n.trees = 200,   sigest = NULL,   sigdf = 3,   sigquant = 0.9,   k = 2,   power = 2,   base = 0.95,   nsave = 5000,   nburn = 5000,   nskip = 2,   save_y_hat = FALSE,   target_acc_rate = 0.3,   adapt_rate = 0.75,   stop_adapt_perc = 0.5,   verbose = TRUE )"},{"path":"https://bking124.github.io/rSTAR/reference/bart_star_ispline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MCMC sampler for BART-STAR with a monotone spline model\nfor the transformation — bart_star_ispline","text":"y n x 1 vector observed counts X n x p matrix predictors X_test n0 x p matrix predictors test data y_test n0 x 1 vector test data responses (used computing log-predictive scores) lambda_prior prior mean transformation g() Box-Cox function parameter lambda_prior y_max fixed known upper bound observations; default Inf n.trees number trees use BART; default 200 sigest positive numeric estimate residual standard deviation (see ?bart) sigdf degrees freedom error variance prior (see ?bart) sigquant quantile error variance prior rough estimate (sigest) placed . closer quantile 1, aggresive fit (see ?bart) k number prior standard deviations E(Y|x) = f(x) away +/- 0.5. response internally scaled range -0.5 0.5. bigger k , conservative fitting (see ?bart) power power parameter tree prior (see ?bart) base base parameter tree prior (see ?bart) nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw save_y_hat logical; TRUE, compute save posterior draws expected counts, E(y), may slow compute target_acc_rate target acceptance rate (zero one) adapt_rate rate adaptation RAM sampler (zero one) stop_adapt_perc stop adapting proposal covariance stop_adapt_perc*nburn verbose logical; TRUE, print time remaining","code":""},{"path":"https://bking124.github.io/rSTAR/reference/bart_star_ispline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MCMC sampler for BART-STAR with a monotone spline model\nfor the transformation — bart_star_ispline","text":"list following elements: fitted.values: posterior mean conditional expectation counts y post.fitted.values: posterior draws conditional mean counts y post.pred.test: draws posterior predictive distribution test points X_test post.fitted.values.test: posterior draws conditional mean test points X_test post.pred: draws posterior predictive distribution y post.sigma: draws posterior distribution sigma post.mu.test: draws conditional mean z_star test points post.log.like.point: draws log-likelihood n observations post.log.pred.test: draws log-predictive distribution n0 test cases WAIC: Widely-Applicable/Watanabe-Akaike Information Criterion p_waic: Effective number parameters based WAIC post.g: draws posterior distribution transformation g post.sigma.gamma: draws posterior distribution sigma.gamma, prior standard deviation transformation g coefficients","code":""},{"path":"https://bking124.github.io/rSTAR/reference/bart_star_ispline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MCMC sampler for BART-STAR with a monotone spline model\nfor the transformation — bart_star_ispline","text":"","code":"if (FALSE) { # Simulate data with count-valued response y: sim_dat = simulate_nb_friedman(n = 100, p = 10) y = sim_dat$y; X = sim_dat$X  # BART-STAR with unknown I-spline transformation fit = bart_star_MCMC_ispline(y = y, X = X)  # Fitted values plot_fitted(y = sim_dat$Ey,             post_y = fit$post.fitted.values,             main = 'Fitted Values: BART-STAR-np')  # WAIC for BART-STAR-np: fit$WAIC  # MCMC diagnostics: plot(as.ts(fit$post.fitted.values[,1:10]))  # Posterior predictive check: hist(apply(fit$post.pred, 1,            function(x) mean(x==0)), main = 'Proportion of Zeros', xlab=''); abline(v = mean(y==0), lwd=4, col ='blue') }"},{"path":"https://bking124.github.io/rSTAR/reference/blm_star.html","id":null,"dir":"Reference","previous_headings":"","what":"STAR Bayesian Linear Regression — blm_star","title":"STAR Bayesian Linear Regression — blm_star","text":"STAR Bayesian Linear Regression","code":""},{"path":"https://bking124.github.io/rSTAR/reference/blm_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"STAR Bayesian Linear Regression — blm_star","text":"","code":"blm_star(   y,   X,   X_test = X,   transformation = \"np\",   y_max = Inf,   prior = \"gprior\",   use_MCMC = TRUE,   nsave = 5000,   nburn = 5000,   nskip = 0,   method_sigma = \"mle\",   approx_Fz = FALSE,   approx_Fy = FALSE,   psi = NULL,   compute_marg = FALSE )"},{"path":"https://bking124.github.io/rSTAR/reference/blm_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"STAR Bayesian Linear Regression — blm_star","text":"list following elements:","code":""},{"path":"https://bking124.github.io/rSTAR/reference/blm_star_bnpgibbs.html","id":null,"dir":"Reference","previous_headings":"","what":"Gibbs sampler for STAR linear regression with BNP transformation — blm_star_bnpgibbs","title":"Gibbs sampler for STAR linear regression with BNP transformation — blm_star_bnpgibbs","text":"Compute MCMC samples posterior predictive distributions STAR linear regression model g-prior BNP transformation.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/blm_star_bnpgibbs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gibbs sampler for STAR linear regression with BNP transformation — blm_star_bnpgibbs","text":"","code":"blm_star_bnpgibbs(   y,   X,   X_test = X,   y_max = Inf,   psi = NULL,   approx_Fz = FALSE,   approx_Fy = FALSE,   nsave = 1000,   nburn = 1000,   nskip = 0,   verbose = TRUE )"},{"path":"https://bking124.github.io/rSTAR/reference/blm_star_bnpgibbs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gibbs sampler for STAR linear regression with BNP transformation — blm_star_bnpgibbs","text":"y n x 1 vector observed counts X n x p matrix predictors X_test n0 x p matrix predictors test data; default observed covariates X y_max fixed known upper bound observations; default Inf psi prior variance (g-prior) approx_Fz logical; BNP transformation, apply (fast stable) normal approximation marginal CDF latent data approx_Fy logical; BNP transformation, approximate marginal CDF y using empirical CDF nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw","code":""},{"path":"https://bking124.github.io/rSTAR/reference/blm_star_bnpgibbs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gibbs sampler for STAR linear regression with BNP transformation — blm_star_bnpgibbs","text":"list following elements: coefficients posterior mean regression coefficients post_beta: nsave x p samples posterior distribution regression coefficients post_ytilde: nsave x n0 samples posterior predictive distribution test points X_test post_g: nsave posterior samples transformation evaluated unique y values (applies 'bnp' transformations)","code":""},{"path":"https://bking124.github.io/rSTAR/reference/blm_star_bnpgibbs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gibbs sampler for STAR linear regression with BNP transformation — blm_star_bnpgibbs","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. , continuous latent data model linear regression. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt'. Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y. distribution-based transformations approximately preserve mean variance count data y latent data scale, lends interpretability model parameters. Lastly, transformation can modeled using Bayesian bootstrap ('bnp'), Bayesian nonparametric model incorporates uncertainty transformation posterior predictive inference.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/blm_star_bnpgibbs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gibbs sampler for STAR linear regression with BNP transformation — blm_star_bnpgibbs","text":"","code":"# Simulate some data: sim_dat = simulate_nb_lm(n = 500, p = 10) y = sim_dat$y; X = sim_dat$X  # Fit a linear model: fit = blm_star_bnpgibbs(y, X, nsave = 1000, nburn = 1000) #> Error in blm_star_bnpgibbs(y, X, nsave = 1000, nburn = 1000): could not find function \"blm_star_bnpgibbs\" names(fit) #> Error in eval(expr, envir, enclos): object 'fit' not found  # Check the efficiency of the MCMC samples: getEffSize(fit$post_beta) #> Error in getEffSize(fit$post_beta): object 'fit' not found"},{"path":"https://bking124.github.io/rSTAR/reference/blm_star_exact.html","id":null,"dir":"Reference","previous_headings":"","what":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"Compute direct Monte Carlo samples posterior predictive distributions STAR linear regression model g-prior.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/blm_star_exact.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"","code":"blm_star_exact(   y,   X,   X_test = X,   transformation = \"np\",   y_max = Inf,   psi = NULL,   method_sigma = \"mle\",   approx_Fz = FALSE,   approx_Fy = FALSE,   nsave = 5000,   compute_marg = FALSE )"},{"path":"https://bking124.github.io/rSTAR/reference/blm_star_exact.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"y n x 1 vector observed counts X n x p matrix predictors X_test n0 x p matrix predictors test data; default observed covariates X transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"bnp\" (Bayesian nonparametric transformation using Bayesian bootstrap) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) y_max fixed known upper bound observations; default Inf psi prior variance (g-prior) method_sigma method estimate latent data standard deviation; must one \"mle\" use MLE STAR EM algorithm \"mmle\" use marginal MLE (Note: slower!) approx_Fz logical; BNP transformation, apply (fast stable) normal approximation marginal CDF latent data approx_Fy logical; BNP transformation, approximate marginal CDF y using empirical CDF nsave number Monte Carlo simulations compute_marg logical; TRUE, compute return marginal likelihood","code":""},{"path":"https://bking124.github.io/rSTAR/reference/blm_star_exact.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"list following elements: coefficients posterior mean regression coefficients post_beta: nsave x p samples posterior distribution regression coefficients post_ytilde: nsave x n0 samples posterior predictive distribution test points X_test post_g: nsave posterior samples transformation evaluated unique y values (applies 'bnp' transformations) marg_like: marginal likelihood (requested; otherwise NULL)","code":""},{"path":"https://bking124.github.io/rSTAR/reference/blm_star_exact.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. , continuous latent data model linear regression. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt'. Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y. distribution-based transformations approximately preserve mean variance count data y latent data scale, lends interpretability model parameters. Lastly, transformation can modeled using Bayesian bootstrap ('bnp'), Bayesian nonparametric model incorporates uncertainty transformation posterior predictive inference. Monte Carlo sampler produces direct, discrete, joint draws posterior distribution posterior predictive distribution linear regression model g-prior.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/blm_star_exact.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"'bnp' transformation (without Fy approximation) slower transformations way TruncatedNormal sampler must updated lower upper limits change (due sampling g). Thus, computational improvements likely available.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/blm_star_exact.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Monte Carlo sampler for STAR linear regression with a g-prior — blm_star_exact","text":"","code":"# Simulate some data: sim_dat = simulate_nb_lm(n = 100, p = 10) y = sim_dat$y; X = sim_dat$X  # Fit a linear model: fit = blm_star_exact(y, X) #> Error in blm_star_exact(y, X): could not find function \"blm_star_exact\" names(fit) #> Error in eval(expr, envir, enclos): object 'fit' not found  # Check the efficiency of the Monte Carlo samples: getEffSize(fit$post_beta) #> Error in getEffSize(fit$post_beta): object 'fit' not found"},{"path":"https://bking124.github.io/rSTAR/reference/computeTimeRemaining.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the remaining time in the MCMC based on previous samples — computeTimeRemaining","title":"Estimate the remaining time in the MCMC based on previous samples — computeTimeRemaining","text":"Estimate remaining time MCMC based previous samples","code":""},{"path":"https://bking124.github.io/rSTAR/reference/computeTimeRemaining.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the remaining time in the MCMC based on previous samples — computeTimeRemaining","text":"","code":"computeTimeRemaining(nsi, timer0, nsims, nrep = 1000)"},{"path":"https://bking124.github.io/rSTAR/reference/computeTimeRemaining.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the remaining time in the MCMC based on previous samples — computeTimeRemaining","text":"nsi Current iteration timer0 Initial timer value, returned proc.time()[3] nsims Total number simulations nrep Print estimated time remaining every nrep iterations","code":""},{"path":"https://bking124.github.io/rSTAR/reference/computeTimeRemaining.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the remaining time in the MCMC based on previous samples — computeTimeRemaining","text":"Table summary statistics using function summary","code":""},{"path":"https://bking124.github.io/rSTAR/reference/confint.lmstar.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute asymptotic confidence intervals for STAR linear regression — confint.lmstar","title":"Compute asymptotic confidence intervals for STAR linear regression — confint.lmstar","text":"linear regression model within STAR framework, compute (asymptotic) confidence intervals regression coefficient interest. Confidence intervals computed inverting likelihood ratio test profiling log-likelihood.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/confint.lmstar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute asymptotic confidence intervals for STAR linear regression — confint.lmstar","text":"","code":"# S3 method for lmstar confint(object, j, level = 0.95, include_plot = TRUE)"},{"path":"https://bking124.github.io/rSTAR/reference/confint.lmstar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute asymptotic confidence intervals for STAR linear regression — confint.lmstar","text":"object Object class \"lmstar\" output lm_star j scalar column index desired confidence interval level confidence level; default 0.95 include_plot logical; TRUE, include plot profile likelihood","code":""},{"path":"https://bking124.github.io/rSTAR/reference/confint.lmstar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute asymptotic confidence intervals for STAR linear regression — confint.lmstar","text":"upper lower endpoints confidence interval","code":""},{"path":"https://bking124.github.io/rSTAR/reference/confint.lmstar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute asymptotic confidence intervals for STAR linear regression — confint.lmstar","text":"","code":"# Simulate data with count-valued response y: sim_dat = simulate_nb_lm(n = 100, p = 2) y = sim_dat$y; X = sim_dat$X  # Select a transformation: transformation = 'np'  #Estimate model fit = lm_star(y~X, transformation=transformation)  # Confidence interval for the intercept: ci_beta_0 = confint(fit, j = 1)  ci_beta_0 #> [1] -0.1875115  0.1857334  # Confidence interval for the slope: ci_beta_1 = confint(fit, j = 2)  ci_beta_1 #> [1] 0.2680532 0.6766080"},{"path":"https://bking124.github.io/rSTAR/reference/credBands.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Simultaneous Credible Bands — credBands","title":"Compute Simultaneous Credible Bands — credBands","text":"Compute (1-alpha)% credible BANDS function based MCMC samples using Crainiceanu et al. (2007)","code":""},{"path":"https://bking124.github.io/rSTAR/reference/credBands.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Simultaneous Credible Bands — credBands","text":"","code":"credBands(sampFuns, alpha = 0.05)"},{"path":"https://bking124.github.io/rSTAR/reference/credBands.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Simultaneous Credible Bands — credBands","text":"sampFuns Nsims x m matrix Nsims MCMC samples m points along curve alpha confidence level","code":""},{"path":"https://bking124.github.io/rSTAR/reference/credBands.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Simultaneous Credible Bands — credBands","text":"m x 2 matrix credible bands; first column lower band, second upper band","code":""},{"path":"https://bking124.github.io/rSTAR/reference/credBands.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute Simultaneous Credible Bands — credBands","text":"input needs curves: simultaneous credible \"bands\" may computed vectors. resulting credible intervals provide joint coverage (1-alpha) level across components vector.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/ergMean.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the ergodic (running) mean. — ergMean","title":"Compute the ergodic (running) mean. — ergMean","text":"Compute ergodic (running) mean.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/ergMean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the ergodic (running) mean. — ergMean","text":"","code":"ergMean(x)"},{"path":"https://bking124.github.io/rSTAR/reference/ergMean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the ergodic (running) mean. — ergMean","text":"x vector compute running mean","code":""},{"path":"https://bking124.github.io/rSTAR/reference/ergMean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the ergodic (running) mean. — ergMean","text":"vector y element defined y[] = mean(x[1:])","code":""},{"path":"https://bking124.github.io/rSTAR/reference/ergMean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the ergodic (running) mean. — ergMean","text":"","code":"# Compare: ergMean(1:10) #>  [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 mean(1:10) #> [1] 5.5  # Running mean for iid N(5, 1) samples: x = rnorm(n = 10^4, mean = 5, sd = 1) plot(ergMean(x)) abline(h=5)"},{"path":"https://bking124.github.io/rSTAR/reference/expectation2_gRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute E(Y^2) for a STAR process — expectation2_gRcpp","title":"Compute E(Y^2) for a STAR process — expectation2_gRcpp","text":"Compute conditional expectation Y^2 STAR process Y generic link function g.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/expectation2_gRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute E(Y^2) for a STAR process — expectation2_gRcpp","text":"","code":"expectation2_gRcpp(g_a_j, g_a_jp1, mu, sigma, Jmax)"},{"path":"https://bking124.github.io/rSTAR/reference/expectation2_gRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute E(Y^2) for a STAR process — expectation2_gRcpp","text":"g_a_j Jmax x 1 vector g((j)) g_a_jp1 Jmax x 1 vector g((j + 1)) mu m x 1 vector conditional expectations sigma m x 1 vector conditional standard deviations Jmax m x 1 vector maximum integer values consider","code":""},{"path":"https://bking124.github.io/rSTAR/reference/expectation2_gRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute E(Y^2) for a STAR process — expectation2_gRcpp","text":"y2_hat m x 1 vector conditional expectations","code":""},{"path":"https://bking124.github.io/rSTAR/reference/expectation2_gRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute E(Y^2) for a STAR process — expectation2_gRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/expectation_gRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the mean for a STAR process — expectation_gRcpp","title":"Estimate the mean for a STAR process — expectation_gRcpp","text":"Estimate conditional expectation STAR process generic link function g.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/expectation_gRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the mean for a STAR process — expectation_gRcpp","text":"","code":"expectation_gRcpp(g_a_j, g_a_jp1, mu, sigma, Jmax)"},{"path":"https://bking124.github.io/rSTAR/reference/expectation_gRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the mean for a STAR process — expectation_gRcpp","text":"g_a_j Jmax x 1 vector g((j)) g_a_jp1 Jmax x 1 vector g((j + 1)) mu m x 1 vector conditional expectations sigma m x 1 vector conditional standard deviations Jmax m x 1 vector maximum integer values consider","code":""},{"path":"https://bking124.github.io/rSTAR/reference/expectation_gRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the mean for a STAR process — expectation_gRcpp","text":"y_hat m x 1 vector conditional expectations","code":""},{"path":"https://bking124.github.io/rSTAR/reference/expectation_gRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimate the mean for a STAR process — expectation_gRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/expectation_identity.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the mean for a STAR process — expectation_identity","title":"Estimate the mean for a STAR process — expectation_identity","text":"Estimate conditional expectation STAR process identity link function.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/expectation_identity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the mean for a STAR process — expectation_identity","text":"","code":"expectation_identity(a, Jmax, Mu, sigma_t, Offset)"},{"path":"https://bking124.github.io/rSTAR/reference/expectation_identity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the mean for a STAR process — expectation_identity","text":"Jmaxmax-dimensonal vector STAR integers a_j Jmax T x m matrix maximum integer values consider Mu T x m matrix latent means sigma_t T-dimensional vector time-dependent latent error sd's Offset T x m matrix offsets","code":""},{"path":"https://bking124.github.io/rSTAR/reference/expectation_identity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the mean for a STAR process — expectation_identity","text":"Zhat T x m matrix conditional expectations","code":""},{"path":"https://bking124.github.io/rSTAR/reference/expectation_identity.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimate the mean for a STAR process — expectation_identity","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/expectation_log.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the mean for a STAR process — expectation_log","title":"Estimate the mean for a STAR process — expectation_log","text":"Estimate conditional expectation STAR process log link function.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/expectation_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the mean for a STAR process — expectation_log","text":"","code":"expectation_log(a, Jmax, Mu, sigma_t, Offset)"},{"path":"https://bking124.github.io/rSTAR/reference/expectation_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the mean for a STAR process — expectation_log","text":"Jmaxmax-dimensonal vector STAR integers a_j Jmax T x m matrix maximum integer values consider Mu T x m matrix latent means sigma_t T-dimensional vector time-dependent latent error sd's Offset T x m matrix offsets","code":""},{"path":"https://bking124.github.io/rSTAR/reference/expectation_log.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the mean for a STAR process — expectation_log","text":"Zhat T x m matrix conditional expectations","code":""},{"path":"https://bking124.github.io/rSTAR/reference/expectation_log.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimate the mean for a STAR process — expectation_log","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/expectation_sqrt.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the mean for a STAR process — expectation_sqrt","title":"Estimate the mean for a STAR process — expectation_sqrt","text":"Estimate conditional expectation STAR process square root link function.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/expectation_sqrt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the mean for a STAR process — expectation_sqrt","text":"","code":"expectation_sqrt(a, Jmax, Mu, sigma_t, Offset)"},{"path":"https://bking124.github.io/rSTAR/reference/expectation_sqrt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the mean for a STAR process — expectation_sqrt","text":"Jmaxmax-dimensonal vector STAR integers a_j Jmax T x m matrix maximum integer values consider Mu T x m matrix latent means sigma_t T-dimensional vector time-dependent latent error sd's Offset T x m matrix offsets","code":""},{"path":"https://bking124.github.io/rSTAR/reference/expectation_sqrt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the mean for a STAR process — expectation_sqrt","text":"Zhat T x m matrix conditional expectations","code":""},{"path":"https://bking124.github.io/rSTAR/reference/expectation_sqrt.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimate the mean for a STAR process — expectation_sqrt","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/g_bc.html","id":null,"dir":"Reference","previous_headings":"","what":"Box-Cox transformation — g_bc","title":"Box-Cox transformation — g_bc","text":"Evaluate Box-Cox transformation, scaled power transformation preserve continuity index lambda zero. Negative values permitted.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/g_bc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Box-Cox transformation — g_bc","text":"","code":"g_bc(t, lambda)"},{"path":"https://bking124.github.io/rSTAR/reference/g_bc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Box-Cox transformation — g_bc","text":"t argument(s) evaluate function lambda Box-Cox parameter","code":""},{"path":"https://bking124.github.io/rSTAR/reference/g_bc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Box-Cox transformation — g_bc","text":"evaluation(s) Box-Cox function given input(s) t.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/g_bc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Box-Cox transformation — g_bc","text":"Special cases include identity transformation (lambda = 1), square-root transformation (lambda = 1/2), log transformation (lambda = 0).","code":""},{"path":"https://bking124.github.io/rSTAR/reference/g_bc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Box-Cox transformation — g_bc","text":"","code":"# Log-transformation: g_bc(1:5, lambda = 0); log(1:5) #> [1] 0.0000000 0.6931472 1.0986123 1.3862944 1.6094379 #> [1] 0.0000000 0.6931472 1.0986123 1.3862944 1.6094379  # Square-root transformation: note the shift and scaling g_bc(1:5, lambda = 1/2); sqrt(1:5) #> [1] 0.0000000 0.8284271 1.4641016 2.0000000 2.4721360 #> [1] 1.000000 1.414214 1.732051 2.000000 2.236068"},{"path":"https://bking124.github.io/rSTAR/reference/g_bnp.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian bootstrap-based transformation — g_bnp","title":"Bayesian bootstrap-based transformation — g_bnp","text":"Compute one posterior draw smoothed transformation implied (separate) Bayesian bootstrap models CDFs y X.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/g_bnp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian bootstrap-based transformation — g_bnp","text":"","code":"g_bnp(   y,   xtSigmax = rep(0, length(y)),   zgrid = NULL,   sigma_epsilon = 1,   approx_Fz = FALSE )"},{"path":"https://bking124.github.io/rSTAR/reference/g_bnp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian bootstrap-based transformation — g_bnp","text":"y n x 1 vector observed counts xtSigmax n x 1 vector t(X_i) Sigma_theta X_i, Sigma_theta prior variance zgrid optional vector grid points evaluating CDF z (Fz) sigma_epsilon latent standard deviation approx_Fz logical; TRUE, use normal approximation Fz, marginal CDF latent z, faster stable","code":""},{"path":"https://bking124.github.io/rSTAR/reference/g_bnp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian bootstrap-based transformation — g_bnp","text":"smooth monotone function can used evaluations transformation posterior draw.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/g_bnp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian bootstrap-based transformation — g_bnp","text":"","code":"if (FALSE) { # Sample some data: y = rpois(n = 200, lambda = 5) # Compute 200 draws of g on a grid: t = seq(0, max(y), length.out = 100) # grid g_post = t(sapply(1:500, function(s) g_bnp(y)(t))) # Plot together: plot(t, t, ylim = range(g_post), type='n', ylab = 'g(t)',  main = 'Bayesian bootstrap posterior: g') apply(g_post, 1, function(g) lines(t, g, col='gray')) # And the posterior mean of g: lines(t, colMeans(g_post), lwd=3) }"},{"path":"https://bking124.github.io/rSTAR/reference/g_cdf.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative distribution function (CDF)-based transformation — g_cdf","title":"Cumulative distribution function (CDF)-based transformation — g_cdf","text":"Compute CDF-based transformation using observed count data. CDF can estimated nonparametrically parametrically based Poisson Negative-Binimial distributions. parametric case, parameters determined based moments y. Note fixed quantity come uncertainty quantification.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/g_cdf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative distribution function (CDF)-based transformation — g_cdf","text":"","code":"g_cdf(y, distribution = \"np\")"},{"path":"https://bking124.github.io/rSTAR/reference/g_cdf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative distribution function (CDF)-based transformation — g_cdf","text":"y n x 1 vector observed counts distribution distribution used CDF; must one \"np\" (empirical CDF) \"pois\" (moment-matched marginal Poisson CDF) \"neg-bin\" (moment-matched marginal Negative Binomial CDF)","code":""},{"path":"https://bking124.github.io/rSTAR/reference/g_cdf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative distribution function (CDF)-based transformation — g_cdf","text":"smooth monotone function can used evaluations transformation.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/g_cdf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative distribution function (CDF)-based transformation — g_cdf","text":"","code":"# Sample some data: y = rpois(n = 500, lambda = 5)  # Empirical CDF version: g_np = g_cdf(y, distribution = 'np')  # Poisson version: g_pois = g_cdf(y, distribution = 'pois')  # Negative binomial version: g_negbin = g_cdf(y, distribution = 'neg-bin')  # Plot together: t = 1:max(y) # grid plot(t, g_np(t), type='l') lines(t, g_pois(t), lty = 2) lines(t, g_negbin(t), lty = 3)"},{"path":"https://bking124.github.io/rSTAR/reference/g_inv_approx.html","id":null,"dir":"Reference","previous_headings":"","what":"Approximate inverse transformation — g_inv_approx","title":"Approximate inverse transformation — g_inv_approx","text":"Compute inverse function transformation g based grid search.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/g_inv_approx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Approximate inverse transformation — g_inv_approx","text":"","code":"g_inv_approx(g, t_grid)"},{"path":"https://bking124.github.io/rSTAR/reference/g_inv_approx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Approximate inverse transformation — g_inv_approx","text":"g transformation function t_grid grid arguments evaluate transformation function","code":""},{"path":"https://bking124.github.io/rSTAR/reference/g_inv_approx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Approximate inverse transformation — g_inv_approx","text":"function can used evaluations (approximate) inverse transformation function.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/g_inv_approx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Approximate inverse transformation — g_inv_approx","text":"","code":"# Sample some data: y = rpois(n = 500, lambda = 5)  # Empirical CDF transformation: g_np = g_cdf(y, distribution = 'np')  # Grid for approximation: t_grid = seq(1, max(y), length.out = 100)  # Approximate inverse: g_inv = g_inv_approx(g = g_np, t_grid = t_grid)  # Check the approximation: plot(t_grid, g_inv(g_np(t_grid)), type='p') lines(t_grid, t_grid)"},{"path":"https://bking124.github.io/rSTAR/reference/g_inv_bc.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse Box-Cox transformation — g_inv_bc","title":"Inverse Box-Cox transformation — g_inv_bc","text":"Evaluate inverse Box-Cox transformation. Negative values permitted.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/g_inv_bc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse Box-Cox transformation — g_inv_bc","text":"","code":"g_inv_bc(s, lambda)"},{"path":"https://bking124.github.io/rSTAR/reference/g_inv_bc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse Box-Cox transformation — g_inv_bc","text":"s argument(s) evaluate function lambda Box-Cox parameter","code":""},{"path":"https://bking124.github.io/rSTAR/reference/g_inv_bc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse Box-Cox transformation — g_inv_bc","text":"evaluation(s) inverse Box-Cox function given input(s) s.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/g_inv_bc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Inverse Box-Cox transformation — g_inv_bc","text":"Special cases include identity transformation (lambda = 1), square-root transformation (lambda = 1/2), log transformation (lambda = 0). #' @examples # (Inverse) log-transformation: g_inv_bc(1:5, lambda = 0); exp(1:5) # (Inverse) square-root transformation: note shift scaling g_inv_bc(1:5, lambda = 1/2); (1:5)^2","code":""},{"path":"https://bking124.github.io/rSTAR/reference/gbm_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"Compute MLEs log-likelihood Gradient Boosting Machines (GBM) STAR model. STAR model requires *transformation* *estimation function* conditional mean given observed data. transformation can known (e.g., log sqrt) unknown (Box-Cox estimated nonparametrically) greater flexibility. estimator case GBM. Standard function calls including fitted residuals apply.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/gbm_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"","code":"gbm_star(   y,   X,   X.test = NULL,   transformation = \"np\",   y_max = Inf,   sd_init = 10,   tol = 10^-10,   max_iters = 1000,   n.trees = 100,   interaction.depth = 1,   shrinkage = 0.1,   bag.fraction = 1 )"},{"path":"https://bking124.github.io/rSTAR/reference/gbm_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"y n x 1 vector observed counts X n x p matrix predictors X.test m x p matrix --sample predictors transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) y_max fixed known upper bound observations; default Inf sd_init add random noise EM algorithm initialization scaled sd_init times Gaussian MLE standard deviation; default 10 tol tolerance stopping EM algorithm; default 10^-10; max_iters maximum number EM iterations stopping; default 1000 n.trees Integer specifying total number trees fit. equivalent number iterations number basis functions additive expansion. Default 100. interaction.depth Integer specifying maximum depth tree (.e., highest level variable interactions allowed). value 1 implies additive model, value 2 implies model 2-way interactions, etc. Default 1. shrinkage shrinkage parameter applied tree expansion. Also known learning rate step-size reduction; 0.001 0.1 usually work, smaller learning rate typically requires trees. Default 0.1. bag.fraction fraction training set observations randomly selected propose next tree expansion. introduces randomnesses model fit. bag.fraction < 1 running model twice result similar different fits. Default 1 (deterministic prediction).","code":""},{"path":"https://bking124.github.io/rSTAR/reference/gbm_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"list following elements: fitted.values: fitted values MLEs (training) fitted.values.test: fitted values MLEs (testing) g.hat function containing (known estimated) transformation sigma.hat MLE standard deviation mu.hat MLE conditional mean (transformed scale) z.hat estimated latent data (transformed scale) MLEs residuals Dunn-Smyth residuals (randomized) residuals_rep Dunn-Smyth residuals (randomized) 10 replicates logLik log-likelihood MLEs logLik0 log-likelihood MLEs *unrounded* initialization lambda Box-Cox nonlinear parameter gbmObj: object returned gbm() MLEs parameters (1) track parameters across EM iterations (2) record model specifications","code":""},{"path":"https://bking124.github.io/rSTAR/reference/gbm_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. Gaussian model case GBM.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/gbm_star.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"Infinite latent data values may occur transformed Gaussian model highly inadequate. case, function returns *indices* data points infinite latent values, significant outliers model. Deletion indices re-running model one option, care must taken ensure () appropriate treat observations outliers (ii) model adequate remaining data points.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/gbm_star.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"Kowal, D. R., & Wu, B. (2021). Semiparametric count data regression self‐reported mental health. Biometrics. doi:10.1111/biom.13617","code":""},{"path":"https://bking124.github.io/rSTAR/reference/gbm_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting STAR Gradient Boosting Machines via EM algorithm — gbm_star","text":"","code":"# Simulate data with count-valued response y: sim_dat = simulate_nb_friedman(n = 100, p = 10) y = sim_dat$y; X = sim_dat$X  # EM algorithm for STAR (using the log-link) fit_em = gbm_star(y = y, X = X,                  transformation = 'log')  # Evaluate convergence: plot(fit_em$logLik_all, type='l', main = 'GBM-STAR-log', xlab = 'Iteration', ylab = 'log-lik')   # Fitted values: y_hat = fitted(fit_em) plot(y_hat, y);   # Residuals: plot(residuals(fit_em))  qqnorm(residuals(fit_em)); qqline(residuals(fit_em))   # Log-likelihood at MLEs: fit_em$logLik #> [1] -175.3269"},{"path":"https://bking124.github.io/rSTAR/reference/genEM_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized EM estimation for STAR — genEM_star","title":"Generalized EM estimation for STAR — genEM_star","text":"Compute MLEs log-likelihood generalized STAR model. STAR model requires *transformation* *estimation function* conditional mean given observed data. transformation can known (e.g., log sqrt) unknown (Box-Cox estimated nonparametrically) greater flexibility. estimator can least squares estimator, including nonlinear models. Standard function calls including coefficients(), fitted(), residuals() apply.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/genEM_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized EM estimation for STAR — genEM_star","text":"","code":"genEM_star(   y,   estimator,   transformation = \"np\",   y_max = Inf,   sd_init = 10,   tol = 10^-10,   max_iters = 1000 )"},{"path":"https://bking124.github.io/rSTAR/reference/genEM_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized EM estimation for STAR — genEM_star","text":"y n x 1 vector observed counts estimator function inputs data y outputs list two elements: fitted values fitted.values parameter estimates coefficients transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) y_max fixed known upper bound observations; default Inf sd_init add random noise EM algorithm initialization scaled sd_init times Gaussian MLE standard deviation; default 10 tol tolerance stopping EM algorithm; default 10^-10; max_iters maximum number EM iterations stopping; default 1000","code":""},{"path":"https://bking124.github.io/rSTAR/reference/genEM_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized EM estimation for STAR — genEM_star","text":"list following elements: coefficients MLEs coefficients fitted.values fitted values MLEs g.hat function containing (known estimated) transformation sigma.hat MLE standard deviation mu.hat MLE conditional mean (transformed scale) z.hat estimated latent data (transformed scale) MLEs residuals Dunn-Smyth residuals (randomized) residuals_rep Dunn-Smyth residuals (randomized) 10 replicates logLik log-likelihood MLEs logLik0 log-likelihood MLEs *unrounded* initialization lambda Box-Cox nonlinear parameter parameters (1) track parameters across EM iterations (2) record model specifications","code":""},{"path":"https://bking124.github.io/rSTAR/reference/genEM_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized EM estimation for STAR — genEM_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. expectation-maximization (EM) algorithm used produce maximum likelihood estimators (MLEs) parameters defined estimator function, linear regression coefficients, define Gaussian model continuous latent data. Fitted values (point predictions), residuals, log-likelihood values also available. Inference estimators proceeds via classical maximum likelihood. Initialization EM algorithm can randomized monitor convergence. However, log-likelihood concave transformations (except 'box-cox'), global convergence guaranteed. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt', well version Box-Cox parameter estimated within EM algorithm ('box-cox'). Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/genEM_star.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Generalized EM estimation for STAR — genEM_star","text":"Infinite latent data values may occur transformed Gaussian model highly inadequate. case, function returns *indices* data points infinite latent values, significant outliers model. Deletion indices re-running model one option, care must taken ensure () appropriate treat observations outliers (ii) model adequate remaining data points.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/genEM_star.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized EM estimation for STAR — genEM_star","text":"Kowal, D. R., & Wu, B. (2021). Semiparametric count data regression self‐reported mental health. Biometrics. doi:10.1111/biom.13617","code":""},{"path":"https://bking124.github.io/rSTAR/reference/genEM_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized EM estimation for STAR — genEM_star","text":"","code":"# Simulate data with count-valued response y: sim_dat = simulate_nb_friedman(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Select a transformation: transformation = 'np'  # Example using GAM as underlying estimator (for illustration purposes only) fit_em = star_EM(y = y,                  estimator = function(y) gam(y ~ s(X1)+s(X2), data=data.frame(y,X)),                   transformation = transformation) #> Error in star_EM(y = y, estimator = function(y) gam(y ~ s(X1) + s(X2),     data = data.frame(y, X)), transformation = transformation): could not find function \"star_EM\"  # Fitted coefficients: coef(fit_em) #> Error in coef(fit_em): object 'fit_em' not found  # Fitted values: y_hat = fitted(fit_em) #> Error in fitted(fit_em): object 'fit_em' not found plot(y_hat, y); #> Error in plot(y_hat, y): object 'y_hat' not found  # Log-likelihood at MLEs: fit_em$logLik #> Error in eval(expr, envir, enclos): object 'fit_em' not found"},{"path":"https://bking124.github.io/rSTAR/reference/genMCMC_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized MCMC Algorithm for STAR — genMCMC_star","title":"Generalized MCMC Algorithm for STAR — genMCMC_star","text":"Run MCMC algorithm STAR given function initialize model parameters; function sample (.e., update) model parameters. transformation can known (e.g., log sqrt) unknown (Box-Cox estimated nonparametrically) greater flexibility.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/genMCMC_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized MCMC Algorithm for STAR — genMCMC_star","text":"","code":"genMCMC_star(   y,   sample_params,   init_params,   transformation = \"np\",   y_max = Inf,   nsave = 5000,   nburn = 5000,   nskip = 2,   save_y_hat = FALSE,   verbose = TRUE )"},{"path":"https://bking124.github.io/rSTAR/reference/genMCMC_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized MCMC Algorithm for STAR — genMCMC_star","text":"y n x 1 vector observed counts sample_params function inputs data y named list params containing mu: n x 1 vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu outputs updated list params samples full conditional posterior distribution coefficients sigma (updates mu) init_params initializing function inputs data y initializes named list params mu, sigma, coefficients transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) y_max fixed known upper bound observations; default Inf nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw save_y_hat logical; TRUE, compute save posterior draws expected counts, E(y), may slow compute verbose logical; TRUE, print time remaining","code":""},{"path":"https://bking124.github.io/rSTAR/reference/genMCMC_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized MCMC Algorithm for STAR — genMCMC_star","text":"list following elements: coefficients: posterior mean coefficients fitted.values: posterior mean conditional expectation counts y post.coefficients: posterior draws coefficients post.fitted.values: posterior draws conditional mean counts y post.pred: draws posterior predictive distribution y post.lambda: draws posterior distribution lambda post.sigma: draws posterior distribution sigma post.log.like.point: draws log-likelihood n observations WAIC: Widely-Applicable/Watanabe-Akaike Information Criterion p_waic: Effective number parameters based WAIC","code":""},{"path":"https://bking124.github.io/rSTAR/reference/genMCMC_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized MCMC Algorithm for STAR — genMCMC_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. Posterior predictive inference obtained via Gibbs sampler combines () latent data augmentation step (like probit regression) (ii) existing sampler continuous data model. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt', well version Box-Cox parameter inferred within MCMC sampler ('box-cox'). Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/genMCMC_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized MCMC Algorithm for STAR — genMCMC_star","text":"","code":"if (FALSE) { # Simulate data with count-valued response y: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # STAR: log-transformation: fit_log = star_MCMC(y = y,                          sample_params = function(y, params) sample_params_lm(y, X, params),                          init_params = function(y) init_params_lm(y, X),                          transformation = 'log') # Posterior mean of each coefficient: coef(fit_log)  # WAIC for STAR-log: fit_log$WAIC  # MCMC diagnostics: plot(as.ts(fit_log$post.coefficients[,1:3]))  # Posterior predictive check: hist(apply(fit_log$post.pred, 1,            function(x) mean(x==0)), main = 'Proportion of Zeros', xlab=''); abline(v = mean(y==0), lwd=4, col ='blue')  # STAR: nonparametric transformation fit = star_MCMC(y = y,                 sample_params = function(y, params) sample_params_lm(y, X, params),                 init_params = function(y) init_params_lm(y, X),                 transformation = 'np')  # Posterior mean of each coefficient: coef(fit)  # WAIC: fit$WAIC  # MCMC diagnostics: plot(as.ts(fit$post.coefficients[,1:3]))  # Posterior predictive check: hist(apply(fit$post.pred, 1,            function(x) mean(x==0)), main = 'Proportion of Zeros', xlab=''); abline(v = mean(y==0), lwd=4, col ='blue')  }"},{"path":"https://bking124.github.io/rSTAR/reference/genMCMC_star_ispline.html","id":null,"dir":"Reference","previous_headings":"","what":"MCMC sampler for STAR with a monotone spline model\nfor the transformation — genMCMC_star_ispline","title":"MCMC sampler for STAR with a monotone spline model\nfor the transformation — genMCMC_star_ispline","text":"Run MCMC algorithm STAR given function initialize model parameters; function sample (.e., update) model parameters. transformation modeled unknown, monotone function using -splines. Robust Adaptive Metropolis (RAM) sampler used drawing parameter transformation function.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/genMCMC_star_ispline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MCMC sampler for STAR with a monotone spline model\nfor the transformation — genMCMC_star_ispline","text":"","code":"genMCMC_star_ispline(   y,   sample_params,   init_params,   lambda_prior = 1/2,   y_max = Inf,   nsave = 5000,   nburn = 5000,   nskip = 2,   save_y_hat = FALSE,   target_acc_rate = 0.3,   adapt_rate = 0.75,   stop_adapt_perc = 0.5,   verbose = TRUE )"},{"path":"https://bking124.github.io/rSTAR/reference/genMCMC_star_ispline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MCMC sampler for STAR with a monotone spline model\nfor the transformation — genMCMC_star_ispline","text":"y n x 1 vector observed counts sample_params function inputs data y named list params containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu outputs updated list params samples full conditional posterior distribution coefficients sigma (updates mu) init_params initializing function inputs data y initializes named list params mu, sigma, coefficients lambda_prior prior mean transformation g() Box-Cox function parameter lambda_prior y_max fixed known upper bound observations; default Inf nsave number MCMC iterations save nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw save_y_hat logical; TRUE, compute save posterior draws expected counts, E(y), may slow compute target_acc_rate target acceptance rate (zero one) adapt_rate rate adaptation RAM sampler (zero one) stop_adapt_perc stop adapting proposal covariance stop_adapt_perc*nburn verbose logical; TRUE, print time remaining","code":""},{"path":"https://bking124.github.io/rSTAR/reference/genMCMC_star_ispline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MCMC sampler for STAR with a monotone spline model\nfor the transformation — genMCMC_star_ispline","text":"list following elements: coefficients: posterior mean coefficients fitted.values: posterior mean conditional expectation counts y post.coefficients: posterior draws coefficients post.fitted.values: posterior draws conditional mean counts y post.pred: draws posterior predictive distribution y post.sigma: draws posterior distribution sigma post.log.like.point: draws log-likelihood n observations WAIC: Widely-Applicable/Watanabe-Akaike Information Criterion p_waic: Effective number parameters based WAIC post.g: draws posterior distribution transformation g post.sigma.gamma: draws posterior distribution sigma.gamma, prior standard deviation transformation g() coefficients","code":""},{"path":"https://bking124.github.io/rSTAR/reference/genMCMC_star_ispline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MCMC sampler for STAR with a monotone spline model\nfor the transformation — genMCMC_star_ispline","text":"","code":"if (FALSE) { # Simulate data with count-valued response y: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # STAR: unknown I-spline transformation fit = genMCMC_star_ispline(y = y,                          sample_params = function(y, params) sample_params_lm(y, X, params),                          init_params = function(y) init_params_lm(y, X)) # Posterior mean of each coefficient: coef(fit)  # WAIC for STAR-np: fit$WAIC  # MCMC diagnostics: plot(as.ts(fit$post.coefficients[,1:3]))  # Posterior predictive check: hist(apply(fit$post.pred, 1,            function(x) mean(x==0)), main = 'Proportion of Zeros', xlab=''); abline(v = mean(y==0), lwd=4, col ='blue')  }"},{"path":"https://bking124.github.io/rSTAR/reference/getEffSize.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize of effective sample size — getEffSize","title":"Summarize of effective sample size — getEffSize","text":"Compute summary statistics effective sample size (ESS) across posterior samples possibly many variables","code":""},{"path":"https://bking124.github.io/rSTAR/reference/getEffSize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize of effective sample size — getEffSize","text":"","code":"getEffSize(postX)"},{"path":"https://bking124.github.io/rSTAR/reference/getEffSize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize of effective sample size — getEffSize","text":"postX array arbitrary dimension (nsims x ... x ...), nsims number posterior samples","code":""},{"path":"https://bking124.github.io/rSTAR/reference/getEffSize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize of effective sample size — getEffSize","text":"Table summary statistics using function summary().","code":""},{"path":"https://bking124.github.io/rSTAR/reference/getEffSize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize of effective sample size — getEffSize","text":"","code":"# ESS for iid simulations: rand_iid = rnorm(n = 10^4) getEffSize(rand_iid) #>   var1  #> 9673.3   # ESS for several AR(1) simulations with coefficients 0.1, 0.2,...,0.9: rand_ar1 = sapply(seq(0.1, 0.9, by = 0.1), function(x) arima.sim(n = 10^4, list(ar = x))) getEffSize(rand_ar1) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   432.8  1866.4  3310.5  3783.7  5328.5  8183.3"},{"path":"https://bking124.github.io/rSTAR/reference/init_bam_orthog.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize the parameters for an additive model — init_bam_orthog","title":"Initialize the parameters for an additive model — init_bam_orthog","text":"Initialize parameters additive model, may contain linear nonlinear predictors. nonlinear terms modeled using orthogonalized splines.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_bam_orthog.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize the parameters for an additive model — init_bam_orthog","text":"","code":"init_bam_orthog(y, X_lin, X_nonlin, B_all = NULL)"},{"path":"https://bking124.github.io/rSTAR/reference/init_bam_orthog.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize the parameters for an additive model — init_bam_orthog","text":"y n x 1 vector data X_lin n x pL matrix predictors modelled linear X_nonlin n x pNL matrix predictors modelled nonlinear B_all optional pNL-dimensional list n x L[j] dimensional basis matrices nonlinear term j=1,...,pNL; NULL, compute internally","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_bam_orthog.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize the parameters for an additive model — init_bam_orthog","text":"named list params containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_bam_orthog.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize the parameters for an additive model — init_bam_orthog","text":"parameters coefficients : beta: p x 1 linear coefficients, including linear terms X_nonlin f_j: n x pNL matrix fitted values nonlinear function theta_j: pNL-dimensional nonlinear basis coefficients sigma_beta: p x 1 vector linear regression coefficient standard deviations sigma_theta_j: pNL x 1 vector nonlinear coefficient standard deviations","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_bam_orthog.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize the parameters for an additive model — init_bam_orthog","text":"","code":"# Simulate data for illustration: sim_dat = simulate_nb_friedman(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Linear and nonlinear components: X_lin = as.matrix(X[,-(1:3)]) X_nonlin = as.matrix(X[,(1:3)])  # Initialize: params = init_params_additive(y = y,                               X_lin = X_lin,                               X_nonlin = X_nonlin) #> Error in init_params_additive(y = y, X_lin = X_lin, X_nonlin = X_nonlin): could not find function \"init_params_additive\" names(params) #> Error in eval(expr, envir, enclos): object 'params' not found names(params$coefficients) #> Error in eval(expr, envir, enclos): object 'params' not found"},{"path":"https://bking124.github.io/rSTAR/reference/init_bam_thin.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize the parameters for an additive model — init_bam_thin","title":"Initialize the parameters for an additive model — init_bam_thin","text":"Initialize parameters additive model, may contain linear nonlinear predictors. nonlinear terms modeled using low-rank thin plate splines.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_bam_thin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize the parameters for an additive model — init_bam_thin","text":"","code":"init_bam_thin(y, X_lin, X_nonlin, B_all = NULL)"},{"path":"https://bking124.github.io/rSTAR/reference/init_bam_thin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize the parameters for an additive model — init_bam_thin","text":"y n x 1 vector data X_lin n x pL matrix predictors modelled linear X_nonlin n x pNL matrix predictors modelled nonlinear B_all optional pNL-dimensional list n x L[j] dimensional basis matrices nonlinear term j=1,...,pNL; NULL, compute internally","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_bam_thin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize the parameters for an additive model — init_bam_thin","text":"named list params containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_bam_thin.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize the parameters for an additive model — init_bam_thin","text":"parameters coefficients : beta: p x 1 linear coefficients, including linear terms X_nonlin f_j: n x pNL matrix fitted values nonlinear function theta_j: pNL-dimensional nonlinear basis coefficients sigma_beta: p x 1 vector linear regression coefficient standard deviations sigma_theta_j: pNL x 1 vector nonlinear coefficient standard deviations","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_bam_thin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize the parameters for an additive model — init_bam_thin","text":"","code":"# Simulate data for illustration: sim_dat = simulate_nb_friedman(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Linear and nonlinear components: X_lin = as.matrix(X[,-(1:3)]) X_nonlin = as.matrix(X[,(1:3)])  # Initialize: params = init_params_additive0(y = y,                               X_lin = X_lin,                               X_nonlin = X_nonlin) #> Error in init_params_additive0(y = y, X_lin = X_lin, X_nonlin = X_nonlin): could not find function \"init_params_additive0\" names(params) #> Error in eval(expr, envir, enclos): object 'params' not found names(params$coefficients) #> Error in eval(expr, envir, enclos): object 'params' not found"},{"path":"https://bking124.github.io/rSTAR/reference/init_lm_gprior.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","title":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","text":"Initialize parameters linear regression model assuming g-prior coefficients.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_lm_gprior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","text":"","code":"init_lm_gprior(y, X)"},{"path":"https://bking124.github.io/rSTAR/reference/init_lm_gprior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","text":"y n x 1 vector data X n x p matrix predictors","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_lm_gprior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","text":"named list params containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_lm_gprior.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","text":"parameters coefficients : beta: p x 1 vector regression coefficients components beta","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_lm_gprior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize linear regression parameters assuming a g-prior — init_lm_gprior","text":"","code":"# Simulate data for illustration: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Initialize: params = init_params_lm_gprior(y = y, X = X) #> Error in init_params_lm_gprior(y = y, X = X): could not find function \"init_params_lm_gprior\" names(params) #> Error in eval(expr, envir, enclos): object 'params' not found names(params$coefficients) #> Error in eval(expr, envir, enclos): object 'params' not found"},{"path":"https://bking124.github.io/rSTAR/reference/init_lm_hs.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","title":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","text":"Initialize parameters linear regression model assuming horseshoe prior (non-intercept) coefficients. number predictors p may exceed number observations n.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_lm_hs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","text":"","code":"init_lm_hs(y, X)"},{"path":"https://bking124.github.io/rSTAR/reference/init_lm_hs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","text":"y n x 1 vector data X n x p matrix predictors","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_lm_hs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","text":"named list params containing mu n x 1 vector conditional means (fitted values) sigma conditional standard deviation coefficients named list parameters determine mu","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_lm_hs.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","text":"parameters coefficients : beta: p x 1 vector regression coefficients sigma_beta: p x 1 vector regression coefficient standard deviations (local scale parameters) xi_sigma_beta: p x 1 vector parameter-expansion variables sigma_beta lambda_beta: global scale parameter xi_lambda_beta: parameter-expansion variable lambda_beta components beta","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_lm_hs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize linear regression parameters assuming a horseshoe prior — init_lm_hs","text":"","code":"# Simulate data for illustration: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Initialize: params = init_params_lm_hs(y = y, X = X) #> Error in init_params_lm_hs(y = y, X = X): could not find function \"init_params_lm_hs\" names(params) #> Error in eval(expr, envir, enclos): object 'params' not found names(params$coefficients) #> Error in eval(expr, envir, enclos): object 'params' not found"},{"path":"https://bking124.github.io/rSTAR/reference/init_lm_ridge.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","title":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","text":"Initialize parameters linear regression model assuming ridge prior (non-intercept) coefficients. number predictors p may exceed number observations n.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_lm_ridge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","text":"","code":"init_lm_ridge(y, X)"},{"path":"https://bking124.github.io/rSTAR/reference/init_lm_ridge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","text":"y n x 1 vector data X n x p matrix predictors","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_lm_ridge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","text":"named list params containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_lm_ridge.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","text":"parameters coefficients : beta: p x 1 vector regression coefficients sigma_beta: prior standard deviation (non-intercept) components beta","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_lm_ridge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize linear regression parameters assuming a ridge prior — init_lm_ridge","text":"","code":"# Simulate data for illustration: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Initialize: params = init_params_lm(y = y, X = X) #> Error in init_params_lm(y = y, X = X): could not find function \"init_params_lm\" names(params) #> Error in eval(expr, envir, enclos): object 'params' not found names(params$coefficients) #> Error in eval(expr, envir, enclos): object 'params' not found"},{"path":"https://bking124.github.io/rSTAR/reference/init_params_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize the parameters for a simple mean-only model — init_params_mean","title":"Initialize the parameters for a simple mean-only model — init_params_mean","text":"Initialize parameters model y ~ N(mu0, sigma^2) flat prior mu0.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_params_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize the parameters for a simple mean-only model — init_params_mean","text":"","code":"init_params_mean(y)"},{"path":"https://bking124.github.io/rSTAR/reference/init_params_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize the parameters for a simple mean-only model — init_params_mean","text":"y n x 1 vector data","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_params_mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize the parameters for a simple mean-only model — init_params_mean","text":"named list params containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_params_mean.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize the parameters for a simple mean-only model — init_params_mean","text":"parameter coefficients mu0. Although redundant , parametrization useful functions.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/init_params_mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize the parameters for a simple mean-only model — init_params_mean","text":"","code":"# Example: params = init_params_mean(y = 1:10) #> Error in init_params_mean(y = 1:10): could not find function \"init_params_mean\""},{"path":"https://bking124.github.io/rSTAR/reference/interval_gRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate confidence intervals/bands for a STAR process — interval_gRcpp","title":"Estimate confidence intervals/bands for a STAR process — interval_gRcpp","text":"Compute confidence intervals/bands expected value count-valued STAR process y based intervals/bands Gaussian process mu.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/interval_gRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate confidence intervals/bands for a STAR process — interval_gRcpp","text":"","code":"interval_gRcpp(g_a_j, g_a_jp1, L_mu, U_mu, sigma, Jmax)"},{"path":"https://bking124.github.io/rSTAR/reference/interval_gRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate confidence intervals/bands for a STAR process — interval_gRcpp","text":"g_a_j Jmax x 1 vector g((j)) g_a_jp1 Jmax x 1 vector g((j + 1)) L_mu m x 1 vector lower intervals mu U_mu m x 1 vector upper intervals mu sigma m x 1 vector conditional standard deviations Jmax m x 1 vector maximum integer values consider","code":""},{"path":"https://bking124.github.io/rSTAR/reference/interval_gRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate confidence intervals/bands for a STAR process — interval_gRcpp","text":"LU_y m x 2 vector intervals y.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/interval_gRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimate confidence intervals/bands for a STAR process — interval_gRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/invlogit.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the inverse log-odds — invlogit","title":"Compute the inverse log-odds — invlogit","text":"Compute inverse log-odds","code":""},{"path":"https://bking124.github.io/rSTAR/reference/invlogit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the inverse log-odds — invlogit","text":"","code":"invlogit(x)"},{"path":"https://bking124.github.io/rSTAR/reference/invlogit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the inverse log-odds — invlogit","text":"x scalar vector compute (componentwise) inverse log-odds","code":""},{"path":"https://bking124.github.io/rSTAR/reference/invlogit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the inverse log-odds — invlogit","text":"scalar vector values (0,1)","code":""},{"path":"https://bking124.github.io/rSTAR/reference/invlogit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the inverse log-odds — invlogit","text":"","code":"x = seq(-5, 5, length.out = 10^3) plot(x, invlogit(x)) #> Error in invlogit(x): could not find function \"invlogit\""},{"path":"https://bking124.github.io/rSTAR/reference/lm_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting frequentist STAR linear model via EM algorithm — lm_star","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"Compute MLEs log-likelihood STAR linear model. regression coefficients estimated using least squares within EM algorithm. transformation can known (e.g., log sqrt) unknown (Box-Cox estimated nonparametrically) greater flexibility. latter case, empirical CDF used determine transformation. Standard function calls including coefficients, fitted, residuals apply.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/lm_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"","code":"lm_star(   formula,   data = NULL,   transformation = \"np\",   y_max = Inf,   sd_init = 10,   tol = 10^-10,   max_iters = 1000 )"},{"path":"https://bking124.github.io/rSTAR/reference/lm_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"formula object class \"formula\" (see lm details model specification) data optional data frame, list environment (object coercible .data.frame data frame) containing variables model; like lm, found data, variables taken environment(formula) transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) y_max fixed known upper bound observations; default Inf sd_init add random noise EM algorithm initialization scaled sd_init times Gaussian MLE standard deviation; default 10 tol tolerance stopping EM algorithm; default 10^-10; max_iters maximum number EM iterations stopping; default 1000","code":""},{"path":"https://bking124.github.io/rSTAR/reference/lm_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"object class \"lmstar\", list following elements: coefficients MLEs coefficients fitted.values fitted values MLEs g.hat function containing (known estimated) transformation sigma.hat MLE standard deviation mu.hat MLE conditional mean (transformed scale) z.hat estimated latent data (transformed scale) MLEs residuals Dunn-Smyth residuals (randomized) residuals_rep Dunn-Smyth residuals (randomized) 10 replicates logLik log-likelihood MLEs logLik0 log-likelihood MLEs *unrounded* initialization lambda Box-Cox nonlinear parameter parameters (1) track parameters across EM iterations (2) record model specifications","code":""},{"path":"https://bking124.github.io/rSTAR/reference/lm_star.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"Infinite latent data values may occur transformed Gaussian model highly inadequate. case, function returns *indices* data points infinite latent values, significant outliers model. Deletion indices re-running model one option, care must taken ensure () appropriate treat observations outliers (ii) model adequate remaining data points.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/lm_star.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"Kowal, D. R., & Wu, B. (2021). Semiparametric count data regression self‐reported mental health. Biometrics. doi:10.1111/biom.13617","code":""},{"path":"https://bking124.github.io/rSTAR/reference/lm_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting frequentist STAR linear model via EM algorithm — lm_star","text":"","code":"# Simulate data with count-valued response y: sim_dat = simulate_nb_lm(n = 100, p = 3) y = sim_dat$y; X = sim_dat$X  # Fit model fit_em = lm_star(y~X)  # Fitted coefficients: coef(fit_em) #> (Intercept)          X1          X2  #>  0.06036832  0.52490914 -0.05264222  # Fitted values: y_hat = fitted(fit_em) plot(y_hat, y);   # Residuals: plot(residuals(fit_em))  qqnorm(residuals(fit_em)); qqline(residuals(fit_em))"},{"path":"https://bking124.github.io/rSTAR/reference/logLikePointRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the pointwise log-likelihood for STAR — logLikePointRcpp","title":"Compute the pointwise log-likelihood for STAR — logLikePointRcpp","text":"Compute pointwise log-likelihood STAR model. code assumes transformed real-valued process (z_star) conditionally independent components means mu standard deviations sigma.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/logLikePointRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the pointwise log-likelihood for STAR — logLikePointRcpp","text":"","code":"logLikePointRcpp(g_a_j, g_a_jp1, mu, sigma)"},{"path":"https://bking124.github.io/rSTAR/reference/logLikePointRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the pointwise log-likelihood for STAR — logLikePointRcpp","text":"g_a_j m x 1 vector g((j)) g_a_jp1 m x 1 vector g((j + 1)) mu m x 1 vector conditional expectations sigma m x 1 vector conditional standard deviations","code":""},{"path":"https://bking124.github.io/rSTAR/reference/logLikePointRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the pointwise log-likelihood for STAR — logLikePointRcpp","text":"loglike m x 1 log-likelihood value","code":""},{"path":"https://bking124.github.io/rSTAR/reference/logLikePointRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute the pointwise log-likelihood for STAR — logLikePointRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/logLikeRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the log-likelihood for STAR — logLikeRcpp","title":"Compute the log-likelihood for STAR — logLikeRcpp","text":"Compute log-likelihood STAR model. code assumes transformed real-valued process (z_star) conditionally independent components means mu standard deviations sigma.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/logLikeRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the log-likelihood for STAR — logLikeRcpp","text":"","code":"logLikeRcpp(g_a_j, g_a_jp1, mu, sigma)"},{"path":"https://bking124.github.io/rSTAR/reference/logLikeRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the log-likelihood for STAR — logLikeRcpp","text":"g_a_j m x 1 vector g((j)) g_a_jp1 m x 1 vector g((j + 1)) mu m x 1 vector conditional expectations sigma m x 1 vector conditional standard deviations","code":""},{"path":"https://bking124.github.io/rSTAR/reference/logLikeRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the log-likelihood for STAR — logLikeRcpp","text":"loglike scalar log-likelihood value","code":""},{"path":"https://bking124.github.io/rSTAR/reference/logLikeRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute the log-likelihood for STAR — logLikeRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/logit.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the log-odds — logit","title":"Compute the log-odds — logit","text":"Compute log-odds","code":""},{"path":"https://bking124.github.io/rSTAR/reference/logit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the log-odds — logit","text":"","code":"logit(x)"},{"path":"https://bking124.github.io/rSTAR/reference/logit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the log-odds — logit","text":"x scalar vector (0,1) compute (componentwise) log-odds","code":""},{"path":"https://bking124.github.io/rSTAR/reference/logit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the log-odds — logit","text":"scalar vector log-odds","code":""},{"path":"https://bking124.github.io/rSTAR/reference/logit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the log-odds — logit","text":"","code":"x = seq(0, 1, length.out = 10^3) plot(x, logit(x)) #> Error in logit(x): could not find function \"logit\""},{"path":"https://bking124.github.io/rSTAR/reference/plot_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the estimated regression coefficients and credible intervals — plot_coef","title":"Plot the estimated regression coefficients and credible intervals — plot_coef","text":"Plot estimated regression coefficients credible intervals linear effects two models.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/plot_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the estimated regression coefficients and credible intervals — plot_coef","text":"","code":"plot_coef(   post_coefficients_1,   post_coefficients_2 = NULL,   alpha = 0.05,   labels = NULL )"},{"path":"https://bking124.github.io/rSTAR/reference/plot_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the estimated regression coefficients and credible intervals — plot_coef","text":"post_coefficients_1 Nsims x p matrix simulations posterior distribution p coefficients, Nsims number simulations post_coefficients_2 Nsims x p matrix simulations posterior distribution p coefficients another model alpha confidence level credible intervals labels p dimensional string labels coefficient names","code":""},{"path":"https://bking124.github.io/rSTAR/reference/plot_fitted.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the fitted values and the data — plot_fitted","title":"Plot the fitted values and the data — plot_fitted","text":"Plot fitted values, plus pointwise credible intervals, data. simulations, one may use true values place data.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/plot_fitted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the fitted values and the data — plot_fitted","text":"","code":"plot_fitted(y, post_y, y_hat = NULL, alpha = 0.05, ...)"},{"path":"https://bking124.github.io/rSTAR/reference/plot_fitted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the fitted values and the data — plot_fitted","text":"y n x 1 vector data post_y Nsims x n matrix simulated fitted values, Nsims number simulations y_hat n x 1 vector fitted values; NULL, use pointwise sample mean colMeans(post_y) alpha confidence level credible intervals ... arguments plotting","code":""},{"path":"https://bking124.github.io/rSTAR/reference/plot_pmf.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the empirical and model-based probability mass functions — plot_pmf","title":"Plot the empirical and model-based probability mass functions — plot_pmf","text":"Plot empirical probability mass function, .e., proportion data values y equal j j=0,1,..., together model-based estimate probability mass function based posterior predictive distribution.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/plot_pmf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the empirical and model-based probability mass functions — plot_pmf","text":"","code":"plot_pmf(y, post.pred, error.bars = FALSE, alpha = 0.05)"},{"path":"https://bking124.github.io/rSTAR/reference/plot_pmf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the empirical and model-based probability mass functions — plot_pmf","text":"y n x 1 vector data post.pred nsave draws posterior predictive distribution y error.bars logical; TRUE, include errors bars model-based PMF alpha confidence level credible intervals","code":""},{"path":"https://bking124.github.io/rSTAR/reference/pmaxRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"pmax() in Rcpp — pmaxRcpp","title":"pmax() in Rcpp — pmaxRcpp","text":"Compute pointwise max two vectors equal length","code":""},{"path":"https://bking124.github.io/rSTAR/reference/pmaxRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pmax() in Rcpp — pmaxRcpp","text":"","code":"pmaxRcpp(v1, v2)"},{"path":"https://bking124.github.io/rSTAR/reference/pmaxRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pmax() in Rcpp — pmaxRcpp","text":"v1 m x 1 vector v2 m x 1 vector","code":""},{"path":"https://bking124.github.io/rSTAR/reference/pmaxRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"pmax() in Rcpp — pmaxRcpp","text":"vm m x 1 vector pointwise maxima","code":""},{"path":"https://bking124.github.io/rSTAR/reference/pmaxRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"pmax() in Rcpp — pmaxRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/pminRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"pmin() in Rcpp — pminRcpp","title":"pmin() in Rcpp — pminRcpp","text":"Compute pointwise min two vectors equal length","code":""},{"path":"https://bking124.github.io/rSTAR/reference/pminRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pmin() in Rcpp — pminRcpp","text":"","code":"pminRcpp(v1, v2)"},{"path":"https://bking124.github.io/rSTAR/reference/pminRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pmin() in Rcpp — pminRcpp","text":"v1 m x 1 vector v2 m x 1 vector","code":""},{"path":"https://bking124.github.io/rSTAR/reference/pminRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"pmin() in Rcpp — pminRcpp","text":"vm m x 1 vector pointwise minima","code":""},{"path":"https://bking124.github.io/rSTAR/reference/pminRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"pmin() in Rcpp — pminRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/predict.lmstar.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute a predictive distribution for the integer-valued response in STAR linear model — predict.lmstar","title":"Compute a predictive distribution for the integer-valued response in STAR linear model — predict.lmstar","text":"Monte Carlo approach estimating (plug-) predictive distribution STAR linear model. algorithm iteratively samples () latent data given observed data, (ii) latent predictive data given latent data (), (iii) (inverse) transforms rounds latent predictive data obtain draw integer-valued predictive distribution.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/predict.lmstar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute a predictive distribution for the integer-valued response in STAR linear model — predict.lmstar","text":"","code":"# S3 method for lmstar predict(object, newdata = NULL, N = 1000)"},{"path":"https://bking124.github.io/rSTAR/reference/predict.lmstar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute a predictive distribution for the integer-valued response in STAR linear model — predict.lmstar","text":"object Object class \"lmstar\" output lm_star newdata optional m x p matrix --sample predictors. omitted, fitted values used. N number Monte Carlo samples posterior predictive distribution; default 1000","code":""},{"path":"https://bking124.github.io/rSTAR/reference/predict.lmstar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute a predictive distribution for the integer-valued response in STAR linear model — predict.lmstar","text":"N x m samples posterior predictive distribution m test points","code":""},{"path":"https://bking124.github.io/rSTAR/reference/predict.lmstar.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute a predictive distribution for the integer-valued response in STAR linear model — predict.lmstar","text":"``plug-\" predictive distribution crude approximation. Better approaches available using Bayesian models, provide samples posterior predictive distribution.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/predict.lmstar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute a predictive distribution for the integer-valued response in STAR linear model — predict.lmstar","text":"","code":"# Simulate data with count-valued response y: x = seq(0, 1, length.out = 100) y = rpois(n = length(x), lambda = exp(1.5 + 5*(x -.5)^2))  # Estimate model--assume a quadratic effect (better for illustration purposes) fit = lm_star(y~x+I(x^2), transformation = 'sqrt')  #Compute the predictive draws for the test points (same as observed points here) y_pred = predict(fit)  # Using these draws, compute prediction intervals for STAR: PI_y = t(apply(y_pred, 2, quantile, c(0.05, 1 - 0.05)))  # Plot the results: PIs and CIs plot(x, y, ylim = range(y, PI_y), main = 'STAR: 90% Prediction Intervals') lines(x, PI_y[,1], col='darkgray', type='s', lwd=4); lines(x, PI_y[,2], col='darkgray', type='s', lwd=4)"},{"path":"https://bking124.github.io/rSTAR/reference/pvals.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute coefficient p-values for STAR linear regression using likelihood ratio test — pvals","title":"Compute coefficient p-values for STAR linear regression using likelihood ratio test — pvals","text":"linear regression model within STAR framework, compute p-values regression coefficients using likelihood ratio test. also computes p-value excluding predictors, akin (partial) F test.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/pvals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute coefficient p-values for STAR linear regression using likelihood ratio test — pvals","text":"","code":"pvals(object)"},{"path":"https://bking124.github.io/rSTAR/reference/pvals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute coefficient p-values for STAR linear regression using likelihood ratio test — pvals","text":"object Object class \"lmstar\" output lm_star","code":""},{"path":"https://bking124.github.io/rSTAR/reference/pvals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute coefficient p-values for STAR linear regression using likelihood ratio test — pvals","text":"list p+1 p-values, one predictor well joint p-value excluding predictors","code":""},{"path":"https://bking124.github.io/rSTAR/reference/pvals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute coefficient p-values for STAR linear regression using likelihood ratio test — pvals","text":"","code":"# Simulate data with count-valued response y: sim_dat = simulate_nb_lm(n = 100, p = 2) y = sim_dat$y; X = sim_dat$X  # Select a transformation: transformation = 'np'  #Estimate model fit = lm_star(y~X, transformation = transformation)  #Compute p-values pvals(fit) #>        (Intercept)                  X Any linear effects  #>       3.313437e-01       6.861815e-05       6.861806e-05"},{"path":"https://bking124.github.io/rSTAR/reference/randomForest_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Random Forest STAR with EM algorithm — randomForest_star","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"Compute MLEs log-likelihood Random Forest STAR model. STAR model requires *transformation* *estimation function* conditional mean given observed data. transformation can known (e.g., log sqrt) unknown (Box-Cox estimated nonparametrically) greater flexibility. estimator case random forest. Standard function calls including fitted residuals apply.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/randomForest_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"","code":"randomForest_star(   y,   X,   X.test = NULL,   transformation = \"np\",   y_max = Inf,   sd_init = 10,   tol = 10^-10,   max_iters = 1000,   ntree = 500,   mtry = max(floor(ncol(X)/3), 1),   nodesize = 5 )"},{"path":"https://bking124.github.io/rSTAR/reference/randomForest_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"y n x 1 vector observed counts X n x p matrix predictors X.test m x p matrix --sample predictors transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) \"box-cox\" (box-cox transformation learned parameter) y_max fixed known upper bound observations; default Inf sd_init add random noise EM algorithm initialization scaled sd_init times Gaussian MLE standard deviation; default 10 tol tolerance stopping EM algorithm; default 10^-10; max_iters maximum number EM iterations stopping; default 1000 ntree Number trees grow. set small number, ensure every input row gets predicted least times. Default 500. mtry Number variables randomly sampled candidates split. Default p/3. nodesize Minimum size terminal nodes. Setting number larger causes smaller trees grown (thus take less time). Default 5.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/randomForest_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"list following elements: fitted.values: fitted values MLEs based --bag samples (training) fitted.values.test: fitted values MLEs (testing) g.hat function containing (known estimated) transformation sigma.hat MLE standard deviation mu.hat MLE conditional mean (transformed scale) z.hat estimated latent data (transformed scale) MLEs residuals Dunn-Smyth residuals (randomized) residuals_rep Dunn-Smyth residuals (randomized) 10 replicates logLik log-likelihood MLEs logLik0 log-likelihood MLEs *unrounded* initialization lambda Box-Cox nonlinear parameter rfObj: object returned randomForest() MLEs parameters (1) track parameters across EM iterations (2) record model specifications","code":""},{"path":"https://bking124.github.io/rSTAR/reference/randomForest_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. expectation-maximization (EM) algorithm used produce maximum likelihood estimators (MLEs) parameters defined fitted values computed using --bag samples. result, log-likelihood based --bag prediction, similarly straightforward compute --bag squared absolute errors.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/randomForest_star.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"Since random forest produces random predictions, EM algorithm never converge exactly. Infinite latent data values may occur transformed Gaussian model highly inadequate. case, function returns *indices* data points infinite latent values, significant outliers model. Deletion indices re-running model one option, care must taken ensure () appropriate treat observations outliers (ii) model adequate remaining data points.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/randomForest_star.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"Kowal, D. R., & Wu, B. (2021). Semiparametric count data regression self‐reported mental health. Biometrics. doi:10.1111/biom.13617","code":""},{"path":"https://bking124.github.io/rSTAR/reference/randomForest_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Random Forest STAR with EM algorithm — randomForest_star","text":"","code":"if (FALSE) { # Simulate data with count-valued response y: sim_dat = simulate_nb_friedman(n = 100, p = 10) y = sim_dat$y; X = sim_dat$X  # EM algorithm for STAR (using the log-link) fit_em = randomForest_star(y = y, X = X,                  transformation = 'log',                  max_iters = 100)  # Fitted values (out-of-bag) y_hat = fitted(fit_em) plot(y_hat, y);  # Residuals: plot(residuals(fit_em)) qqnorm(residuals(fit_em)); qqline(residuals(fit_em))  # Log-likelihood at MLEs (out-of-bag): fit_em$logLik }"},{"path":"https://bking124.github.io/rSTAR/reference/round_floor.html","id":null,"dir":"Reference","previous_headings":"","what":"Rounding function — round_floor","title":"Rounding function — round_floor","text":"Define rounding operator associated floor function. function also returns zero whenever input negative caps value y_max, y_max known upper bound data y (specified).","code":""},{"path":"https://bking124.github.io/rSTAR/reference/round_floor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rounding function — round_floor","text":"","code":"round_floor(z, y_max = Inf)"},{"path":"https://bking124.github.io/rSTAR/reference/round_floor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rounding function — round_floor","text":"z real-valued input(s) y_max fixed known upper bound observations; default Inf","code":""},{"path":"https://bking124.github.io/rSTAR/reference/round_floor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rounding function — round_floor","text":"count-valued output(s) rounding function.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/round_floor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rounding function — round_floor","text":"","code":"# Floor function: round_floor(1.5) #> [1] 1 round_floor(0.5) #> [1] 0  # Special treatmeant of negative numbers: round_floor(-1) #> [1] 0"},{"path":"https://bking124.github.io/rSTAR/reference/rtruncnormRcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a truncated normal distribution — rtruncnormRcpp","title":"Sample from a truncated normal distribution — rtruncnormRcpp","text":"Sample truncated normal distribution. Samples drawn componentwise, component vector allowed mean, standard deviation, upper lower limits. components assumed independent.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/rtruncnormRcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a truncated normal distribution — rtruncnormRcpp","text":"","code":"rtruncnormRcpp(y_lower, y_upper, mu, sigma, u_rand)"},{"path":"https://bking124.github.io/rSTAR/reference/rtruncnormRcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a truncated normal distribution — rtruncnormRcpp","text":"y_lower m x 1 vector lower endpoints y_upper m x 1 vector upper endpoints mu m x 1 vector conditional expectations sigma m x 1 vector conditional standard deviations u_rand m x 1 vector uniform random variables","code":""},{"path":"https://bking124.github.io/rSTAR/reference/rtruncnormRcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a truncated normal distribution — rtruncnormRcpp","text":"z_star m x 1 draw truncated normal distribution","code":""},{"path":"https://bking124.github.io/rSTAR/reference/rtruncnormRcpp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample from a truncated normal distribution — rtruncnormRcpp","text":"function uses Rcpp computational efficiency.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sampleFastGaussian.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al. — sampleFastGaussian","title":"Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al. — sampleFastGaussian","text":"Sample N(mu, Sigma) Sigma = solve(crossprod(Phi) + solve(D)) mu = Sigma*crossprod(Phi, alpha):","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sampleFastGaussian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al. — sampleFastGaussian","text":"","code":"sampleFastGaussian(Phi, Ddiag, alpha)"},{"path":"https://bking124.github.io/rSTAR/reference/sampleFastGaussian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al. — sampleFastGaussian","text":"Phi n x p matrix (predictors) Ddiag p x 1 vector diagonal components (prior variance) alpha n x 1 vector (data, scaled variance)","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sampleFastGaussian.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al. — sampleFastGaussian","text":"Draw N(mu, Sigma), p x 1, computed O(n^2*p)","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sampleFastGaussian.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample a Gaussian vector using the fast sampler of BHATTACHARYA et al. — sampleFastGaussian","text":"Assumes D diagonal, extensions available","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_bam_orthog.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample the parameters for an additive model — sample_bam_orthog","title":"Sample the parameters for an additive model — sample_bam_orthog","text":"Sample parameters additive model, may contain linear nonlinear predictors. nonlinear terms modeled using orthogonalized splines. sampler draws linear terms jointly samples vector nonlinear coefficients using Bayesian backfitting (.e., conditional nonlinear linear terms).","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_bam_orthog.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample the parameters for an additive model — sample_bam_orthog","text":"","code":"sample_bam_orthog(   y,   X_lin,   X_nonlin,   params,   A = 10^4,   B_all = NULL,   diagBtB_all = NULL,   XtX = NULL )"},{"path":"https://bking124.github.io/rSTAR/reference/sample_bam_orthog.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample the parameters for an additive model — sample_bam_orthog","text":"y n x 1 vector data X_lin n x pL matrix predictors modelled linear X_nonlin n x pNL matrix predictors modelled nonlinear params named list parameters containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu prior scale sigma_beta, assume follows Uniform(0, ) prior. B_all optional pNL-dimensional list n x L[j] dimensional basis matrices nonlinear term j=1,...,pNL; NULL, compute internally diagBtB_all optional pNL-dimensional list diag(crossprod(B_all[[j]])); NULL, compute internally XtX optional p x p matrix crossprod(X) (one-time cost); NULL, compute internally","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_bam_orthog.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample the parameters for an additive model — sample_bam_orthog","text":"updated named list params draws full conditional distributions sigma coefficients (updated mu).","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_bam_orthog.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample the parameters for an additive model — sample_bam_orthog","text":"parameters coefficients : beta: p x 1 linear coefficients, including linear terms X_nonlin f_j: n x pNL matrix fitted values nonlinear function theta_j: pNL-dimensional nonlinear basis coefficients sigma_beta: p x 1 vector linear regression coefficient standard deviations sigma_theta_j: pNL x 1 vector nonlinear coefficient standard deviations","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_bam_orthog.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample the parameters for an additive model — sample_bam_orthog","text":"","code":"# Simulate data for illustration: sim_dat = simulate_nb_friedman(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Linear and nonlinear components: X_lin = as.matrix(X[,-(1:3)]) X_nonlin = as.matrix(X[,(1:3)])  # Initialize: params = init_params_additive(y = y, X_lin = X_lin, X_nonlin = X_nonlin) #> Error in init_params_additive(y = y, X_lin = X_lin, X_nonlin = X_nonlin): could not find function \"init_params_additive\"  # Sample: params = sample_params_additive(y = y,                                 X_lin = X_lin,                                 X_nonlin = X_nonlin,                                 params = params) #> Error in sample_params_additive(y = y, X_lin = X_lin, X_nonlin = X_nonlin,     params = params): could not find function \"sample_params_additive\" names(params) #> Error in eval(expr, envir, enclos): object 'params' not found names(params$coefficients) #> Error in eval(expr, envir, enclos): object 'params' not found  # And plot an example: plot(X_nonlin[,1], params$coefficients$f_j[,1]) #> Error in xy.coords(x, y, xlabel, ylabel, log): object 'params' not found"},{"path":"https://bking124.github.io/rSTAR/reference/sample_bam_thin.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample the parameters for an additive model — sample_bam_thin","title":"Sample the parameters for an additive model — sample_bam_thin","text":"Sample parameters additive model, may contain linear nonlinear predictors. nonlinear terms modeled using low-rank thin plate splines. sampler draws linear terms jointly samples vector nonlinear coefficients using Bayesian backfitting (.e., conditional nonlinear linear terms).","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_bam_thin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample the parameters for an additive model — sample_bam_thin","text":"","code":"sample_bam_thin(   y,   X_lin,   X_nonlin,   params,   A = 10^4,   B_all = NULL,   BtB_all = NULL,   XtX = NULL )"},{"path":"https://bking124.github.io/rSTAR/reference/sample_bam_thin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample the parameters for an additive model — sample_bam_thin","text":"y n x 1 vector data X_lin n x pL matrix predictors modelled linear X_nonlin n x pNL matrix predictors modelled nonlinear params named list parameters containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu prior scale sigma_beta, assume follows Uniform(0, ) prior. B_all optional pNL-dimensional list n x L[j] dimensional basis matrices nonlinear term j=1,...,pNL; NULL, compute internally BtB_all optional pNL-dimensional list crossprod(B_all[[j]]); NULL, compute internally XtX optional p x p matrix crossprod(X) (one-time cost); NULL, compute internally","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_bam_thin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample the parameters for an additive model — sample_bam_thin","text":"updated named list params draws full conditional distributions sigma coefficients (updated mu).","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_bam_thin.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample the parameters for an additive model — sample_bam_thin","text":"parameters coefficients : beta: p x 1 linear coefficients, including linear terms X_nonlin f_j: n x pNL matrix fitted values nonlinear function theta_j: pNL-dimensional nonlinear basis coefficients sigma_beta: p x 1 vector linear regression coefficient standard deviations sigma_theta_j: pNL x 1 vector nonlinear coefficient standard deviations","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_bam_thin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample the parameters for an additive model — sample_bam_thin","text":"","code":"# Simulate data for illustration: sim_dat = simulate_nb_friedman(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Linear and nonlinear components: X_lin = as.matrix(X[,-(1:3)]) X_nonlin = as.matrix(X[,(1:3)])  # Initialize: params = init_params_additive0(y = y, X_lin = X_lin, X_nonlin = X_nonlin) #> Error in init_params_additive0(y = y, X_lin = X_lin, X_nonlin = X_nonlin): could not find function \"init_params_additive0\"  # Sample: params = sample_params_additive0(y = y,                                 X_lin = X_lin,                                 X_nonlin = X_nonlin,                                 params = params) #> Error in sample_params_additive0(y = y, X_lin = X_lin, X_nonlin = X_nonlin,     params = params): could not find function \"sample_params_additive0\" names(params) #> Error in eval(expr, envir, enclos): object 'params' not found names(params$coefficients) #> Error in eval(expr, envir, enclos): object 'params' not found  # And plot an example: plot(X_nonlin[,1], params$coefficients$f_j[,1]) #> Error in xy.coords(x, y, xlabel, ylabel, log): object 'params' not found"},{"path":"https://bking124.github.io/rSTAR/reference/sample_lm_gprior.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","title":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","text":"Sample parameters linear regression model assuming g-prior  coefficients.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_lm_gprior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","text":"","code":"sample_lm_gprior(y, X, params, psi = NULL, XtX = NULL)"},{"path":"https://bking124.github.io/rSTAR/reference/sample_lm_gprior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","text":"y n x 1 vector data X n x p matrix predictors params named list parameters containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu psi prior variance g-prior XtX p x p matrix crossprod(X) (one-time cost); NULL, compute within function","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_lm_gprior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","text":"updated named list params draws full conditional distributions sigma coefficients (updated mu).","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_lm_gprior.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","text":"parameters coefficients : beta: p x 1 vector regression coefficients components beta","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_lm_gprior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample the linear regression parameters assuming a g-prior — sample_lm_gprior","text":"","code":"# Simulate data for illustration: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Initialize: params = init_params_lm_gprior(y = y, X = X) #> Error in init_params_lm_gprior(y = y, X = X): could not find function \"init_params_lm_gprior\"  # Sample: params = sample_params_lm_gprior(y = y, X = X, params = params) #> Error in sample_params_lm_gprior(y = y, X = X, params = params): could not find function \"sample_params_lm_gprior\" names(params) #> Error in eval(expr, envir, enclos): object 'params' not found names(params$coefficients) #> Error in eval(expr, envir, enclos): object 'params' not found"},{"path":"https://bking124.github.io/rSTAR/reference/sample_lm_hs.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","title":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","text":"Sample parameters linear regression model assuming horseshoe prior (non-intercept) coefficients. number predictors p may exceed number observations n.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_lm_hs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","text":"","code":"sample_lm_hs(y, X, params, XtX = NULL)"},{"path":"https://bking124.github.io/rSTAR/reference/sample_lm_hs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","text":"y n x 1 vector data X n x p matrix predictors params named list parameters containing mu n x 1 vector conditional means (fitted values) sigma conditional standard deviation coefficients named list parameters determine mu XtX p x p matrix crossprod(X) (one-time cost); NULL, compute within function","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_lm_hs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","text":"updated named list params draws full conditional distributions sigma coefficients (updated mu).","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_lm_hs.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","text":"parameters coefficients : beta p x 1 vector regression coefficients sigma_beta p x 1 vector regression coefficient standard deviations (local scale parameters) xi_sigma_beta p x 1 vector parameter-expansion variables sigma_beta lambda_beta global scale parameter xi_lambda_beta parameter-expansion variable lambda_beta components beta","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_lm_hs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample linear regression parameters assuming horseshoe prior — sample_lm_hs","text":"","code":"# Simulate data for illustration: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Initialize: params = init_params_lm_hs(y = y, X = X) #> Error in init_params_lm_hs(y = y, X = X): could not find function \"init_params_lm_hs\"  # Sample: params = sample_params_lm_hs(y = y, X = X, params = params) #> Error in sample_params_lm_hs(y = y, X = X, params = params): could not find function \"sample_params_lm_hs\" names(params) #> Error in eval(expr, envir, enclos): object 'params' not found names(params$coefficients) #> Error in eval(expr, envir, enclos): object 'params' not found"},{"path":"https://bking124.github.io/rSTAR/reference/sample_lm_ridge.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample linear regressionparameters assuming a ridge prior — sample_lm_ridge","title":"Sample linear regressionparameters assuming a ridge prior — sample_lm_ridge","text":"Sample parameters linear regression model assuming ridge prior (non-intercept) coefficients. number predictors p may exceed number observations n.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_lm_ridge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample linear regressionparameters assuming a ridge prior — sample_lm_ridge","text":"","code":"sample_lm_ridge(y, X, params, A = 10^4, XtX = NULL)"},{"path":"https://bking124.github.io/rSTAR/reference/sample_lm_ridge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample linear regressionparameters assuming a ridge prior — sample_lm_ridge","text":"y n x 1 vector data X n x p matrix predictors params named list parameters containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu prior scale sigma_beta, assume follows Uniform(0, ) prior. XtX p x p matrix crossprod(X) (one-time cost); NULL, compute within function","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_lm_ridge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample linear regressionparameters assuming a ridge prior — sample_lm_ridge","text":"updated named list params draws full conditional distributions sigma coefficients (updated mu).","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_lm_ridge.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample linear regressionparameters assuming a ridge prior — sample_lm_ridge","text":"parameters coefficients : beta: p x 1 vector regression coefficients sigma_beta: prior standard deviation (non-intercept) components beta","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_lm_ridge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample linear regressionparameters assuming a ridge prior — sample_lm_ridge","text":"","code":"# Simulate data for illustration: sim_dat = simulate_nb_lm(n = 100, p = 5) y = sim_dat$y; X = sim_dat$X  # Initialize: params = init_params_lm(y = y, X = X) #> Error in init_params_lm(y = y, X = X): could not find function \"init_params_lm\"  # Sample: params = sample_params_lm(y = y, X = X, params = params) #> Error in sample_params_lm(y = y, X = X, params = params): could not find function \"sample_params_lm\" names(params) #> Error in eval(expr, envir, enclos): object 'params' not found names(params$coefficients) #> Error in eval(expr, envir, enclos): object 'params' not found"},{"path":"https://bking124.github.io/rSTAR/reference/sample_params_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample the parameters for a simple mean-only model — sample_params_mean","title":"Sample the parameters for a simple mean-only model — sample_params_mean","text":"Sample parameters model y ~ N(mu0, sigma^2) flat prior mu0 sigma ~ Unif(0, ).","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_params_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample the parameters for a simple mean-only model — sample_params_mean","text":"","code":"sample_params_mean(y, params)"},{"path":"https://bking124.github.io/rSTAR/reference/sample_params_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample the parameters for a simple mean-only model — sample_params_mean","text":"y n x 1 vector data params named list parameters containing mu: vector conditional means (fitted values) sigma: conditional standard deviation coefficients: named list parameters determine mu","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_params_mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample the parameters for a simple mean-only model — sample_params_mean","text":"updated named list params draws full conditional distributions sigma coefficients (updated mu).","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_params_mean.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample the parameters for a simple mean-only model — sample_params_mean","text":"parameter coefficients mu0. Although redundant , parametrization useful functions.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/sample_params_mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample the parameters for a simple mean-only model — sample_params_mean","text":"","code":"# Example: y = 1:10 params0 = init_params_mean(y) #> Error in init_params_mean(y): could not find function \"init_params_mean\" params = sample_params_mean(y = y, params = params0) #> Error in sample_params_mean(y = y, params = params0): could not find function \"sample_params_mean\" names(params) #> Error in eval(expr, envir, enclos): object 'params' not found"},{"path":"https://bking124.github.io/rSTAR/reference/simBaS.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Simultaneous Band Scores (SimBaS) — simBaS","title":"Compute Simultaneous Band Scores (SimBaS) — simBaS","text":"Compute simultaneous band scores (SimBaS) Meyer et al. (2015, Biometrics). SimBaS uses MC(MC) simulations function interest compute minimum alpha joint credible bands alpha level include zero. quantity computed grid point (observation point) domain function.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/simBaS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Simultaneous Band Scores (SimBaS) — simBaS","text":"","code":"simBaS(sampFuns)"},{"path":"https://bking124.github.io/rSTAR/reference/simBaS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Simultaneous Band Scores (SimBaS) — simBaS","text":"sampFuns Nsims x m matrix Nsims MCMC samples m points along curve","code":""},{"path":"https://bking124.github.io/rSTAR/reference/simBaS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Simultaneous Band Scores (SimBaS) — simBaS","text":"m x 1 vector simBaS","code":""},{"path":"https://bking124.github.io/rSTAR/reference/simBaS.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute Simultaneous Band Scores (SimBaS) — simBaS","text":"input needs curves: simBaS may computed vectors achieve multiplicity adjustment. minimum returned value, PsimBaS_t, domain t Global Bayesian P-Value (GBPV) testing whether function zero everywhere.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/simulate_nb_friedman.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"Simulate data negative-binomial distribution nonlinear mean function.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/simulate_nb_friedman.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"","code":"simulate_nb_friedman(   n = 100,   p = 10,   r_nb = 1,   b_int = log(1.5),   b_sig = log(5),   sigma_true = sqrt(2 * log(1)),   seed = NULL )"},{"path":"https://bking124.github.io/rSTAR/reference/simulate_nb_friedman.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"n number observations p number predictors r_nb dispersion parameter Negative Binomial dispersion; smaller values imply greater overdispersion, larger values approximate Poisson distribution. b_int intercept; default log(1.5). b_sig regression coefficients true signals; default log(5.0). sigma_true standard deviation Gaussian innovation; default zero. seed optional integer set seed reproducible simulation; default NULL results different dataset run","code":""},{"path":"https://bking124.github.io/rSTAR/reference/simulate_nb_friedman.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"named list simulated count response y, simulated design matrix X, true expected counts Ey.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/simulate_nb_friedman.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"log-expected counts modeled using Friedman (1991) nonlinear function interactions, possibly additional Gaussian noise (log-scale). assume half predictors associated response, .e., true signals. sufficiently large dispersion parameter r_nb, distribution approximate Poisson distribution. , predictor variables simulated independent uniform distributions.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/simulate_nb_friedman.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"Specifying sigma_true = sqrt(2*log(1 + )) implies expected counts inflated 100*% (relative exp(X*beta)), addition providing additional overdispersion.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/simulate_nb_friedman.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate count data from Friedman's nonlinear regression — simulate_nb_friedman","text":"","code":"# Simulate and plot the count data: sim_dat = simulate_nb_friedman(n = 100, p = 10); plot(sim_dat$y)"},{"path":"https://bking124.github.io/rSTAR/reference/simulate_nb_lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate count data from a linear regression — simulate_nb_lm","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"Simulate data negative-binomial distribution linear mean function.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/simulate_nb_lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"","code":"simulate_nb_lm(   n = 100,   p = 10,   r_nb = 1,   b_int = log(1.5),   b_sig = log(2),   sigma_true = sqrt(2 * log(1)),   ar1 = 0,   intercept = FALSE,   seed = NULL )"},{"path":"https://bking124.github.io/rSTAR/reference/simulate_nb_lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"n number observations p number predictors (including intercept) r_nb dispersion parameter Negative Binomial dispersion; smaller values imply greater overdispersion, larger values approximate Poisson distribution. b_int intercept; default log(1.5), implies expected count 1.5 predictors zero b_sig regression coefficients true signals; default log(2.0), implies twofold increase expected counts one unit increase x sigma_true standard deviation Gaussian innovation; default zero. ar1 autoregressive coefficient among columns X matrix; default zero. intercept Boolean indicating whether intercept column included returned design matrix; default FALSE seed optional integer set seed reproducible simulation; default NULL results different dataset run","code":""},{"path":"https://bking124.github.io/rSTAR/reference/simulate_nb_lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"named list simulated count response y, simulated design matrix X (possibly including intercept), true expected counts Ey, true regression coefficients beta_true.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/simulate_nb_lm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"log-expected counts modeled linear function covariates, possibly additional Gaussian noise (log-scale). assume half predictors associated response, .e., true signals. sufficiently large dispersion parameter r_nb, distribution approximate Poisson distribution. , predictor variables simulated independent standard normal distributions.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/simulate_nb_lm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"Specifying sigma_true = sqrt(2*log(1 + )) implies expected counts inflated 100*% (relative exp(X*beta)), addition providing additional overdispersion.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/simulate_nb_lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate count data from a linear regression — simulate_nb_lm","text":"","code":"# Simulate and plot the count data: sim_dat = simulate_nb_lm(n = 100, p = 10); plot(sim_dat$y)"},{"path":"https://bking124.github.io/rSTAR/reference/splineBasis.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize and reparametrize a spline basis matrix — splineBasis","title":"Initialize and reparametrize a spline basis matrix — splineBasis","text":"Following Wand Ormerod (2008), compute low-rank thin plate spline basis diagonalized prior variance nonlinear component scalar times diagonal matrix. Knot locations determined quantiles penalty integrated squared second derivative.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/splineBasis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize and reparametrize a spline basis matrix — splineBasis","text":"","code":"splineBasis(tau, sumToZero = TRUE, rescale01 = TRUE)"},{"path":"https://bking124.github.io/rSTAR/reference/splineBasis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize and reparametrize a spline basis matrix — splineBasis","text":"tau m x 1 vector observed points sumToZero logical; TRUE, enforce sum--zero constraint (useful additive models) rescale01 logical; TRUE, rescale tau interval [0,1] prior computing basis penalty matrices","code":""},{"path":"https://bking124.github.io/rSTAR/reference/splineBasis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize and reparametrize a spline basis matrix — splineBasis","text":"B_nl: nonlinear component spline basis matrix","code":""},{"path":"https://bking124.github.io/rSTAR/reference/splineBasis.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Initialize and reparametrize a spline basis matrix — splineBasis","text":"form full spline basis matrix, compute cbind(1, tau, B_nl). sum--zero constraint implicitly assumes linear term centered scaled, .e., scale(tau).","code":""},{"path":"https://bking124.github.io/rSTAR/reference/spline_star.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation for Bayesian STAR spline regression — spline_star","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"Compute samples predictive distributions STAR spline regression model.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/spline_star.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"","code":"spline_star(   y,   tau = NULL,   transformation = \"np\",   y_max = Inf,   psi = NULL,   approx_Fz = FALSE,   approx_Fy = FALSE,   nsave = 1000,   use_MCMC = TRUE,   nburn = 1000,   nskip = 0,   verbose = TRUE,   method_sigma = \"mle\" )"},{"path":"https://bking124.github.io/rSTAR/reference/spline_star.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"y n x 1 vector observed counts tau n x 1 vector observation points; NULL, assume equally-spaced [0,1] transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"bnp\" (Bayesian nonparametric transformation using Bayesian bootstrap) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) y_max fixed known upper bound observations; default Inf psi prior variance (1/smoothing parameter); NULL, update MCMC approx_Fz logical; BNP transformation, apply (fast stable) normal approximation marginal CDF latent data approx_Fy logical; BNP transformation, approximate marginal CDF y using empirical CDF nsave number MCMC iterations save (number Monte Carlo simulations) use_MCMC logical; whether run Gibbs sampler Monte Carlo (default TRUE) nburn number MCMC iterations discard nskip number MCMC iterations skip saving iterations, .e., save every (nskip + 1)th draw verbose logical; TRUE, print time remaining method_sigma method estimate latent data standard deviation (applicable use_MCMC=FALSE); must one \"mle\" use MLE STAR EM algorithm (default) \"mmle\" use marginal MLE (Note: slower!)","code":""},{"path":"https://bking124.github.io/rSTAR/reference/spline_star.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"list following elements: post_ytilde: nsave x n samples posterior predictive distribution observation points tau marg_like: marginal likelihood (use_MCMC=FALSE; otherwise NULL)","code":""},{"path":"https://bking124.github.io/rSTAR/reference/spline_star.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. , continuous latent data model spline regression. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt'. Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y. distribution-based transformations approximately preserve mean variance count data y latent data scale, lends interpretability model parameters. Lastly, transformation can modeled using Bayesian bootstrap ('bnp'), Bayesian nonparametric model incorporates uncertainty transformation posterior predictive inference.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/spline_star.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"'bnp' transformation (without Fy approximation), numerical stability issues psi modeled unknown. case, better fix psi positive number.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/spline_star.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation for Bayesian STAR spline regression — spline_star","text":"","code":"# Simulate some data: n = 100 tau = seq(0,1, length.out = n) y = round_floor(exp(1 + rnorm(n)/4 + poly(tau, 4)%*%rnorm(n=4, sd = 4:1)))  # Sample from the predictive distribution of a STAR spline model: post_ytilde = STAR_spline_gibbs(y = y, tau = tau) #> Error in STAR_spline_gibbs(y = y, tau = tau): could not find function \"STAR_spline_gibbs\"  # Compute 90% prediction intervals: pi_y = t(apply(post_ytilde, 2, quantile, c(0.05, .95))) #> Error in apply(post_ytilde, 2, quantile, c(0.05, 0.95)): object 'post_ytilde' not found  # Plot the results: intervals, median, and smoothed mean plot(tau, y, ylim = range(pi_y, y)) #> Error in plot.default(tau, y, ylim = range(pi_y, y)): object 'pi_y' not found polygon(c(tau, rev(tau)),c(pi_y[,2], rev(pi_y[,1])),col='gray', border=NA) #> Error in xy.coords(x, y, setLab = FALSE): object 'pi_y' not found lines(tau, apply(post_ytilde, 2, median), lwd=5, col ='black') #> Error in apply(post_ytilde, 2, median): object 'post_ytilde' not found lines(tau, smooth.spline(tau, apply(post_ytilde, 2, mean))$y, lwd=5, col='blue') #> Error in apply(post_ytilde, 2, mean): object 'post_ytilde' not found lines(tau, y, type='p') #> Error in plot.xy(xy.coords(x, y), type = type, ...): plot.new has not been called yet"},{"path":"https://bking124.github.io/rSTAR/reference/spline_star_exact.html","id":null,"dir":"Reference","previous_headings":"","what":"Monte Carlo predictive sampler for spline regression — spline_star_exact","title":"Monte Carlo predictive sampler for spline regression — spline_star_exact","text":"Compute direct Monte Carlo samples posterior predictive distribution STAR spline regression model.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/spline_star_exact.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Monte Carlo predictive sampler for spline regression — spline_star_exact","text":"","code":"spline_star_exact(   y,   tau = NULL,   transformation = \"np\",   y_max = Inf,   psi = 1000,   method_sigma = \"mle\",   approx_Fz = FALSE,   approx_Fy = FALSE,   nsave = 1000,   compute_marg = TRUE )"},{"path":"https://bking124.github.io/rSTAR/reference/spline_star_exact.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Monte Carlo predictive sampler for spline regression — spline_star_exact","text":"y n x 1 vector observed counts tau n x 1 vector observation points; NULL, assume equally-spaced [0,1] transformation transformation use latent data; must one \"identity\" (identity transformation) \"log\" (log transformation) \"sqrt\" (square root transformation) \"bnp\" (Bayesian nonparametric transformation using Bayesian bootstrap) \"np\" (nonparametric transformation estimated empirical CDF) \"pois\" (transformation moment-matched marginal Poisson CDF) \"neg-bin\" (transformation moment-matched marginal Negative Binomial CDF) y_max fixed known upper bound observations; default Inf psi prior variance (1/smoothing parameter) method_sigma method estimate latent data standard deviation; must one \"mle\" use MLE STAR EM algorithm \"mmle\" use marginal MLE (Note: slower!) approx_Fz logical; BNP transformation, apply (fast stable) normal approximation marginal CDF latent data approx_Fy logical; BNP transformation, approximate marginal CDF y using empirical CDF nsave number Monte Carlo simulations compute_marg logical; TRUE, compute return marginal likelihood","code":""},{"path":"https://bking124.github.io/rSTAR/reference/spline_star_exact.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Monte Carlo predictive sampler for spline regression — spline_star_exact","text":"list following elements: post_ytilde: nsave x n samples posterior predictive distribution observation points tau marg_like: marginal likelihood (requested; otherwise NULL)","code":""},{"path":"https://bking124.github.io/rSTAR/reference/spline_star_exact.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Monte Carlo predictive sampler for spline regression — spline_star_exact","text":"STAR defines count-valued probability model (1) specifying Gaussian model continuous *latent* data (2) connecting latent data observed data via *transformation rounding* operation. , continuous latent data model spline regression. several options transformation. First, transformation can belong *Box-Cox* family, includes known transformations 'identity', 'log', 'sqrt'. Second, transformation can estimated (model fitting) using empirical distribution data y. Options case include empirical cumulative distribution function (CDF), fully nonparametric ('np'), parametric alternatives based Poisson ('pois') Negative-Binomial ('neg-bin') distributions. parametric distributions, parameters distribution estimated using moments (means variances) y. distribution-based transformations approximately preserve mean variance count data y latent data scale, lends interpretability model parameters. Lastly, transformation can modeled using Bayesian bootstrap ('bnp'), Bayesian nonparametric model incorporates uncertainty transformation posterior predictive inference. Monte Carlo sampler produces direct, discrete, joint draws posterior predictive distribution spline regression model observed tau points.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/spline_star_exact.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Monte Carlo predictive sampler for spline regression — spline_star_exact","text":"","code":"# Simulate some data: n = 100 tau = seq(0,1, length.out = n) y = round_floor(exp(1 + rnorm(n)/4 + poly(tau, 4)%*%rnorm(n=4, sd = 4:1)))  # Sample from the predictive distribution of a STAR spline model: fit_star = STAR_spline(y = y, tau = tau) #> Error in STAR_spline(y = y, tau = tau): could not find function \"STAR_spline\" post_ytilde = fit_star$post_ytilde #> Error in eval(expr, envir, enclos): object 'fit_star' not found  # Compute 90% prediction intervals: pi_y = t(apply(post_ytilde, 2, quantile, c(0.05, .95))) #> Error in apply(post_ytilde, 2, quantile, c(0.05, 0.95)): object 'post_ytilde' not found  # Plot the results: intervals, median, and smoothed mean plot(tau, y, ylim = range(pi_y, y)) #> Error in plot.default(tau, y, ylim = range(pi_y, y)): object 'pi_y' not found polygon(c(tau, rev(tau)),c(pi_y[,2], rev(pi_y[,1])),col='gray', border=NA) #> Error in xy.coords(x, y, setLab = FALSE): object 'pi_y' not found lines(tau, apply(post_ytilde, 2, median), lwd=5, col ='black') #> Error in apply(post_ytilde, 2, median): object 'post_ytilde' not found lines(tau, smooth.spline(tau, apply(post_ytilde, 2, mean))$y, lwd=5, col='blue') #> Error in apply(post_ytilde, 2, mean): object 'post_ytilde' not found lines(tau, y, type='p') #> Error in plot.xy(xy.coords(x, y), type = type, ...): plot.new has not been called yet"},{"path":"https://bking124.github.io/rSTAR/reference/truncnorm_mom.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the first and second moment of a truncated normal — truncnorm_mom","title":"Compute the first and second moment of a truncated normal — truncnorm_mom","text":"Given lower upper endpoints mean standard deviation (non-truncated) normal distribution, compute first second moment truncated normal distribution. inputs may scalars vectors.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/truncnorm_mom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the first and second moment of a truncated normal — truncnorm_mom","text":"","code":"truncnorm_mom(a, b, mu, sig)"},{"path":"https://bking124.github.io/rSTAR/reference/truncnorm_mom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the first and second moment of a truncated normal — truncnorm_mom","text":"lower endpoint b upper endpoint mu expected value non-truncated normal distribution sig standard deviation non-truncated normal distribution","code":""},{"path":"https://bking124.github.io/rSTAR/reference/truncnorm_mom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the first and second moment of a truncated normal — truncnorm_mom","text":"list containing first moment m1 second moment m2","code":""},{"path":"https://bking124.github.io/rSTAR/reference/truncnorm_mom.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the first and second moment of a truncated normal — truncnorm_mom","text":"","code":"truncnorm_mom(-1, 1, 0, 1) #> Error in truncnorm_mom(-1, 1, 0, 1): could not find function \"truncnorm_mom\""},{"path":"https://bking124.github.io/rSTAR/reference/uni.slice.html","id":null,"dir":"Reference","previous_headings":"","what":"Univariate Slice Sampler from Neal (2008) — uni.slice","title":"Univariate Slice Sampler from Neal (2008) — uni.slice","text":"Compute draw univariate distribution using code provided Radford M. Neal. documentation also reproduced Neal (2008).","code":""},{"path":"https://bking124.github.io/rSTAR/reference/uni.slice.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Univariate Slice Sampler from Neal (2008) — uni.slice","text":"","code":"uni.slice(x0, g, w = 1, m = Inf, lower = -Inf, upper = +Inf, gx0 = NULL)"},{"path":"https://bking124.github.io/rSTAR/reference/uni.slice.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Univariate Slice Sampler from Neal (2008) — uni.slice","text":"x0 Initial point g Function returning log probability density (plus constant) w Size steps creating interval (default 1) m Limit steps (default infinite) lower Lower bound support distribution (default -Inf) upper Upper bound support distribution (default +Inf) gx0 Value g(x0), known (default known)","code":""},{"path":"https://bking124.github.io/rSTAR/reference/uni.slice.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Univariate Slice Sampler from Neal (2008) — uni.slice","text":"point sampled, log density attached attribute.","code":""},{"path":"https://bking124.github.io/rSTAR/reference/uni.slice.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Univariate Slice Sampler from Neal (2008) — uni.slice","text":"log density function may return -Inf points outside support distribution.  lower /upper bound specified support, log density function called outside limits.","code":""}]
